{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章: 係り受け解析\n",
    "『吾輩は猫である』に係り受け解析器CaboChaを適用し，係り受け木の操作と統語的な分析を体験します．\n",
    "\n",
    "- クラス, 係り受け解析, CaboCha, 文節, 係り受け, 格, 機能動詞構文, 係り受けパス, Graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "夏目漱石の小説『吾輩は猫である』の文章（[neko.txt](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/neko.txt)）をCaboChaを使って係り受け解析し，その結果をneko.txt.cabochaというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!brew install cabocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\r\n",
      "\r\n",
      "　吾輩は猫である。\r\n",
      "名前はまだ無い。\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 neko.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\n",
      "EOS\n",
      "EOS\n",
      "        　---D\n",
      "      吾輩は-D\n",
      "    猫である。\n",
      "EOS\n",
      "名前は---D\n",
      "    まだ-D\n",
      "    無い。\n",
      "EOS\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "!head -5 neko.txt | cabocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://taku910.github.io/cabocha/\n",
    "によると、 `-f1`オプションでcsv形式の出力になる様子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 -1D 0/0 0.000000\r\n",
      "一\t名詞,数,*,*,*,*,一,イチ,イチ\r\n",
      "EOS\r\n",
      "EOS\r\n",
      "* 0 2D 0/0 -0.764522\r\n",
      "　\t記号,空白,*,*,*,*,　,　,　\r\n",
      "* 1 2D 0/1 -0.764522\r\n",
      "吾輩\t名詞,代名詞,一般,*,*,*,吾輩,ワガハイ,ワガハイ\r\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\r\n",
      "* 2 -1D 0/2 0.000000\r\n",
      "猫\t名詞,一般,*,*,*,*,猫,ネコ,ネコ\r\n",
      "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\r\n",
      "ある\t助動詞,*,*,*,五段・ラ行アル,基本形,ある,アル,アル\r\n",
      "。\t記号,句点,*,*,*,*,。,。,。\r\n",
      "EOS\r\n",
      "* 0 2D 0/1 -1.911675\r\n",
      "名前\t名詞,一般,*,*,*,*,名前,ナマエ,ナマエ\r\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\r\n",
      "* 1 2D 0/0 -1.911675\r\n",
      "まだ\t副詞,助詞類接続,*,*,*,*,まだ,マダ,マダ\r\n",
      "* 2 -1D 0/0 0.000000\r\n",
      "無い\t形容詞,自立,*,*,形容詞・アウオ段,基本形,無い,ナイ,ナイ\r\n",
      "。\t記号,句点,*,*,*,*,。,。,。\r\n",
      "EOS\r\n",
      "EOS\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 neko.txt | cabocha -f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat neko.txt | cabocha -f1 > neko.txt.cabocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 -1D 0/0 0.000000\r\n",
      "一\t名詞,数,*,*,*,*,一,イチ,イチ\r\n",
      "EOS\r\n",
      "EOS\r\n",
      "* 0 2D 0/0 -0.764522\r\n",
      "　\t記号,空白,*,*,*,*,　,　,　\r\n",
      "* 1 2D 0/1 -0.764522\r\n",
      "吾輩\t名詞,代名詞,一般,*,*,*,吾輩,ワガハイ,ワガハイ\r\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\r\n",
      "* 2 -1D 0/2 0.000000\r\n"
     ]
    }
   ],
   "source": [
    "!head -10 neko.txt.cabocha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，CaboChaの解析結果（neko.txt.cabocha）を読み込み，各文をMorphオブジェクトのリストとして表現し，3文目の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Morph({self.surface}, {self.base}, {self.pos}, {self.pos1})'\n",
    "    \n",
    "    __str__ = __repr__\n",
    "\n",
    "    RE_CABOCHA_LINE = r\"\"\"\n",
    "    (?P<surface>[^,]+)\\t\n",
    "    (?P<pos>[^,]+),\n",
    "    (?P<pos1>[^,]+),\n",
    "    (?P<pos2>[^,]+),\n",
    "    (?P<pos3>[^,]+),\n",
    "    (?P<conjtype>[^,]+),\n",
    "    (?P<form>[^,]+),\n",
    "    (?P<base>[^,]+)\n",
    "    (\n",
    "        ,(?P<kana>[^,]+)\n",
    "        ,(?P<sound>[^,]+)\n",
    "    )?\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def from_cabocha_line(cls, line):\n",
    "        line = line.rstrip()\n",
    "        m = re.match(cls.RE_CABOCHA_LINE, line, re.VERBOSE)\n",
    "        if m:\n",
    "            return cls(m.group('surface'), m.group('base'), m.group('pos'), m.group('pos1'))\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    @property\n",
    "    def is_sign(self):\n",
    "        \"\"\"\n",
    "        42, 43で使用\n",
    "        \"\"\"\n",
    "        return self.pos == '記号'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence = []\n",
    "with open('neko.txt.cabocha') as f:\n",
    "    for line in f:\n",
    "        # 末尾の改行除去\n",
    "        line = line.rstrip()\n",
    "        if line == 'EOS':\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            m = Morph.from_cabocha_line(line)\n",
    "            if m:\n",
    "                sentence.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Morph(一, 一, 名詞, 数)],\n",
       " [],\n",
       " [Morph(　, 　, 記号, 空白),\n",
       "  Morph(吾輩, 吾輩, 名詞, 代名詞),\n",
       "  Morph(は, は, 助詞, 係助詞),\n",
       "  Morph(猫, 猫, 名詞, 一般),\n",
       "  Morph(で, だ, 助動詞, *),\n",
       "  Morph(ある, ある, 助動詞, *),\n",
       "  Morph(。, 。, 記号, 句点)],\n",
       " [Morph(名前, 名前, 名詞, 一般),\n",
       "  Morph(は, は, 助詞, 係助詞),\n",
       "  Morph(まだ, まだ, 副詞, 助詞類接続),\n",
       "  Morph(無い, 無い, 形容詞, 自立),\n",
       "  Morph(。, 。, 記号, 句点)],\n",
       " [],\n",
       " [Morph(　, 　, 記号, 空白),\n",
       "  Morph(どこ, どこ, 名詞, 代名詞),\n",
       "  Morph(で, で, 助詞, 格助詞),\n",
       "  Morph(生れ, 生れる, 動詞, 自立),\n",
       "  Morph(た, た, 助動詞, *),\n",
       "  Morph(か, か, 助詞, 副助詞／並立助詞／終助詞),\n",
       "  Morph(とんと, とんと, 副詞, 一般),\n",
       "  Morph(見当, 見当, 名詞, サ変接続),\n",
       "  Morph(が, が, 助詞, 格助詞),\n",
       "  Morph(つか, つく, 動詞, 自立),\n",
       "  Morph(ぬ, ぬ, 助動詞, *),\n",
       "  Morph(。, 。, 記号, 句点)]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Morph(　, 　, 記号, 空白),\n",
       " Morph(どこ, どこ, 名詞, 代名詞),\n",
       " Morph(で, で, 助詞, 格助詞),\n",
       " Morph(生れ, 生れる, 動詞, 自立),\n",
       " Morph(た, た, 助動詞, *),\n",
       " Morph(か, か, 助詞, 副助詞／並立助詞／終助詞),\n",
       " Morph(とんと, とんと, 副詞, 一般),\n",
       " Morph(見当, 見当, 名詞, サ変接続),\n",
       " Morph(が, が, 助詞, 格助詞),\n",
       " Morph(つか, つく, 動詞, 自立),\n",
       " Morph(ぬ, ぬ, 助動詞, *),\n",
       " Morph(。, 。, 記号, 句点)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストのCaboChaの解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，8文目の文節の文字列と係り先を表示せよ．第5章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = 'EOS'\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, dst):\n",
    "        self.morphs = []\n",
    "        self.dst = int(dst)\n",
    "        self.srcs = []\n",
    "    \n",
    "    RE_CABOCHA_LINE = r'\\* \\d+ (?P<dst>-?\\d+)D \\d+/\\d+ -?\\d+(\\.\\d*)?'\n",
    "    @classmethod\n",
    "    def from_cabocha_line(cls, line, current_chunk=None):\n",
    "        line = line.rstrip()\n",
    "        if line == 'EOS':\n",
    "            return EOS\n",
    "        \n",
    "        m = re.match(cls.RE_CABOCHA_LINE, line)\n",
    "        if m:\n",
    "            return Chunk(m.group('dst'))\n",
    "        \n",
    "        m = Morph.from_cabocha_line(line)\n",
    "        assert m is not None\n",
    "        current_chunk.morphs.append(m)\n",
    "    \n",
    "    @property\n",
    "    def surface(self):\n",
    "        return ''.join(map(lambda m: m.surface, self.morphs))\n",
    "    \n",
    "    @property\n",
    "    def morphs_wo_signs(self):\n",
    "        \"\"\"\n",
    "        42, 43で使用\n",
    "        \"\"\"\n",
    "        return [m for m in self.morphs if not m.is_sign]\n",
    "\n",
    "    def wo_signs(self):\n",
    "        \"\"\"\n",
    "        42, 43で使用\n",
    "        \"\"\"\n",
    "        chunk = type(self)(dst=self.dst)\n",
    "        chunk.morphs = self.morphs_wo_signs\n",
    "        chunk.srcs = self.srcs\n",
    "        return chunk\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return bool(self.morphs)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Chunk(surface={repr(self.surface)}, dst={self.dst}, srcs={self.srcs})'\n",
    "    __str__ = __repr__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence = []\n",
    "current_chunk = None\n",
    "with open('neko.txt.cabocha') as f:\n",
    "    for line in f:\n",
    "        ret = Chunk.from_cabocha_line(line, current_chunk=current_chunk)\n",
    "        if ret == EOS:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "            current_chunk = None\n",
    "        elif isinstance(ret, Chunk):\n",
    "            sentence.append(ret)\n",
    "            current_chunk = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_srcs(sentence):\n",
    "    for i_chunk in range(len(sentence)):\n",
    "        chunk = sentence[i_chunk]\n",
    "        if chunk.dst != -1:\n",
    "            sentence[chunk.dst].srcs.append(i_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    set_srcs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(surface='この', dst=1, srcs=[]),\n",
       " Chunk(surface='書生というのは', dst=7, srcs=[0]),\n",
       " Chunk(surface='時々', dst=4, srcs=[]),\n",
       " Chunk(surface='我々を', dst=4, srcs=[]),\n",
       " Chunk(surface='捕えて', dst=5, srcs=[2, 3]),\n",
       " Chunk(surface='煮て', dst=6, srcs=[4]),\n",
       " Chunk(surface='食うという', dst=7, srcs=[5]),\n",
       " Chunk(surface='話である。', dst=-1, srcs=[1, 6])]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[8 + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = [\n",
    "    (chunk, sentence[chunk.dst]) \n",
    "    for sentence in sentences \n",
    "    for chunk in sentence \n",
    "    if chunk.dst != -1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Chunk(surface='\\u3000', dst=2, srcs=[]),\n",
       "  Chunk(surface='猫である。', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='吾輩は', dst=2, srcs=[]),\n",
       "  Chunk(surface='猫である。', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='名前は', dst=2, srcs=[]),\n",
       "  Chunk(surface='無い。', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='まだ', dst=2, srcs=[]),\n",
       "  Chunk(surface='無い。', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='\\u3000どこで', dst=1, srcs=[]),\n",
       "  Chunk(surface='生れたか', dst=4, srcs=[0]))]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Chunk(surface='吾輩は', dst=2, srcs=[]),\n",
       "  Chunk(surface='猫である', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='名前は', dst=2, srcs=[]),\n",
       "  Chunk(surface='無い', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='まだ', dst=2, srcs=[]),\n",
       "  Chunk(surface='無い', dst=-1, srcs=[0, 1])),\n",
       " (Chunk(surface='どこで', dst=1, srcs=[]),\n",
       "  Chunk(surface='生れたか', dst=4, srcs=[0])),\n",
       " (Chunk(surface='生れたか', dst=4, srcs=[0]),\n",
       "  Chunk(surface='つかぬ', dst=-1, srcs=[1, 2, 3])),\n",
       " (Chunk(surface='とんと', dst=4, srcs=[]),\n",
       "  Chunk(surface='つかぬ', dst=-1, srcs=[1, 2, 3])),\n",
       " (Chunk(surface='見当が', dst=4, srcs=[]),\n",
       "  Chunk(surface='つかぬ', dst=-1, srcs=[1, 2, 3])),\n",
       " (Chunk(surface='何でも', dst=1, srcs=[]), Chunk(surface='薄暗い', dst=3, srcs=[0])),\n",
       " (Chunk(surface='薄暗い', dst=3, srcs=[0]),\n",
       "  Chunk(surface='所で', dst=5, srcs=[1, 2])),\n",
       " (Chunk(surface='じめじめした', dst=3, srcs=[]),\n",
       "  Chunk(surface='所で', dst=5, srcs=[1, 2]))]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps_wo_signs = ((src.wo_signs(), dst.wo_signs()) for src, dst in deps)\n",
    "# いずれかが空文字列なら削除\n",
    "deps_wo_signs = list(filter(all, deps_wo_signs))\n",
    "deps_wo_signs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep2tsv(dep):\n",
    "    surfaces = map(lambda c: c.surface, dep)\n",
    "    return '\\t'.join(surfaces)\n",
    "def deps2tsv(deps):\n",
    "    return '\\n'.join(map(dep2tsv, deps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps_tsv = deps2tsv(deps_wo_signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吾輩は\\t猫である',\n",
       " '名前は\\t無い',\n",
       " 'まだ\\t無い',\n",
       " 'どこで\\t生れたか',\n",
       " '生れたか\\tつかぬ',\n",
       " 'とんと\\tつかぬ',\n",
       " '見当が\\tつかぬ',\n",
       " '何でも\\t薄暗い',\n",
       " '薄暗い\\t所で',\n",
       " 'じめじめした\\t所で',\n",
       " '所で\\t泣いて',\n",
       " 'ニャーニャー\\t泣いて',\n",
       " '泣いて\\t記憶している',\n",
       " 'いた事だけは\\t記憶している',\n",
       " '吾輩は\\t見た',\n",
       " 'ここで\\t始めて',\n",
       " '始めて\\t人間という',\n",
       " '人間という\\tものを',\n",
       " 'ものを\\t見た',\n",
       " 'しかも\\t種族であったそうだ']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps_tsv.splitlines()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['どこで\\t生れたか',\n",
       " '見当が\\tつかぬ',\n",
       " '所で\\t泣いて',\n",
       " 'ニャーニャー\\t泣いて',\n",
       " 'いた事だけは\\t記憶している',\n",
       " '吾輩は\\t見た',\n",
       " 'ここで\\t始めて',\n",
       " 'ものを\\t見た',\n",
       " 'あとで\\t聞くと',\n",
       " '我々を\\t捕えて',\n",
       " '掌に\\t載せられて',\n",
       " 'スーと\\t持ち上げられた',\n",
       " '時\\tフワフワした',\n",
       " '感じが\\tあったばかりである',\n",
       " '上で\\t落ちついて',\n",
       " '顔を\\t見たのが',\n",
       " 'ものの\\t見始であろう',\n",
       " 'ものだと\\t思った',\n",
       " '感じが\\t残っている',\n",
       " '今でも\\t残っている']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contains_pos(chunk, pos):\n",
    "    a = list(filter(lambda m: m.pos == pos, chunk.morphs))\n",
    "    return bool(a)\n",
    "\n",
    "def is_sv(dep):\n",
    "    src, dst = dep\n",
    "    return contains_pos(src, '名詞') and contains_pos(dst, '動詞')\n",
    "\n",
    "svs = list(filter(is_sv, deps_wo_signs))\n",
    "svs_tsv = deps2tsv(svs)\n",
    "svs_tsv.splitlines()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，係り受け木をDOT言語に変換し，Graphvizを用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，pydotを使うとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pydot.Nodeのプロパティについては\n",
    "http://www.graphviz.org/doc/info/attrs.html\n",
    "を、notebook上にinlineで表示させる方法は\n",
    "https://qiita.com/horihori49/items/0c79bb2d9e5209713eed\n",
    "を、それぞれ参考にした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"116pt\" viewBox=\"0.00 0.00 140.19 116.00\" width=\"140pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-112 136.1949,-112 136.1949,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- asdf -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>asdf</title>\n",
       "<ellipse cx=\"65.5975\" cy=\"-90\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5975\" y=\"-86.3\">asdf</text>\n",
       "</g>\n",
       "<!-- a -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>a</title>\n",
       "<ellipse cx=\"28.5975\" cy=\"-18\" fill=\"none\" rx=\"28.6953\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"28.5975\" y=\"-14.3\">qwer</text>\n",
       "</g>\n",
       "<!-- asdf&#45;&gt;a -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>asdf-&gt;a</title>\n",
       "<path d=\"M56.829,-72.937C52.4695,-64.4537 47.1022,-54.0092 42.2222,-44.513\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"45.2438,-42.7352 37.56,-35.4407 39.0178,-45.9348 45.2438,-42.7352\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>b</title>\n",
       "<ellipse cx=\"103.5975\" cy=\"-18\" fill=\"none\" rx=\"28.6953\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5975\" y=\"-14.3\">qwer</text>\n",
       "</g>\n",
       "<!-- asdf&#45;&gt;b -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>asdf-&gt;b</title>\n",
       "<path d=\"M74.6029,-72.937C79.0802,-64.4537 84.5926,-54.0092 89.6045,-44.513\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"92.8204,-45.9182 94.3927,-35.4407 86.6297,-42.6509 92.8204,-45.9182\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = pydot.Dot()\n",
    "a = pydot.Node('asdf')\n",
    "b = pydot.Node('a', label=\"qwer\")\n",
    "c = pydot.Node('b', label=\"qwer\")\n",
    "\n",
    "dot.add_node(a)\n",
    "dot.add_node(b)\n",
    "\n",
    "dot.add_node(c)\n",
    "\n",
    "dot.add_edge(pydot.Edge(a, b))\n",
    "dot.add_edge(pydot.Edge(a, c))\n",
    "SVG(dot.create(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2tree(sentence):\n",
    "    dot = pydot.Dot()\n",
    "    nodes = [pydot.Node(str(i), label=chunk.surface) for i, chunk in enumerate(sentence)]\n",
    "    edges = [pydot.Edge(str(i), str(chunk.dst)) for i, chunk in enumerate(sentence) if chunk.dst != -1]\n",
    "    for node in nodes:\n",
    "        dot.add_node(node)\n",
    "    for edge in edges:\n",
    "        dot.add_edge(edge)\n",
    "    return SVG(dot.create(format='svg'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"332pt\" viewBox=\"0.00 0.00 313.09 332.00\" width=\"313pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-328 309.09,-328 309.09,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>0</title>\n",
       "<ellipse cx=\"74.7434\" cy=\"-162\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74.7434\" y=\"-158.3\">この</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1</title>\n",
       "<ellipse cx=\"74.7434\" cy=\"-90\" fill=\"none\" rx=\"74.9875\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74.7434\" y=\"-86.3\">書生というのは</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>0-&gt;1</title>\n",
       "<path d=\"M74.7434,-143.8314C74.7434,-136.131 74.7434,-126.9743 74.7434,-118.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"78.2435,-118.4132 74.7434,-108.4133 71.2435,-118.4133 78.2435,-118.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>7</title>\n",
       "<ellipse cx=\"148.7434\" cy=\"-18\" fill=\"none\" rx=\"56.59\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148.7434\" y=\"-14.3\">話である。</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1-&gt;7</title>\n",
       "<path d=\"M93.0355,-72.2022C102.2442,-63.2425 113.5509,-52.2414 123.5661,-42.4968\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"126.1905,-44.8267 130.917,-35.3446 121.309,-39.8096 126.1905,-44.8267\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>2</title>\n",
       "<ellipse cx=\"180.7434\" cy=\"-306\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.7434\" y=\"-302.3\">時々</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4</title>\n",
       "<ellipse cx=\"223.7434\" cy=\"-234\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.7434\" y=\"-230.3\">捕えて</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>2-&gt;4</title>\n",
       "<path d=\"M190.9338,-288.937C196.0529,-280.3654 202.368,-269.7914 208.0863,-260.2165\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"211.2049,-261.8207 213.3274,-251.4407 205.195,-258.2315 211.2049,-261.8207\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>3</title>\n",
       "<ellipse cx=\"266.7434\" cy=\"-306\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"266.7434\" y=\"-302.3\">我々を</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>3-&gt;4</title>\n",
       "<path d=\"M256.3343,-288.5708C251.2486,-280.0553 245.0229,-269.6308 239.3804,-260.183\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"242.338,-258.3091 234.2056,-251.5182 236.3282,-261.8983 242.338,-258.3091\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5</title>\n",
       "<ellipse cx=\"223.7434\" cy=\"-162\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.7434\" y=\"-158.3\">煮て</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4-&gt;5</title>\n",
       "<path d=\"M223.7434,-215.8314C223.7434,-208.131 223.7434,-198.9743 223.7434,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"227.2435,-190.4132 223.7434,-180.4133 220.2435,-190.4133 227.2435,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>6</title>\n",
       "<ellipse cx=\"223.7434\" cy=\"-90\" fill=\"none\" rx=\"56.59\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.7434\" y=\"-86.3\">食うという</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5-&gt;6</title>\n",
       "<path d=\"M223.7434,-143.8314C223.7434,-136.131 223.7434,-126.9743 223.7434,-118.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"227.2435,-118.4132 223.7434,-108.4133 220.2435,-118.4133 227.2435,-118.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>6-&gt;7</title>\n",
       "<path d=\"M205.588,-72.5708C196.0992,-63.4616 184.3349,-52.1679 173.9747,-42.2221\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"176.3694,-39.6692 166.7316,-35.2687 171.5216,-44.7189 176.3694,-39.6692\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2tree(sentences[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"476pt\" viewBox=\"0.00 0.00 563.89 476.00\" width=\"564pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-472 559.8916,-472 559.8916,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>0</title>\n",
       "<ellipse cx=\"38.3466\" cy=\"-90\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.3466\" y=\"-86.3\">しかし</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>13</title>\n",
       "<ellipse cx=\"142.3466\" cy=\"-18\" fill=\"none\" rx=\"56.59\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.3466\" y=\"-14.3\">事である。</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;13 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>0-&gt;13</title>\n",
       "<path d=\"M59.8955,-75.0816C74.487,-64.9797 94.0177,-51.4585 110.4079,-40.1114\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.4201,-42.9753 118.6498,-34.4055 108.4356,-37.2199 112.4201,-42.9753\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1</title>\n",
       "<ellipse cx=\"56.3466\" cy=\"-162\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"56.3466\" y=\"-158.3\">一番</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>3</title>\n",
       "<ellipse cx=\"142.3466\" cy=\"-90\" fill=\"none\" rx=\"47.3916\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.3466\" y=\"-86.3\">好いのは</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1-&gt;3</title>\n",
       "<path d=\"M73.75,-147.4297C85.4558,-137.6295 101.1407,-124.498 114.5575,-113.2653\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"117.1417,-115.6665 122.5625,-106.5634 112.6481,-110.2992 117.1417,-115.6665\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>2</title>\n",
       "<ellipse cx=\"142.3466\" cy=\"-162\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.3466\" y=\"-158.3\">心持の</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>2-&gt;3</title>\n",
       "<path d=\"M142.3466,-143.8314C142.3466,-136.131 142.3466,-126.9743 142.3466,-118.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"145.8467,-118.4132 142.3466,-108.4133 138.8467,-118.4133 145.8467,-118.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;13 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>3-&gt;13</title>\n",
       "<path d=\"M142.3466,-71.8314C142.3466,-64.131 142.3466,-54.9743 142.3466,-46.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"145.8467,-46.4132 142.3466,-36.4133 138.8467,-46.4133 145.8467,-46.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4</title>\n",
       "<ellipse cx=\"237.3466\" cy=\"-234\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.3466\" y=\"-230.3\">夜に</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5</title>\n",
       "<ellipse cx=\"237.3466\" cy=\"-162\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.3466\" y=\"-158.3\">入って</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4-&gt;5</title>\n",
       "<path d=\"M237.3466,-215.8314C237.3466,-208.131 237.3466,-198.9743 237.3466,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"240.8467,-190.4132 237.3466,-180.4133 233.8467,-190.4133 240.8467,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>12</title>\n",
       "<ellipse cx=\"298.3466\" cy=\"-90\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.3466\" y=\"-86.3\">ねる</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;12 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5-&gt;12</title>\n",
       "<path d=\"M251.8027,-144.937C259.5867,-135.7494 269.3197,-124.2613 277.8701,-114.1689\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"280.6203,-116.3373 284.4141,-106.4449 275.2794,-111.8123 280.6203,-116.3373\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>6</title>\n",
       "<ellipse cx=\"359.3466\" cy=\"-450\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.3466\" y=\"-446.3\">ここの</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>7</title>\n",
       "<ellipse cx=\"359.3466\" cy=\"-378\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.3466\" y=\"-374.3\">うちの</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>6-&gt;7</title>\n",
       "<path d=\"M359.3466,-431.8314C359.3466,-424.131 359.3466,-414.9743 359.3466,-406.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"362.8467,-406.4132 359.3466,-396.4133 355.8467,-406.4133 362.8467,-406.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>8</title>\n",
       "<ellipse cx=\"359.3466\" cy=\"-306\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.3466\" y=\"-302.3\">小供の</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>7-&gt;8</title>\n",
       "<path d=\"M359.3466,-359.8314C359.3466,-352.131 359.3466,-342.9743 359.3466,-334.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"362.8467,-334.4132 359.3466,-324.4133 355.8467,-334.4133 362.8467,-334.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>9</title>\n",
       "<ellipse cx=\"359.3466\" cy=\"-234\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.3466\" y=\"-230.3\">寝床へ</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>8-&gt;9</title>\n",
       "<path d=\"M359.3466,-287.8314C359.3466,-280.131 359.3466,-270.9743 359.3466,-262.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"362.8467,-262.4132 359.3466,-252.4133 355.8467,-262.4133 362.8467,-262.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>10</title>\n",
       "<ellipse cx=\"359.3466\" cy=\"-162\" fill=\"none\" rx=\"65.7887\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359.3466\" y=\"-158.3\">もぐり込んで</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>9-&gt;10</title>\n",
       "<path d=\"M359.3466,-215.8314C359.3466,-208.131 359.3466,-198.9743 359.3466,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"362.8467,-190.4132 359.3466,-180.4133 355.8467,-190.4133 362.8467,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>10-&gt;12</title>\n",
       "<path d=\"M344.2679,-144.2022C336.5502,-135.0928 327.0448,-123.8733 318.688,-114.0096\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"321.1376,-111.4864 312.003,-106.119 315.7967,-116.0113 321.1376,-111.4864\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>11</title>\n",
       "<ellipse cx=\"499.3466\" cy=\"-162\" fill=\"none\" rx=\"56.59\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499.3466\" y=\"-158.3\">いっしょに</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>11-&gt;12</title>\n",
       "<path d=\"M461.54,-148.4574C424.7426,-135.2762 369.2753,-115.4073 333.4336,-102.5685\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"334.4712,-99.2224 323.8767,-99.1451 332.1106,-105.8124 334.4712,-99.2224\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>12-&gt;13</title>\n",
       "<path d=\"M274.6536,-79.0647C250.5802,-67.954 212.8058,-50.5196 183.7714,-37.1192\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"185.2266,-33.936 174.6803,-32.9232 182.2931,-40.2917 185.2266,-33.936\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2tree(sentences[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "- 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "- 述語に係る助詞を格とする\n",
    "- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "\n",
    "「吾輩はここで始めて人間というものを見た」という例文（neko.txt.cabochaの8文目）を考える． この文は「始める」と「見る」の２つの動詞を含み，「始める」に係る文節は「ここで」，「見る」に係る文節は「吾輩は」と「ものを」と解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "```\n",
    "始める  で\n",
    "見る    は を\n",
    "```\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "- コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "- 「する」「見る」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_verb(chunk):\n",
    "    for m in chunk.morphs:\n",
    "        if m.pos == '動詞':\n",
    "            return m.base\n",
    "    return None\n",
    "\n",
    "def get_last_particle(chunk):\n",
    "    for m in reversed(chunk.morphs):\n",
    "        if m.pos == '助詞':\n",
    "            return m.base\n",
    "    return None\n",
    "\n",
    "def extract_verb_src_pairs(sentence):\n",
    "    # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "    chunks_with_verbs = [(chunk, get_first_verb(chunk)) for chunk in sentence]\n",
    "    chunks_with_verbs = list(filter(lambda x: x[1] is not None, chunks_with_verbs))\n",
    "    \n",
    "    # 述語に係る助詞を格とする\n",
    "    verb_src_pairs = [\n",
    "        (\n",
    "            verb_base, \n",
    "            [get_last_particle(sentence[i_src]) for i_src in chunk.srcs]\n",
    "        )\n",
    "        for chunk, verb_base in chunks_with_verbs\n",
    "    ]\n",
    "    verb_src_pairs = list(filter(lambda x: x[1] is not None, verb_src_pairs))\n",
    "    \n",
    "    return verb_src_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out_chapter5_45.txt', 'w') as f:\n",
    "    for sentence in sentences:\n",
    "        for verb, srcs in extract_verb_src_pairs(sentence):\n",
    "            # 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "            srcs_sorted = sorted(filter(bool, srcs))\n",
    "            if srcs_sorted:\n",
    "                print(verb, ' '.join(srcs_sorted), file=f, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生れる\tで\r\n",
      "つく\tか が\r\n",
      "泣く\tで\r\n",
      "する\tて は\r\n",
      "始める\tで\r\n",
      "見る\tは を\r\n",
      "聞く\tで\r\n",
      "捕える\tを\r\n",
      "煮る\tて\r\n",
      "食う\tて\r\n"
     ]
    }
   ],
   "source": [
    "!head out_chapter5_45.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 704 云う\tと\r\n",
      " 452 する\tを\r\n",
      " 333 思う\tと\r\n",
      " 202 ある\tが\r\n",
      " 199 なる\tに\r\n",
      " 188 する\tに\r\n",
      " 175 見る\tて\r\n",
      " 159 する\tと\r\n",
      " 117 する\tが\r\n",
      " 113 する\tに を\r\n",
      "  98 見る\tを\r\n",
      "  97 見える\tと\r\n",
      "  90 する\tて を\r\n",
      "  85 する\tは\r\n",
      "  61 する\tて\r\n",
      "  60 する\tが を\r\n",
      "  60 もつ\tを\r\n",
      "  59 する\tも\r\n",
      "  57 ある\tの\r\n",
      "  56 云う\tを\r\n",
      "sort: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "# コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "!sort out_chapter5_45.txt | uniq -c | sort -rn | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 452 する\tを\r\n",
      " 188 する\tに\r\n",
      " 175 見る\tて\r\n",
      " 159 する\tと\r\n",
      " 117 する\tが\r\n",
      " 113 する\tに を\r\n",
      "  98 見る\tを\r\n",
      "  90 する\tて を\r\n",
      "  85 する\tは\r\n",
      "  61 する\tて\r\n",
      "  60 する\tが を\r\n",
      "  59 する\tも\r\n",
      "  51 する\tから\r\n",
      "  51 する\tと を\r\n",
      "  46 する\tで を\r\n",
      "  40 する\tの\r\n",
      "  39 する\tと は\r\n",
      "  37 する\tから を\r\n",
      "  37 する\tは を\r\n",
      "  36 する\tで\r\n",
      "  32 する\tが に\r\n",
      "  32 する\tが と\r\n",
      "  25 する\tと は を\r\n",
      "  25 する\tに は\r\n",
      "  24 する\tて に\r\n",
      "  23 見る\tて て\r\n",
      "  20 見る\tから\r\n",
      "  17 する\tが に を\r\n",
      "  17 見る\tと\r\n",
      "  16 する\tから に\r\n",
      "  15 見る\tて を\r\n",
      "  15 する\tは も\r\n",
      "  15 する\tて と\r\n",
      "  13 見る\tて は\r\n",
      "  13 する\tも を\r\n",
      "  13 する\tか\r\n",
      "  12 見る\tから て\r\n",
      "  12 する\tまで\r\n",
      "  12 する\tて は を\r\n",
      "  12 する\tて に を\r\n",
      "  12 する\tて は\r\n",
      "  12 見る\tで\r\n",
      "  12 する\tば\r\n",
      "  11 する\tと に は\r\n",
      "  11 する\tが と を\r\n",
      "  11 する\tに も\r\n",
      "  11 する\tに に\r\n",
      "  11 する\tで と\r\n",
      "  11 する\tが は\r\n",
      "  11 する\tが で\r\n",
      "  10 する\tに は を\r\n",
      "  10 する\tと に を\r\n",
      "  10 する\tが で を\r\n",
      "  10 する\tと も\r\n",
      "  10 する\tと に\r\n",
      "  10 する\tが も\r\n",
      "   9 する\tから は\r\n",
      "   9 する\tで に\r\n",
      "   9 見る\tに\r\n",
      "   8 する\tでも\r\n",
      "   8 する\tに に を\r\n",
      "   8 する\tて と を\r\n",
      "   8 見る\tて と\r\n",
      "   8 見る\tが\r\n",
      "   7 する\tまで を\r\n",
      "   7 する\tから も\r\n",
      "   7 する\tから が\r\n",
      "   7 する\tさえ\r\n",
      "   7 する\tで に を\r\n",
      "   7 見る\tに を\r\n",
      "   7 見る\tが を\r\n",
      "   7 する\tて も\r\n",
      "   7 する\tへ\r\n",
      "   6 する\tくらい\r\n",
      "   6 する\tと に は を\r\n",
      "   6 見る\tて は を\r\n",
      "   6 する\tに も を\r\n",
      "   6 する\tて と は\r\n",
      "   6 する\tが て を\r\n",
      "   6 する\tが て に\r\n",
      "   6 見る\tと を\r\n",
      "   6 見る\tて も\r\n",
      "   6 する\tば を\r\n",
      "   6 する\tて て\r\n",
      "   6 見る\tも\r\n",
      "   5 する\tをもって\r\n",
      "   5 する\tなんか\r\n",
      "   5 する\tでも を\r\n",
      "   5 する\tと も を\r\n",
      "   5 する\tて に は\r\n",
      "   5 する\tが と に\r\n",
      "   5 する\tが で に\r\n",
      "   5 する\tが て は\r\n",
      "   5 見る\tで を\r\n",
      "   5 する\tて の\r\n",
      "   5 する\tが て\r\n",
      "   4 与える\tに を\r\n",
      "   4 する\tだって\r\n",
      "   4 見る\tから て て\r\n",
      "   4 する\tから と を\r\n",
      "   4 する\tから が に\r\n",
      "   4 見る\tから を\r\n",
      "   4 する\tって を\r\n",
      "   4 する\tたり を\r\n",
      "   4 する\tから て\r\n",
      "   4 する\tだけ\r\n",
      "   4 見る\tて て は\r\n",
      "   4 する\tて と に\r\n",
      "   4 する\tが に は\r\n",
      "   4 見る\tは を\r\n",
      "   4 見る\tが て\r\n",
      "   4 見る\tか て\r\n",
      "   4 する\tへ を\r\n",
      "   4 する\tは は\r\n",
      "   4 する\tね を\r\n",
      "   4 する\tと と\r\n",
      "   4 する\tが へ\r\n",
      "   4 する\tか を\r\n",
      "   4 見る\tは\r\n",
      "   3 する\tにおいて\r\n",
      "   3 する\tながら は を\r\n",
      "   3 する\tながら\r\n",
      "   3 する\tとして\r\n",
      "   3 する\tから と は を\r\n",
      "   3 する\tから と に は\r\n",
      "   3 する\tから が と は\r\n",
      "   3 する\tじゃ に は\r\n",
      "   3 する\tから に を\r\n",
      "   3 する\tから て を\r\n",
      "   3 する\tから が を\r\n",
      "   3 見る\tたり て\r\n",
      "   3 する\tから と\r\n",
      "   3 する\tので\r\n",
      "   3 する\tじゃ\r\n",
      "   3 する\tに について\r\n",
      "   3 する\tが として\r\n",
      "   3 見る\tて ので\r\n",
      "   3 する\tを んで\r\n",
      "   3 する\tと に は も\r\n",
      "   3 する\tて と は を\r\n",
      "   3 する\tが に に を\r\n",
      "   3 する\tは も を\r\n",
      "   3 する\tに は も\r\n",
      "   3 する\tと は は\r\n",
      "   3 する\tで と は\r\n",
      "   3 する\tて て を\r\n",
      "   3 する\tが と と\r\n",
      "   3 する\tか は を\r\n",
      "   3 する\tか て を\r\n",
      "   3 見る\tて ば\r\n",
      "   3 する\tの を\r\n",
      "   3 する\tに の\r\n",
      "   3 する\tで も\r\n",
      "   3 する\tて へ\r\n",
      "   3 する\tか に\r\n",
      "   2 与える\tて に は を\r\n",
      "   2 与える\tて に を\r\n",
      "   2 する\tばかり を\r\n",
      "   2 する\tながら を\r\n",
      "   2 する\tとして を\r\n",
      "   2 する\tだって を\r\n",
      "   2 する\tだって に\r\n",
      "   2 する\tばかり\r\n",
      "   2 する\tから で は を\r\n",
      "   2 する\tから て は を\r\n",
      "   2 する\tから て で を\r\n",
      "   2 する\tから が に は\r\n",
      "   2 見る\tから て を\r\n",
      "   2 見る\tから て は\r\n",
      "   2 する\tから は を\r\n",
      "   2 する\tから で を\r\n",
      "   2 する\tから で は\r\n",
      "   2 する\tから て は\r\n",
      "   2 する\tから て に\r\n",
      "   2 する\tから が は\r\n",
      "   2 する\tから が で\r\n",
      "   2 する\tから が て\r\n",
      "   2 する\tども は\r\n",
      "   2 する\tでも は\r\n",
      "   2 する\tでも に\r\n",
      "   2 する\tって に\r\n",
      "   2 する\tじゃ を\r\n",
      "   2 する\tじゃ て\r\n",
      "   2 する\tさえ を\r\n",
      "   2 する\tから へ\r\n",
      "   2 する\tから で\r\n",
      "   2 する\tほど\r\n",
      "   2 する\tとも\r\n",
      "   2 する\tって\r\n",
      "   2 する\tと ながら は\r\n",
      "   2 する\tが として を\r\n",
      "   2 する\tが として に\r\n",
      "   2 する\tに ばかり\r\n",
      "   2 する\tと ばかり\r\n",
      "   2 する\tで でも を\r\n",
      "   2 する\tは まで\r\n",
      "   2 する\tで のに\r\n",
      "   2 する\tが のに\r\n",
      "   2 する\tが ので\r\n",
      "   2 する\tが さえ\r\n",
      "   2 する\tて と は も を\r\n",
      "   2 する\tて と に は を\r\n",
      "   2 見る\tて に は を\r\n",
      "   2 する\tに は ば を\r\n",
      "   2 する\tと は は は\r\n",
      "   2 する\tと と も を\r\n",
      "   2 する\tで と は を\r\n",
      "   2 する\tて に に を\r\n",
      "   2 する\tて と に を\r\n",
      "   2 する\tて で は を\r\n",
      "   2 する\tて て と を\r\n",
      "   2 する\tが と は を\r\n",
      "   2 する\tが と に を\r\n",
      "   2 する\tが て に を\r\n",
      "   2 する\tが て に は\r\n",
      "   2 する\tか に は を\r\n",
      "   2 見る\tで は を\r\n",
      "   2 見る\tて に を\r\n",
      "   2 見る\tて と は\r\n",
      "   2 見る\tて で は\r\n",
      "   2 見る\tて て を\r\n",
      "   2 見る\tが は も\r\n",
      "   2 見る\tが て は\r\n",
      "   2 する\tと は ば\r\n",
      "   2 する\tと に も\r\n",
      "   2 する\tで に は\r\n",
      "   2 する\tて で を\r\n",
      "   2 する\tが も を\r\n",
      "   2 する\tが へ を\r\n",
      "   2 する\tが に に\r\n",
      "   2 する\tが て で\r\n",
      "   2 する\tか が に\r\n",
      "   2 見る\tて に\r\n",
      "   2 する\tば も\r\n",
      "   2 する\tは ば\r\n",
      "   2 する\tの も\r\n",
      "   2 する\tに ば\r\n",
      "   2 する\tに ね\r\n",
      "   2 する\tと ば\r\n",
      "   2 する\tで は\r\n",
      "   2 する\tて で\r\n",
      "   2 する\tさ と\r\n",
      "   2 する\tが の\r\n",
      "   2 する\tが が\r\n",
      "   2 する\tか は\r\n",
      "   2 する\tか て\r\n",
      "   2 する\tか が\r\n",
      "   2 見る\tの\r\n",
      "   2 見る\tか\r\n",
      "   2 する\tや\r\n",
      "   2 する\tね\r\n",
      "   2 する\tな\r\n",
      "   2 する\tぜ\r\n",
      "   1 与える\tけれども は を\r\n",
      "   1 与える\tか として\r\n",
      "   1 与える\tが て と に は は を\r\n",
      "   1 与える\tて に に は を\r\n",
      "   1 与える\tて と は を\r\n",
      "   1 与える\tは は も\r\n",
      "   1 与える\tで に を\r\n",
      "   1 与える\tも を\r\n",
      "   1 与える\tば を\r\n",
      "   1 与える\tが を\r\n",
      "   1 する\tにあたって を\r\n",
      "   1 する\tに対して は を\r\n",
      "   1 する\tについて の を\r\n",
      "   1 見る\tによって も\r\n",
      "   1 する\tに従って は\r\n",
      "   1 する\tによって は\r\n",
      "   1 する\tについて を\r\n",
      "   1 する\tにおいて を\r\n",
      "   1 見る\tに従って\r\n",
      "   1 する\tによって\r\n",
      "   1 する\tけれども\r\n",
      "   1 する\tだって なんて は や\r\n",
      "   1 する\tくらい でも\r\n",
      "   1 する\tくらい に まで\r\n",
      "   1 する\tけれど で に は を\r\n",
      "   1 する\tながら の は を\r\n",
      "   1 する\tながら に は を\r\n",
      "   1 する\tとして に は を\r\n",
      "   1 する\tとして に に を\r\n",
      "   1 する\tたって に に は\r\n",
      "   1 見る\tながら は を\r\n",
      "   1 見る\tながら に を\r\n",
      "   1 する\tながら に を\r\n",
      "   1 する\tながら に は\r\n",
      "   1 する\tとして に は\r\n",
      "   1 する\tけども て を\r\n",
      "   1 する\tくらい に を\r\n",
      "   1 する\tくらい と を\r\n",
      "   1 する\tに対し を\r\n",
      "   1 する\tなんか や\r\n",
      "   1 する\tながら は\r\n",
      "   1 する\tとして に\r\n",
      "   1 する\tだって や\r\n",
      "   1 する\tけれど を\r\n",
      "   1 する\tくらい を\r\n",
      "   1 する\tくらい も\r\n",
      "   1 する\tくらい は\r\n",
      "   1 する\tくらい と\r\n",
      "   1 見る\tなんか\r\n",
      "   1 する\tたって\r\n",
      "   1 する\tから について\r\n",
      "   1 する\tたり として に\r\n",
      "   1 する\tから ながら に\r\n",
      "   1 見る\tから ながら\r\n",
      "   1 する\tから ばかり\r\n",
      "   1 する\tから だって\r\n",
      "   1 する\tたり たり たり たり て\r\n",
      "   1 見る\tから から たり と\r\n",
      "   1 する\tって でも も を\r\n",
      "   1 する\tから って に を\r\n",
      "   1 する\tから から て を\r\n",
      "   1 する\tたり だり を\r\n",
      "   1 見る\tから んで\r\n",
      "   1 見る\tから じゃ\r\n",
      "   1 する\tから とか\r\n",
      "   1 する\tから ちゃ\r\n",
      "   1 する\tから さえ\r\n",
      "   1 する\tから から\r\n",
      "   1 する\tから と によって\r\n",
      "   1 する\tから は まで を\r\n",
      "   1 する\tから が て に ので は\r\n",
      "   1 する\tから が て に は は\r\n",
      "   1 する\tって て に は や\r\n",
      "   1 する\tから は ば も を\r\n",
      "   1 する\tから と に も を\r\n",
      "   1 する\tから と と は を\r\n",
      "   1 する\tから で に の は\r\n",
      "   1 する\tから て は は も\r\n",
      "   1 する\tから が は も を\r\n",
      "   1 する\tから が と に を\r\n",
      "   1 見る\tから て て は\r\n",
      "   1 する\tって に は を\r\n",
      "   1 する\tって て に を\r\n",
      "   1 する\tだけ て に に\r\n",
      "   1 する\tたり て は を\r\n",
      "   1 する\tたり て と を\r\n",
      "   1 する\tたり て て を\r\n",
      "   1 する\tから は は を\r\n",
      "   1 する\tから に は は\r\n",
      "   1 する\tから と は も\r\n",
      "   1 する\tから と と に\r\n",
      "   1 する\tから て も を\r\n",
      "   1 する\tから て て を\r\n",
      "   1 する\tから て て は\r\n",
      "   1 する\tから が は ば\r\n",
      "   1 する\tから が て を\r\n",
      "   1 見る\tって に を\r\n",
      "   1 見る\tたり て て\r\n",
      "   1 見る\tじゃ て に\r\n",
      "   1 見る\tから て に\r\n",
      "   1 する\tので も を\r\n",
      "   1 する\tとか ば を\r\n",
      "   1 する\tでも は を\r\n",
      "   1 する\tでも に へ\r\n",
      "   1 する\tでも に は\r\n",
      "   1 する\tでも と を\r\n",
      "   1 する\tでも と は\r\n",
      "   1 する\tって て は\r\n",
      "   1 する\tちゃ は を\r\n",
      "   1 する\tだり て て\r\n",
      "   1 する\tだけ て へ\r\n",
      "   1 する\tじゃ に に\r\n",
      "   1 する\tじゃ で も\r\n",
      "   1 する\tじゃ て を\r\n",
      "   1 する\tさえ と を\r\n",
      "   1 する\tから も を\r\n",
      "   1 する\tから は は\r\n",
      "   1 する\tから に も\r\n",
      "   1 する\tから と は\r\n",
      "   1 する\tから と に\r\n",
      "   1 する\tから て も\r\n",
      "   1 する\tから て の\r\n",
      "   1 する\tから が が\r\n",
      "   1 見る\tまで を\r\n",
      "   1 見る\tって て\r\n",
      "   1 見る\tだけ も\r\n",
      "   1 見る\tさえ て\r\n",
      "   1 見る\tから に\r\n",
      "   1 見る\tから で\r\n",
      "   1 する\tより を\r\n",
      "   1 する\tまで も\r\n",
      "   1 する\tのに ば\r\n",
      "   1 する\tので は\r\n",
      "   1 する\tにて を\r\n",
      "   1 する\tとも を\r\n",
      "   1 する\tでも の\r\n",
      "   1 する\tでも と\r\n",
      "   1 する\tって や\r\n",
      "   1 する\tって て\r\n",
      "   1 する\tだけ を\r\n",
      "   1 する\tたり も\r\n",
      "   1 する\tすら を\r\n",
      "   1 する\tじゃ で\r\n",
      "   1 する\tさえ は\r\n",
      "   1 する\tさえ に\r\n",
      "   1 する\tさえ て\r\n",
      "   1 する\tこそ を\r\n",
      "   1 する\tから ね\r\n",
      "   1 見る\tより\r\n",
      "   1 見る\tまで\r\n",
      "   1 見る\tすら\r\n",
      "   1 する\tんで\r\n",
      "   1 する\tより\r\n",
      "   1 する\tねえ\r\n",
      "   1 する\tとか\r\n",
      "   1 する\tつつ\r\n",
      "   1 する\tちゃ\r\n",
      "   1 する\tだに\r\n",
      "   1 する\tすら\r\n",
      "   1 する\tが にあたって へ\r\n",
      "   1 する\tと によって の は を\r\n",
      "   1 する\tに について は\r\n",
      "   1 する\tと において も\r\n",
      "   1 する\tが において を\r\n",
      "   1 する\tに に対して\r\n",
      "   1 する\tと において\r\n",
      "   1 する\tが によって\r\n",
      "   1 する\tが において\r\n",
      "   1 する\tが だって でも と に は\r\n",
      "   1 する\tて として に を を\r\n",
      "   1 する\tと として は も\r\n",
      "   1 する\tて と共に に の\r\n",
      "   1 する\tて として は を\r\n",
      "   1 見る\tて として に\r\n",
      "   1 する\tで と共に に\r\n",
      "   1 する\tて ながら を\r\n",
      "   1 する\tが ばかり を\r\n",
      "   1 見る\tと ながら\r\n",
      "   1 見る\tで ばかり\r\n",
      "   1 見る\tて ばかり\r\n",
      "   1 する\tて ばかり\r\n",
      "   1 する\tて なんか\r\n",
      "   1 する\tが なんか\r\n",
      "   1 する\tが ながら\r\n",
      "   1 する\tが くらい\r\n",
      "   1 する\tが こそ として\r\n",
      "   1 する\tと とも とも は\r\n",
      "   1 する\tは ほど ほど\r\n",
      "   1 する\tが だけ に は を\r\n",
      "   1 する\tが こそ で に も\r\n",
      "   1 見る\tが たり て を\r\n",
      "   1 する\tて とも は ば\r\n",
      "   1 する\tて でも と も\r\n",
      "   1 する\tが たり に に\r\n",
      "   1 する\tが ずつ て を\r\n",
      "   1 見る\tで より を\r\n",
      "   1 する\tに まで を\r\n",
      "   1 する\tに ので を\r\n",
      "   1 する\tと ので は\r\n",
      "   1 する\tと ども へ\r\n",
      "   1 する\tと とも は\r\n",
      "   1 する\tで のに は\r\n",
      "   1 する\tて ので を\r\n",
      "   1 する\tが まで を\r\n",
      "   1 する\tが でも に\r\n",
      "   1 する\tが ちゃ に\r\n",
      "   1 する\tが だけ を\r\n",
      "   1 する\tか すら と\r\n",
      "   1 する\tか から と\r\n",
      "   1 する\tか から が\r\n",
      "   1 見る\tて まで\r\n",
      "   1 見る\tて ねえ\r\n",
      "   1 見る\tて なあ\r\n",
      "   1 見る\tが ので\r\n",
      "   1 する\tへ やら\r\n",
      "   1 する\tは より\r\n",
      "   1 する\tの より\r\n",
      "   1 する\tに より\r\n",
      "   1 する\tに まで\r\n",
      "   1 する\tに ので\r\n",
      "   1 する\tと ほど\r\n",
      "   1 する\tで まで\r\n",
      "   1 する\tで ほど\r\n",
      "   1 する\tで ので\r\n",
      "   1 する\tで でも\r\n",
      "   1 する\tて なり\r\n",
      "   1 する\tて でも\r\n",
      "   1 する\tが んで\r\n",
      "   1 する\tが まで\r\n",
      "   1 する\tが ども\r\n",
      "   1 する\tが って\r\n",
      "   1 する\tが こそ\r\n",
      "   1 する\tか とも\r\n",
      "   1 する\tて と にあたって は\r\n",
      "   1 する\tか と について は を\r\n",
      "   1 する\tと に によって は\r\n",
      "   1 する\tて で において を\r\n",
      "   1 する\tが て によって を\r\n",
      "   1 する\tに は をもって\r\n",
      "   1 する\tが て において\r\n",
      "   1 する\tが と ながら は を\r\n",
      "   1 する\tが が と共に に は\r\n",
      "   1 見る\tて と ばかり\r\n",
      "   1 見る\tが て ながら\r\n",
      "   1 する\tで は ばかり\r\n",
      "   1 する\tで に ばかり\r\n",
      "   1 する\tが ね ものの\r\n",
      "   1 する\tが に ばかり\r\n",
      "   1 する\tて に のに は ばかり\r\n",
      "   1 する\tが が でも に は\r\n",
      "   1 する\tか て など は も\r\n",
      "   1 する\tて て でも を\r\n",
      "   1 する\tが と ので を\r\n",
      "   1 見る\tて て ので\r\n",
      "   1 見る\tが て んで\r\n",
      "   1 見る\tが て ので\r\n",
      "   1 する\tに は まで\r\n",
      "   1 する\tに に ほど\r\n",
      "   1 する\tと は より\r\n",
      "   1 する\tと は まで\r\n",
      "   1 する\tで に まで\r\n",
      "   1 する\tて は まで\r\n",
      "   1 する\tて に ので\r\n",
      "   1 する\tが は まで\r\n",
      "   1 する\tが に ほど\r\n",
      "   1 する\tが て まで\r\n",
      "   1 する\tが て に において\r\n",
      "   1 見る\tて ね ば ばかり まで\r\n",
      "   1 見る\tが て て ながら は\r\n",
      "   1 する\tて て と ばかり\r\n",
      "   1 する\tと は は ほど\r\n",
      "   1 する\tが と は は より\r\n",
      "   1 する\tが て に は まで\r\n",
      "   1 見る\tが て と に の は を\r\n",
      "   1 する\tて て と に は も を\r\n",
      "   1 する\tに の は へ を を\r\n",
      "   1 する\tて で と の の は\r\n",
      "   1 する\tて で と に は は\r\n",
      "   1 する\tが と と は は を\r\n",
      "   1 する\tと と に は を\r\n",
      "   1 する\tと と と は を\r\n",
      "   1 する\tて に に は を\r\n",
      "   1 する\tて に に の は\r\n",
      "   1 する\tて で は は を\r\n",
      "   1 する\tて て は は を\r\n",
      "   1 する\tて て に は を\r\n",
      "   1 する\tが ね は も を\r\n",
      "   1 する\tが に に は よ\r\n",
      "   1 する\tが で に は を\r\n",
      "   1 する\tが て に を を\r\n",
      "   1 する\tが て と は を\r\n",
      "   1 する\tが て と は も\r\n",
      "   1 する\tが て と ね は\r\n",
      "   1 する\tが て と に を\r\n",
      "   1 する\tか が で に は\r\n",
      "   1 見る\tと に に を\r\n",
      "   1 見る\tて の は を\r\n",
      "   1 見る\tて に に は\r\n",
      "   1 見る\tて で は を\r\n",
      "   1 見る\tて で と は\r\n",
      "   1 見る\tて て て は\r\n",
      "   1 する\tは は も を\r\n",
      "   1 する\tに に は は\r\n",
      "   1 する\tと に は は\r\n",
      "   1 する\tと と は は\r\n",
      "   1 する\tと と に を\r\n",
      "   1 する\tで と に は\r\n",
      "   1 する\tて は へ も\r\n",
      "   1 する\tて の へ を\r\n",
      "   1 する\tて に も を\r\n",
      "   1 する\tて に は を\r\n",
      "   1 する\tて に の は\r\n",
      "   1 する\tて に に も\r\n",
      "   1 する\tて と は も\r\n",
      "   1 する\tて と は ば\r\n",
      "   1 する\tて と と は\r\n",
      "   1 する\tて で は は\r\n",
      "   1 する\tて て へ も\r\n",
      "   1 する\tて て は を\r\n",
      "   1 する\tて て は も\r\n",
      "   1 する\tて て に を\r\n",
      "   1 する\tて て に は\r\n",
      "   1 する\tて て で を\r\n",
      "   1 する\tし に ね を\r\n",
      "   1 する\tさ と は は\r\n",
      "   1 する\tが は も も\r\n",
      "   1 する\tが に や を\r\n",
      "   1 する\tが に は も\r\n",
      "   1 する\tが に は は\r\n",
      "   1 する\tが に の は\r\n",
      "   1 する\tが と も を\r\n",
      "   1 する\tが で は を\r\n",
      "   1 する\tが で と を\r\n",
      "   1 する\tが で と に\r\n",
      "   1 する\tが で で も\r\n",
      "   1 する\tが て を を\r\n",
      "   1 する\tが て と を\r\n",
      "   1 する\tが て と へ\r\n",
      "   1 する\tが て で に\r\n",
      "   1 する\tが が の は\r\n",
      "   1 する\tか は も を\r\n",
      "   1 する\tか と と は\r\n",
      "   1 する\tか で は を\r\n",
      "   1 する\tか か が と\r\n",
      "   1 見る\tて に は\r\n",
      "   1 見る\tて と も\r\n",
      "   1 見る\tて て も\r\n",
      "   1 見る\tて て ば\r\n",
      "   1 見る\tて て と\r\n",
      "   1 見る\tて て で\r\n",
      "   1 見る\tが に を\r\n",
      "   1 見る\tが と は\r\n",
      "   1 見る\tが で を\r\n",
      "   1 見る\tが て ば\r\n",
      "   1 見る\tが て な\r\n",
      "   1 見る\tが て と\r\n",
      "   1 見る\tが て で\r\n",
      "   1 見る\tが て て\r\n",
      "   1 見る\tが が て\r\n",
      "   1 見る\tか て は\r\n",
      "   1 する\tは へ を\r\n",
      "   1 する\tは ば も\r\n",
      "   1 する\tは は を\r\n",
      "   1 する\tに ば を\r\n",
      "   1 する\tに ば も\r\n",
      "   1 する\tに は ば\r\n",
      "   1 する\tに は は\r\n",
      "   1 する\tに に も\r\n",
      "   1 する\tに に は\r\n",
      "   1 する\tと わ を\r\n",
      "   1 する\tと は も\r\n",
      "   1 する\tと な や\r\n",
      "   1 する\tと と も\r\n",
      "   1 する\tと と は\r\n",
      "   1 する\tで も を\r\n",
      "   1 する\tで も も\r\n",
      "   1 する\tで は を\r\n",
      "   1 する\tで は や\r\n",
      "   1 する\tで は も\r\n",
      "   1 する\tで は ば\r\n",
      "   1 する\tで は は\r\n",
      "   1 する\tで の を\r\n",
      "   1 する\tで に も\r\n",
      "   1 する\tで に に\r\n",
      "   1 する\tで と も\r\n",
      "   1 する\tで と に\r\n",
      "   1 する\tで で を\r\n",
      "   1 する\tて も を\r\n",
      "   1 する\tて へ を\r\n",
      "   1 する\tて は や\r\n",
      "   1 する\tて は へ\r\n",
      "   1 する\tて は は\r\n",
      "   1 する\tて に に\r\n",
      "   1 する\tて と へ\r\n",
      "   1 する\tて て も\r\n",
      "   1 する\tて て の\r\n",
      "   1 する\tて て ね\r\n",
      "   1 する\tて て に\r\n",
      "   1 する\tぜ は を\r\n",
      "   1 する\tし は を\r\n",
      "   1 する\tさ て に\r\n",
      "   1 する\tけ と を\r\n",
      "   1 する\tが を を\r\n",
      "   1 する\tが も も\r\n",
      "   1 する\tが ば を\r\n",
      "   1 する\tが は を\r\n",
      "   1 する\tが は も\r\n",
      "   1 する\tが は へ\r\n",
      "   1 する\tが の を\r\n",
      "   1 する\tが に も\r\n",
      "   1 する\tが に ば\r\n",
      "   1 する\tが と は\r\n",
      "   1 する\tが と ね\r\n",
      "   1 する\tが で と\r\n",
      "   1 する\tが て ば\r\n",
      "   1 する\tが て と\r\n",
      "   1 する\tが し も\r\n",
      "   1 する\tが が を\r\n",
      "   1 する\tが が に\r\n",
      "   1 する\tが が と\r\n",
      "   1 する\tが が で\r\n",
      "   1 する\tが が て\r\n",
      "   1 する\tが が が\r\n",
      "   1 する\tか わ を\r\n",
      "   1 する\tか は よ\r\n",
      "   1 する\tか は も\r\n",
      "   1 する\tか に を\r\n",
      "   1 する\tか に は\r\n",
      "   1 する\tか に に\r\n",
      "   1 する\tか と に\r\n",
      "   1 する\tか て は\r\n",
      "   1 する\tか て て\r\n",
      "   1 する\tか が で\r\n",
      "   1 見る\tも を\r\n",
      "   1 見る\tは も\r\n",
      "   1 見る\tは は\r\n",
      "   1 見る\tの を\r\n",
      "   1 見る\tと へ\r\n",
      "   1 見る\tで は\r\n",
      "   1 見る\tで と\r\n",
      "   1 見る\tで で\r\n",
      "   1 見る\tて で\r\n",
      "   1 見る\tし も\r\n",
      "   1 見る\tが に\r\n",
      "   1 見る\tが で\r\n",
      "   1 見る\tか で\r\n",
      "   1 見る\tか が\r\n",
      "   1 する\tわ を\r\n",
      "   1 する\tは よ\r\n",
      "   1 する\tの は\r\n",
      "   1 する\tに へ\r\n",
      "   1 する\tと の\r\n",
      "   1 する\tで ば\r\n",
      "   1 する\tで の\r\n",
      "   1 する\tし に\r\n",
      "   1 する\tさ も\r\n",
      "   1 する\tか も\r\n",
      "   1 する\tか の\r\n",
      "   1 する\tか と\r\n",
      "   1 見る\tね\r\n",
      "   1 する\tよ\r\n",
      "   1 する\tさ\r\n"
     ]
    }
   ],
   "source": [
    "# 「する」「見る」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）\n",
    "!cat out_chapter5_45.txt | grep -E '^(する|見る|与える)\\t' | sort | uniq -c | sort -rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "- 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "- 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる\n",
    "\n",
    "「吾輩はここで始めて人間というものを見た」という例文（neko.txt.cabochaの8文目）を考える． この文は「始める」と「見る」の２つの動詞を含み，「始める」に係る文節は「ここで」，「見る」に係る文節は「吾輩は」と「ものを」と解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "```\n",
    "始める  で      ここで\n",
    "見る    は を   吾輩は ものを\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_info(sentence):\n",
    "    # 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "    chunks_with_verbs = [(chunk, get_first_verb(chunk)) for chunk in sentence]\n",
    "    chunks_with_verbs = list(filter(lambda x: x[1] is not None, chunks_with_verbs))\n",
    "    \n",
    "    # 述語に係る助詞を格とする\n",
    "    # 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "    frames = [\n",
    "        (\n",
    "            verb_base, \n",
    "            [get_last_particle(sentence[i_src]) for i_src in chunk.srcs], \n",
    "            [sentence[i_src] for i_src in chunk.srcs]\n",
    "        )\n",
    "        for chunk, verb_base in chunks_with_verbs\n",
    "    ]\n",
    "    return frames\n",
    "\n",
    "with open('out_chapter5_46.txt', 'w') as f:\n",
    "    for sentence in sentences:\n",
    "        for verb, src_parts, src_chunks in extract_frame_info(sentence):\n",
    "            # 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "            # 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる\n",
    "            srcs = list(zip(src_parts, src_chunks))\n",
    "            srcs_sorted = sorted(filter(lambda src: src[0] is not None, srcs), key=lambda src: src[0])\n",
    "            if srcs_sorted:\n",
    "                src_parts, src_chunks = tuple(zip(*srcs_sorted))\n",
    "                src_chunks = list(map(lambda c: c.surface, src_chunks))\n",
    "                print(verb, ' '.join(src_parts), ' '.join(src_chunks), file=f, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生れる\tで\t　どこで\r\n",
      "つく\tか が\t生れたか 見当が\r\n",
      "泣く\tで\t所で\r\n",
      "する\tて は\t泣いて いた事だけは\r\n",
      "始める\tで\tここで\r\n",
      "見る\tは を\t吾輩は ものを\r\n",
      "聞く\tで\tあとで\r\n",
      "捕える\tを\t我々を\r\n",
      "煮る\tて\t捕えて\r\n",
      "食う\tて\t煮て\r\n"
     ]
    }
   ],
   "source": [
    "!head out_chapter5_46.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. 機能動詞構文のマイニング\n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "- 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "- 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "- 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n",
    "\n",
    "例えば「別段くるにも及ばんさと、主人は手紙に返事をする。」という文から，以下の出力が得られるはずである．\n",
    "\n",
    "```\n",
    "返事をする      と に は        及ばんさと 手紙に 主人は\n",
    "```\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "- コーパス中で頻出する述語（サ変接続名詞+を+動詞）\n",
    "- コーパス中で頻出する述語と助詞パターン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そもそも、機能動詞構文とは？がよくわからなかったのでぐぐってみた。\n",
    "\n",
    "https://www.kanjifumi.jp/keyword/kinoudousi/\n",
    "\n",
    "> 機能動詞（きのうどうし）\n",
    ">\n",
    ">「（さそいを）かける」「（連絡を）とる」「（考慮に）いれる」「（においが）する」のように実質的な意味を名詞にあずけて、みずからはもっぱら文法的な機能をはたす動詞。\n",
    "\n",
    "とのこと。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sahen_noun_plus_wo(chunk):\n",
    "    if len(chunk.morphs) != 2:\n",
    "        return False\n",
    "    return (\n",
    "        chunk.morphs[0].pos == '名詞' and\n",
    "        chunk.morphs[0].pos1 == 'サ変接続' and\n",
    "        chunk.morphs[1].surface == 'を' and\n",
    "        chunk.morphs[1].pos == '助詞'\n",
    "    )\n",
    "\n",
    "def get_pred_no47(chunk, sentence):\n",
    "    \"\"\"\n",
    "    「サ変接続名詞」+「を」が動詞にかかる場合、\n",
    "    (述語の文字列, 動詞にかかる助詞リスト(辞書順), 動詞にかかる助詞の文節リスト(助詞と同順序)) のtupleを返す。\n",
    "    条件を満たさない場合や、動詞にかかる助詞がない場合はNoneを返す。\n",
    "    \"\"\"\n",
    "    # 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "    # 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "    if not is_sahen_noun_plus_wo(chunk):\n",
    "        return None\n",
    "    if chunk.dst == -1:\n",
    "        return None\n",
    "    \n",
    "    verb_chunk = sentence[chunk.dst]\n",
    "    verb_base = get_first_verb(verb_chunk)\n",
    "    \n",
    "    if verb_base is None:\n",
    "        return None\n",
    "    \n",
    "    pred = chunk.surface + verb_base\n",
    "    \n",
    "    # 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "    # 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n",
    "    # 述語「決心をする」に「決心を」がかかっている、はカウントしたくないので、chunk自身は除外する\n",
    "    srcs = [(get_last_particle(sentence[i_src]), sentence[i_src]) for i_src in verb_chunk.srcs if sentence[i_src] is not chunk]\n",
    "    srcs_sorted = sorted(filter(lambda src: src[0] is not None, srcs), key=lambda src: src[0])\n",
    "    if not srcs_sorted:\n",
    "        return None\n",
    "    \n",
    "    src_parts, src_chunks = tuple(zip(*srcs_sorted))\n",
    "    src_chunks = list(map(lambda c: c.surface, src_chunks))\n",
    "    \n",
    "    return (pred, src_parts, src_chunks)\n",
    "\n",
    "with open('out_chapter5_47.txt', 'w') as f:\n",
    "    for sentence in sentences:\n",
    "        for chunk in sentence:\n",
    "            ret = get_pred_no47(chunk, sentence)\n",
    "            if ret is None:\n",
    "                continue\n",
    "            pred, src_parts, src_chunks = ret\n",
    "            print(pred, ' '.join(src_parts), ' '.join(src_chunks), file=f, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "決心をする\tと\tこうと\r\n",
      "返報をする\tんで\t偸んで\r\n",
      "昼寝をする\tが\t彼が\r\n",
      "迫害を加える\tて\t追い廻して\r\n",
      "投書をする\tて へ\tやって ほととぎすへ\r\n",
      "話をする\tに\t時に\r\n",
      "昼寝をする\tて\t出て\r\n",
      "欠伸をする\tから て て\tなったから、 して、 押し出して\r\n",
      "報道をする\tに\t耳に\r\n",
      "御馳走を食う\tと\t見ると\r\n"
     ]
    }
   ],
   "source": [
    "!head out_chapter5_47.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  25 返事をする\r\n",
      "  19 挨拶をする\r\n",
      "  11 話をする\r\n",
      "   8 質問をする\r\n",
      "   7 喧嘩をする\r\n",
      "   6 真似をする\r\n",
      "   5 質問をかける\r\n",
      "   5 相談をする\r\n",
      "   5 昼寝をする\r\n",
      "   4 休養を要する\r\n",
      "   4 演説をする\r\n",
      "   4 注意をする\r\n",
      "   4 欠伸をする\r\n",
      "   3 落着を告げる\r\n",
      "   3 同情を表する\r\n",
      "   3 降参をする\r\n",
      "   3 講釈をする\r\n",
      "   3 談話を聞く\r\n",
      "   3 談話をする\r\n",
      "   3 病気をする\r\n",
      "   3 決心をする\r\n",
      "   3 安心を得る\r\n",
      "   3 問答をする\r\n",
      "   2 結婚を申し込む\r\n",
      "   2 抗議を申し込む\r\n",
      "   2 一段落を告げる\r\n",
      "   2 いたずらをする\r\n",
      "   2 迫害を加える\r\n",
      "   2 話をつづける\r\n",
      "   2 思案を定める\r\n",
      "   2 往来をあるく\r\n",
      "   2 宙返りをする\r\n",
      "   2 刺激を与える\r\n",
      "   2 逆上をする\r\n",
      "   2 議論をする\r\n",
      "   2 講義をする\r\n",
      "   2 談判を聞く\r\n",
      "   2 観察を怠る\r\n",
      "   2 覚悟をする\r\n",
      "   2 行水を使う\r\n",
      "   2 自炊をする\r\n",
      "   2 自殺をする\r\n",
      "   2 経験をする\r\n",
      "   2 約束をする\r\n",
      "   2 放蕩をする\r\n",
      "   2 掃除をする\r\n",
      "   2 座禅をする\r\n",
      "   2 同情を表す\r\n",
      "   2 出所をする\r\n",
      "   2 修行をする\r\n",
      "   2 体操をする\r\n",
      "   2 話を聞く\r\n",
      "   2 撰をする\r\n",
      "   2 噂をする\r\n",
      "   1 ストライキをしでかす\r\n",
      "   1 相談を持ちかける\r\n",
      "   1 御馳走を食わせる\r\n",
      "   1 ストライキを起す\r\n",
      "   1 いたずらを始める\r\n",
      "   1 震動をはじめる\r\n",
      "   1 降参を申し込む\r\n",
      "   1 道楽をすすめる\r\n",
      "   1 遊戯をくだける\r\n",
      "   1 逆上を重んずる\r\n",
      "   1 談話をつづける\r\n",
      "   1 行水を見下ろす\r\n",
      "   1 御馳走をあるく\r\n",
      "   1 変化をあらわす\r\n",
      "   1 呼吸を飲み込む\r\n",
      "   1 北面を取り囲む\r\n",
      "   1 催促をしてやる\r\n",
      "   1 仲間入りをする\r\n",
      "   1 仕事を片付ける\r\n",
      "   1 いたずらを書く\r\n",
      "   1 鞭撻を加える\r\n",
      "   1 随行を命ずる\r\n",
      "   1 関係をつける\r\n",
      "   1 鑑定をつける\r\n",
      "   1 酷評を加える\r\n",
      "   1 運動を始める\r\n",
      "   1 逆戻りをする\r\n",
      "   1 退去を命ずる\r\n",
      "   1 身震いをする\r\n",
      "   1 質問を受ける\r\n",
      "   1 賛成を求める\r\n",
      "   1 議論を始める\r\n",
      "   1 説法を受ける\r\n",
      "   1 説明を与える\r\n",
      "   1 註釈を加える\r\n",
      "   1 註釈をつける\r\n",
      "   1 診察を始める\r\n",
      "   1 診察を受ける\r\n",
      "   1 訪問を受ける\r\n",
      "   1 訓練を与える\r\n",
      "   1 訓戒を垂れる\r\n",
      "   1 訓戒を加える\r\n",
      "   1 訓戒を与える\r\n",
      "   1 観察を述べる\r\n",
      "   1 観察を始める\r\n",
      "   1 襲撃を受ける\r\n",
      "   1 絞殺を用いる\r\n",
      "   1 祈念をこらす\r\n",
      "   1 研究を要する\r\n",
      "   1 研究を続ける\r\n",
      "   1 由来を案ずる\r\n",
      "   1 猶予を与える\r\n",
      "   1 演説をなする\r\n",
      "   1 満足を求める\r\n",
      "   1 清聴を煩わす\r\n",
      "   1 深入りをする\r\n",
      "   1 治療をうける\r\n",
      "   1 朝食を済ます\r\n",
      "   1 晩酌を始める\r\n",
      "   1 早合点をする\r\n",
      "   1 敬意を表する\r\n",
      "   1 摩擦を与える\r\n",
      "   1 掃除を始める\r\n",
      "   1 批評を加える\r\n",
      "   1 我慢を重ねる\r\n",
      "   1 我儘を尽くす\r\n",
      "   1 慰安を求める\r\n",
      "   1 意味を究める\r\n",
      "   1 意味をつける\r\n",
      "   1 忠告を加える\r\n",
      "   1 心配を掛ける\r\n",
      "   1 御馳走を食う\r\n",
      "   1 御馳走を致す\r\n",
      "   1 御馳走を来る\r\n",
      "   1 御馳走をする\r\n",
      "   1 待ったをする\r\n",
      "   1 影響を与える\r\n",
      "   1 形容をなさる\r\n",
      "   1 差別を立てる\r\n",
      "   1 居眠りをする\r\n",
      "   1 小便をかける\r\n",
      "   1 尊敬を受ける\r\n",
      "   1 安心を欲する\r\n",
      "   1 存在を認める\r\n",
      "   1 始末をつける\r\n",
      "   1 失望を受取る\r\n",
      "   1 大発見をなす\r\n",
      "   1 大息を洩らす\r\n",
      "   1 変調を極める\r\n",
      "   1 変化を起こす\r\n",
      "   1 変化を生ずる\r\n",
      "   1 変化を生じる\r\n",
      "   1 変化を求める\r\n",
      "   1 喧嘩を始める\r\n",
      "   1 同情を求める\r\n",
      "   1 同情を寄せる\r\n",
      "   1 厚遇を受ける\r\n",
      "   1 協商を始める\r\n",
      "   1 区劃を立てる\r\n",
      "   1 制裁を加える\r\n",
      "   1 処分を受ける\r\n",
      "   1 依頼をうける\r\n",
      "   1 休養を欲する\r\n",
      "   1 代理を勤める\r\n",
      "   1 代理を務める\r\n",
      "   1 電話を切る\r\n",
      "   1 雑談をする\r\n",
      "   1 関係をする\r\n",
      "   1 間食をする\r\n",
      "   1 遠慮をする\r\n",
      "   1 遠征をする\r\n",
      "   1 道楽をする\r\n",
      "   1 運動をする\r\n",
      "   1 遊弋をする\r\n",
      "   1 速断をやる\r\n",
      "   1 通行をする\r\n",
      "   1 逆上をがる\r\n",
      "   1 返答をする\r\n",
      "   1 返報をする\r\n",
      "   1 返事を聞く\r\n",
      "   1 返事を承る\r\n",
      "   1 返事を待つ\r\n",
      "   1 近道を通る\r\n",
      "   1 辞職をする\r\n",
      "   1 質問をえる\r\n",
      "   1 講釈を聞く\r\n",
      "   1 講話を聞く\r\n",
      "   1 講話をする\r\n",
      "   1 講義を行く\r\n",
      "   1 講義をきく\r\n",
      "   1 談話を承る\r\n",
      "   1 談話を分る\r\n",
      "   1 談笑をする\r\n",
      "   1 談判をする\r\n",
      "   1 調和を計る\r\n",
      "   1 説教をやる\r\n",
      "   1 説教をする\r\n",
      "   1 話を進める\r\n",
      "   1 話を切らす\r\n",
      "   1 話をなさる\r\n",
      "   1 試験をする\r\n",
      "   1 診断をする\r\n",
      "   1 許諾を至る\r\n",
      "   1 計算をする\r\n",
      "   1 観察を積む\r\n",
      "   1 見物をする\r\n",
      "   1 要求をする\r\n",
      "   1 製造を負う\r\n",
      "   1 行動をする\r\n",
      "   1 虐待をする\r\n",
      "   1 著述を居る\r\n",
      "   1 苦笑をする\r\n",
      "   1 苦心を買う\r\n",
      "   1 苦心をする\r\n",
      "   1 苦労をする\r\n",
      "   1 芝居をする\r\n",
      "   1 自覚を与る\r\n",
      "   1 脱線をする\r\n",
      "   1 胡坐をかく\r\n",
      "   1 絞殺をする\r\n",
      "   1 結婚をする\r\n",
      "   1 答弁を得る\r\n",
      "   1 競争をやる\r\n",
      "   1 立見をする\r\n",
      "   1 研究をやる\r\n",
      "   1 研究をする\r\n",
      "   1 矛盾をする\r\n",
      "   1 真似をやる\r\n",
      "   1 相談を開く\r\n",
      "   1 発達を致す\r\n",
      "   1 発展をする\r\n",
      "   1 火傷をする\r\n",
      "   1 沈黙を守る\r\n",
      "   1 水泳をやる\r\n",
      "   1 案内を頼む\r\n",
      "   1 案内を乞う\r\n",
      "   1 暴行をする\r\n",
      "   1 早死をする\r\n",
      "   1 旅行をする\r\n",
      "   1 散歩をする\r\n",
      "   1 教育をくる\r\n",
      "   1 故障を挟む\r\n",
      "   1 支度をする\r\n",
      "   1 探偵を比す\r\n",
      "   1 投書をする\r\n",
      "   1 戦闘をする\r\n",
      "   1 戦争を挑む\r\n",
      "   1 戦争をなす\r\n",
      "   1 戦争をする\r\n",
      "   1 我儘をする\r\n",
      "   1 懐中を抜く\r\n",
      "   1 意味を示す\r\n",
      "   1 想像をする\r\n",
      "   1 情死をする\r\n",
      "   1 息を凝らす\r\n",
      "   1 息を入れる\r\n",
      "   1 怪我をする\r\n",
      "   1 怒号をする\r\n",
      "   1 復讐をやる\r\n",
      "   1 復讐をとる\r\n",
      "   1 後悔をする\r\n",
      "   1 往来を通る\r\n",
      "   1 弁護をする\r\n",
      "   1 弁論をする\r\n",
      "   1 広告を出す\r\n",
      "   1 平均を保つ\r\n",
      "   1 左右を見る\r\n",
      "   1 小便をする\r\n",
      "   1 尊敬を払う\r\n",
      "   1 対面をする\r\n",
      "   1 対談をする\r\n",
      "   1 対話を聞く\r\n",
      "   1 定義をする\r\n",
      "   1 安心を求む\r\n",
      "   1 学問をする\r\n",
      "   1 妨害をする\r\n",
      "   1 奉職をする\r\n",
      "   1 失礼を致す\r\n",
      "   1 失礼をする\r\n",
      "   1 失恋をする\r\n",
      "   1 外出をする\r\n",
      "   1 報道を逢う\r\n",
      "   1 報道をする\r\n",
      "   1 嘆願をする\r\n",
      "   1 嘆息をする\r\n",
      "   1 喧嘩を買う\r\n",
      "   1 喧嘩を譲る\r\n",
      "   1 喧嘩を見る\r\n",
      "   1 喧嘩を思う\r\n",
      "   1 問答をやる\r\n",
      "   1 告訴をする\r\n",
      "   1 吶喊を喰う\r\n",
      "   1 含嗽をやる\r\n",
      "   1 同情を錬る\r\n",
      "   1 同情を起す\r\n",
      "   1 同情を持つ\r\n",
      "   1 同情をする\r\n",
      "   1 同宿をする\r\n",
      "   1 合奏をする\r\n",
      "   1 合図をする\r\n",
      "   1 反響を起す\r\n",
      "   1 反応を呈す\r\n",
      "   1 反応をする\r\n",
      "   1 午睡をする\r\n",
      "   1 勘定をする\r\n",
      "   1 勉強をする\r\n",
      "   1 制裁をする\r\n",
      "   1 判断をする\r\n",
      "   1 写生を力む\r\n",
      "   1 写生をする\r\n",
      "   1 倹約をする\r\n",
      "   1 修養を力む\r\n",
      "   1 修養をやる\r\n",
      "   1 依頼をする\r\n",
      "   1 供給を仰ぐ\r\n",
      "   1 位置をする\r\n",
      "   1 会釈をする\r\n",
      "   1 休養を得る\r\n",
      "   1 休養を乞う\r\n",
      "   1 仕事をする\r\n",
      "   1 交際をする\r\n",
      "   1 了見を起す\r\n",
      "   1 了見を抱く\r\n",
      "   1 乱暴を働く\r\n",
      "   1 乱暴をかく\r\n",
      "   1 不足を云う\r\n",
      "   1 下宿を出る\r\n",
      "   1 下宿をする\r\n",
      "   1 賭をする\r\n",
      "   1 算を乱す\r\n",
      "   1 息をつく\r\n",
      "   1 息をする\r\n"
     ]
    }
   ],
   "source": [
    "# コーパス中で頻出する述語（サ変接続名詞+を+動詞）\n",
    "!cat out_chapter5_47.txt | cut -f 1 | sort | uniq -c | sort -rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6 返事をする\tと\r\n",
      "   4 挨拶をする\tから\r\n",
      "   4 返事をする\tと は\r\n",
      "   4 挨拶をする\tと\r\n",
      "   3 質問をかける\tと は\r\n",
      "   3 喧嘩をする\tと\r\n",
      "   2 同情を表する\tて と は\r\n",
      "   2 休養を要する\tは\r\n",
      "   2 返事をする\tから と\r\n",
      "   2 挨拶をする\tと も\r\n",
      "   2 議論をする\tて\r\n",
      "   2 講義をする\tで\r\n",
      "   2 覚悟をする\tと\r\n",
      "   2 挨拶をする\tで\r\n",
      "   2 安心を得る\tが\r\n",
      "   1 ストライキをしでかす\tから て\r\n",
      "   1 御馳走を食わせる\tから て に\r\n",
      "   1 ストライキを起す\tが て に\r\n",
      "   1 相談を持ちかける\tに は\r\n",
      "   1 いたずらを始める\tて は\r\n",
      "   1 御馳走をあるく\tって て\r\n",
      "   1 呼吸を飲み込む\tから\r\n",
      "   1 北面を取り囲む\tて として に は\r\n",
      "   1 降参を申し込む\tて と ながら は\r\n",
      "   1 結婚を申し込む\tぜ で に に\r\n",
      "   1 談話をつづける\tて と は\r\n",
      "   1 行水を見下ろす\tて と と\r\n",
      "   1 震動をはじめる\tが に\r\n",
      "   1 抗議を申し込む\tが と\r\n",
      "   1 抗議を申し込む\tが て\r\n",
      "   1 仕事を片付ける\tと へ\r\n",
      "   1 一段落を告げる\tで も\r\n",
      "   1 いたずらをする\tで は\r\n",
      "   1 道楽をすすめる\tに\r\n",
      "   1 遊戯をくだける\tに\r\n",
      "   1 逆上を重んずる\tで\r\n",
      "   1 結婚を申し込む\tに\r\n",
      "   1 変化をあらわす\tに\r\n",
      "   1 催促をしてやる\tて\r\n",
      "   1 仲間入りをする\tて\r\n",
      "   1 一段落を告げる\tが\r\n",
      "   1 いたずらを書く\tも\r\n",
      "   1 いたずらをする\tて\r\n",
      "   1 掃除を始める\tによって は\r\n",
      "   1 尊敬を受ける\tとして も より\r\n",
      "   1 絞殺を用いる\tとして\r\n",
      "   1 存在を認める\tから まで\r\n",
      "   1 鞭撻を加える\tから て て は ば\r\n",
      "   1 関係をつける\tから で と も\r\n",
      "   1 清聴を煩わす\tから て\r\n",
      "   1 晩酌を始める\tから て\r\n",
      "   1 小便をかける\tから に\r\n",
      "   1 宙返りをする\tから が\r\n",
      "   1 休養を要する\tども に\r\n",
      "   1 迫害を加える\tから\r\n",
      "   1 質問を受ける\tすら\r\n",
      "   1 観察を始める\tから\r\n",
      "   1 思案を定める\tまで\r\n",
      "   1 御馳走をする\tにて\r\n",
      "   1 待ったをする\tから\r\n",
      "   1 同情を寄せる\tから\r\n",
      "   1 制裁を加える\tので\r\n",
      "   1 大息を洩らす\tと として は\r\n",
      "   1 同情を求める\tと ながら に\r\n",
      "   1 厚遇を受ける\tが まで\r\n",
      "   1 早合点をする\tが と ので\r\n",
      "   1 摩擦を与える\tが て と に は は\r\n",
      "   1 鑑定をつける\tと に は は\r\n",
      "   1 酷評を加える\tが と は\r\n",
      "   1 説明を与える\tて と は\r\n",
      "   1 訓練を与える\tて に は\r\n",
      "   1 祈念をこらす\tと に に\r\n",
      "   1 宙返りをする\tが と は\r\n",
      "   1 変化を生ずる\tに の を\r\n",
      "   1 区劃を立てる\tで と へ\r\n",
      "   1 休養を要する\tと に は\r\n",
      "   1 退去を命ずる\tて に\r\n",
      "   1 身震いをする\tて は\r\n",
      "   1 質問をかける\tに は\r\n",
      "   1 質問をかける\tが と\r\n",
      "   1 議論を始める\tで は\r\n",
      "   1 話をつづける\tは も\r\n",
      "   1 註釈を加える\tが と\r\n",
      "   1 註釈をつける\tと の\r\n",
      "   1 観察を述べる\tが で\r\n",
      "   1 落着を告げる\tと は\r\n",
      "   1 落着を告げる\tで は\r\n",
      "   1 研究を要する\tが で\r\n",
      "   1 研究を続ける\tて て\r\n",
      "   1 演説をなする\tで ば\r\n",
      "   1 満足を求める\tて は\r\n",
      "   1 治療をうける\tは も\r\n",
      "   1 朝食を済ます\tて に\r\n",
      "   1 批評を加える\tが と\r\n",
      "   1 思案を定める\tと は\r\n",
      "   1 忠告を加える\tと に\r\n",
      "   1 心配を掛ける\tて は\r\n",
      "   1 往来をあるく\tが て\r\n",
      "   1 差別を立てる\tは も\r\n",
      "   1 変化を起こす\tて に\r\n",
      "   1 変化を生じる\tと に\r\n",
      "   1 喧嘩を始める\tは を\r\n",
      "   1 刺激を与える\tで に\r\n",
      "   1 刺激を与える\tて に\r\n",
      "   1 随行を命ずる\tへ\r\n",
      "   1 運動を始める\tは\r\n",
      "   1 逆戻りをする\tに\r\n",
      "   1 迫害を加える\tて\r\n",
      "   1 賛成を求める\tて\r\n",
      "   1 説法を受ける\tて\r\n",
      "   1 話をつづける\tは\r\n",
      "   1 診察を始める\tと\r\n",
      "   1 診察を受ける\tて\r\n",
      "   1 訪問を受ける\tも\r\n",
      "   1 訓戒を垂れる\tに\r\n",
      "   1 訓戒を加える\tに\r\n",
      "   1 訓戒を与える\tに\r\n",
      "   1 襲撃を受ける\tに\r\n",
      "   1 落着を告げる\tて\r\n",
      "   1 由来を案ずる\tて\r\n",
      "   1 猶予を与える\tに\r\n",
      "   1 深入りをする\tは\r\n",
      "   1 敬意を表する\tに\r\n",
      "   1 我慢を重ねる\tに\r\n",
      "   1 我儘を尽くす\tに\r\n",
      "   1 慰安を求める\tに\r\n",
      "   1 意味を究める\tて\r\n",
      "   1 意味をつける\tは\r\n",
      "   1 御馳走を食う\tと\r\n",
      "   1 御馳走を致す\tに\r\n",
      "   1 御馳走を来る\tで\r\n",
      "   1 往来をあるく\tて\r\n",
      "   1 影響を与える\tに\r\n",
      "   1 形容をなさる\tに\r\n",
      "   1 居眠りをする\tて\r\n",
      "   1 安心を欲する\tも\r\n",
      "   1 始末をつける\tで\r\n",
      "   1 失望を受取る\tに\r\n",
      "   1 大発見をなす\tに\r\n",
      "   1 変調を極める\tに\r\n",
      "   1 変化を求める\tて\r\n",
      "   1 同情を表する\tに\r\n",
      "   1 協商を始める\tは\r\n",
      "   1 処分を受ける\tて\r\n",
      "   1 依頼をうける\tで\r\n",
      "   1 休養を欲する\tは\r\n",
      "   1 代理を勤める\tに\r\n",
      "   1 代理を務める\tは\r\n",
      "   1 相談をする\tに対して は\r\n",
      "   1 問答をする\tについて の\r\n",
      "   1 答弁を得る\tに対して\r\n",
      "   1 研究をする\tについて\r\n",
      "   1 喧嘩を思う\tによって\r\n",
      "   1 写生を力む\tに従って\r\n",
      "   1 雑談をする\tながら は\r\n",
      "   1 立見をする\tながら は\r\n",
      "   1 矛盾をする\tくらい と\r\n",
      "   1 演説をする\tけども て\r\n",
      "   1 沈黙を守る\tくらい も\r\n",
      "   1 想像をする\tながら\r\n",
      "   1 怒号をする\tばかり\r\n",
      "   1 後悔をする\tけれど\r\n",
      "   1 近道を通る\tから のに\r\n",
      "   1 嘆息をする\tたり だり\r\n",
      "   1 返事をする\tから が と に\r\n",
      "   1 経験をする\tから が は も\r\n",
      "   1 降参をする\tから と は\r\n",
      "   1 遊弋をする\tから て で\r\n",
      "   1 欠伸をする\tから て て\r\n",
      "   1 案内を乞う\tから で と\r\n",
      "   1 同宿をする\tから と は\r\n",
      "   1 勉強をする\tたり て と\r\n",
      "   1 交際をする\tから て は\r\n",
      "   1 返事をする\tから て\r\n",
      "   1 診断をする\tから も\r\n",
      "   1 相談をする\tから は\r\n",
      "   1 喧嘩をする\tから が\r\n",
      "   1 出所をする\tでも と\r\n",
      "   1 修養をやる\tから て\r\n",
      "   1 位置をする\tとか ば\r\n",
      "   1 乱暴をかく\tから て\r\n",
      "   1 降参をする\tから\r\n",
      "   1 運動をする\tから\r",
      "\r\n",
      "   1 返報をする\tんで\r\n",
      "   1 質問をする\tから\r\n",
      "   1 講釈を聞く\tから\r\n",
      "   1 講義をきく\tから\r\n",
      "   1 談話を分る\tまで\r\n",
      "   1 調和を計る\tから\r\n",
      "   1 見物をする\tって\r\n",
      "   1 苦心をする\tから\r\n",
      "   1 苦労をする\tたり\r\n",
      "   1 自殺をする\tたり\r\n",
      "   1 絞殺をする\tから\r\n",
      "   1 発展をする\tまで\r\n",
      "   1 病気をする\tから\r\n",
      "   1 戦闘をする\tんで\r\n",
      "   1 座禅をする\tまで\r\n",
      "   1 外出をする\tでも\r\n",
      "   1 嘆願をする\tまで\r\n",
      "   1 告訴をする\tから\r\n",
      "   1 写生をする\tから\r\n",
      "   1 修養を力む\tから\r\n",
      "   1 修行をする\tから\r\n",
      "   1 体操をする\tから\r\n",
      "   1 挨拶をする\tと によって の は\r\n",
      "   1 談話をする\tて ながら\r\n",
      "   1 報道を逢う\tて として\r\n",
      "   1 了見を起す\tと ながら\r\n",
      "   1 遠征をする\tに まで\r\n",
      "   1 著述を居る\tて より\r\n",
      "   1 演説をする\tで でも\r\n",
      "   1 挨拶をする\tて ので\r\n",
      "   1 下宿を出る\tて ので\r\n",
      "   1 弁論をする\tか と について は\r\n",
      "   1 平均を保つ\tか か やいなや\r\n",
      "   1 返事を承る\tて で ながら\r\n",
      "   1 談笑をする\tて て と に は も\r\n",
      "   1 逆上をする\tに の は へ を\r\n",
      "   1 談判を聞く\tが で と に は\r\n",
      "   1 返答をする\tが て と は\r\n",
      "   1 返事をする\tと と に は\r\n",
      "   1 返事をする\tと と と は\r\n",
      "   1 講義を行く\tて て て に\r\n",
      "   1 対談をする\tが て と に\r\n",
      "   1 休養を乞う\tて に は は\r\n",
      "   1 逆上をする\tて と は\r\n",
      "   1 返事をする\tと に は\r\n",
      "   1 返事をする\tで と は\r\n",
      "   1 質問をする\tと に は\r\n",
      "   1 質問をする\tが と は\r\n",
      "   1 講釈をする\tか は も\r\n",
      "   1 説教をやる\tで と は\r\n",
      "   1 話を進める\tで と は\r\n",
      "   1 計算をする\tて で は\r\n",
      "   1 行水を使う\tが に は\r\n",
      "   1 行水を使う\tが で に\r\n",
      "   1 苦心を買う\tが が と\r\n",
      "   1 経験をする\tに は ば\r\n",
      "   1 真似をやる\tて と は\r\n",
      "   1 真似をする\tが と も\r\n",
      "   1 発達を致す\tが て は\r\n",
      "   1 注意をする\tと に は\r\n",
      "   1 水泳をやる\tて と は\r\n",
      "   1 欠伸をする\tと に は\r\n",
      "   1 欠伸をする\tて て と\r\n",
      "   1 昼寝をする\tて と は\r\n",
      "   1 掃除をする\tと に は\r\n",
      "   1 挨拶をする\tで と は\r\n",
      "   1 挨拶をする\tて と は\r\n",
      "   1 挨拶をする\tが て と\r\n",
      "   1 復讐をとる\tと に は\r\n",
      "   1 失礼を致す\tて は は\r\n",
      "   1 同情を表す\tと に は\r\n",
      "   1 反応を呈す\tか と も\r\n",
      "   1 速断をやる\tと に\r\n",
      "   1 通行をする\tて は\r\n",
      "   1 返事をする\tと に\r\n",
      "   1 返事をする\tて と\r\n",
      "   1 返事をする\tが と\r\n",
      "   1 辞職をする\tが に\r\n",
      "   1 質問をする\tて は\r\n",
      "   1 質問をする\tが て\r\n",
      "   1 講釈をする\tか わ\r\n",
      "   1 講話を聞く\tが に\r\n",
      "   1 講話をする\tて は\r\n",
      "   1 談判をする\tが と\r\n",
      "   1 許諾を至る\tて を\r\n",
      "   1 苦笑をする\tと は\r\n",
      "   1 自炊をする\tで に\r\n",
      "   1 自炊をする\tが で\r\n",
      "   1 脱線をする\tが に\r\n",
      "   1 競争をやる\tで ば\r\n",
      "   1 研究をやる\tて は\r\n",
      "   1 真似をする\tと も\r\n",
      "   1 真似をする\tが で\r\n",
      "   1 相談を開く\tで も\r\n",
      "   1 相談をする\tが で\r\n",
      "   1 病気をする\tが も\r\n",
      "   1 注意をする\tて と\r\n",
      "   1 注意をする\tが に\r\n",
      "   1 欠伸をする\tが と\r\n",
      "   1 暴行をする\tが に\r\n",
      "   1 昼寝をする\tが へ\r\n",
      "   1 挨拶をする\tと は\r\n",
      "   1 投書をする\tて へ\r\n",
      "   1 戦争を挑む\tに に\r\n",
      "   1 意味を示す\tと は\r\n",
      "   1 息を入れる\tて で\r\n",
      "   1 復讐をやる\tと は\r\n",
      "   1 座禅をする\tで で\r\n",
      "   1 小便をする\tて は\r\n",
      "   1 尊敬を払う\tて に\r\n",
      "   1 妨害をする\tが と\r\n",
      "   1 奉職をする\tが へ\r\n",
      "   1 喧嘩を買う\tで と\r\n",
      "   1 喧嘩をする\tで に\r\n",
      "   1 問答をする\tと は\r\n",
      "   1 同情をする\tて に\r\n",
      "   1 合奏をする\tと に\r\n",
      "   1 合図をする\tて と\r\n",
      "   1 制裁をする\tて に\r\n",
      "   1 判断をする\tと は\r\n",
      "   1 依頼をする\tと は\r\n",
      "   1 体操をする\tが に\r\n",
      "   1 休養を得る\tに は\r\n",
      "   1 仕事をする\tし は\r\n",
      "   1 下宿をする\tが に\r\n",
      "   1 電話を切る\tと\r\n",
      "   1 降参をする\tと\r\n",
      "   1 関係をする\tに\r\n",
      "   1 間食をする\tで\r\n",
      "   1 遠慮をする\tに\r\n",
      "   1 道楽をする\tて\r\n",
      "   1 逆上をがる\tて\r\n",
      "   1 返事を聞く\tで\r\n",
      "   1 返事を待つ\tて\r\n",
      "   1 返事をする\tも\r\n",
      "   1 返事をする\tへ\r\n",
      "   1 返事をする\tは\r\n",
      "   1 返事をする\tて\r\n",
      "   1 質問をする\tね\r\n",
      "   1 質問をする\tと\r\n",
      "   1 質問をする\tが\r\n",
      "   1 質問をえる\tで\r\n",
      "   1 講釈をする\tね\r\n",
      "   1 談話を聞く\tは\r\n",
      "   1 談話を聞く\tで\r\n",
      "   1 談話を聞く\tが\r\n",
      "   1 談話を承る\tて\r\n",
      "   1 談話をする\tに\r\n",
      "   1 談話をする\tが\r\n",
      "   1 談判を聞く\tで\r\n",
      "   1 説教をする\tて\r\n",
      "   1 話を切らす\tて\r\n",
      "   1 話をなさる\tが\r\n",
      "   1 試験をする\tに\r\n",
      "   1 観察を積む\tが\r\n",
      "   1 観察を怠る\tな\r\n",
      "   1 観察を怠る\tて\r\n",
      "   1 要求をする\tと\r\n",
      "   1 製造を負う\tで\r\n",
      "   1 行動をする\tが\r\n",
      "   1 虐待をする\tて\r\n",
      "   1 芝居をする\tで\r\n",
      "   1 自覚を与る\tに\r\n",
      "   1 自殺をする\tに\r\n",
      "   1 胡坐をかく\tで\r\n",
      "   1 結婚をする\tて\r\n",
      "   1 約束をする\tに\r\n",
      "   1 約束をする\tて\r\n",
      "   1 真似をする\tは\r\n",
      "   1 真似をする\tに\r\n",
      "   1 真似をする\tで\r\n",
      "   1 相談をする\tと\r\n",
      "   1 相談をする\tて\r\n",
      "   1 病気をする\tで\r\n",
      "   1 火傷をする\tと\r\n",
      "   1 演説をする\tに\r\n",
      "   1 演説をする\tで\r\n",
      "   1 注意をする\tで\r\n",
      "   1 決心をする\tに\r\n",
      "   1 決心をする\tと\r\n",
      "   1 決心をする\tが\r\n",
      "   1 案内を頼む\tが\r\n",
      "   1 昼寝をする\tで\r\n",
      "   1 昼寝をする\tて\r\n",
      "   1 昼寝をする\tが\r\n",
      "   1 早死をする\tは\r\n",
      "   1 旅行をする\tて\r\n",
      "   1 散歩をする\tに\r\n",
      "   1 教育をくる\tで\r\n",
      "   1 故障を挟む\tに\r\n",
      "   1 放蕩をする\tも\r\n",
      "   1 放蕩をする\tが\r\n",
      "   1 支度をする\tと\r\n",
      "   1 探偵を比す\tに\r\n",
      "   1 掃除をする\tへ\r\n",
      "   1 挨拶をする\tて\r\n",
      "   1 戦争をなす\tに\r\n",
      "   1 戦争をする\tと\r\n",
      "   1 我儘をする\tが\r\n",
      "   1 懐中を抜く\tに\r\n",
      "   1 情死をする\tと\r\n",
      "   1 息を凝らす\tて\r\n",
      "   1 怪我をする\tて\r\n",
      "   1 往来を通る\tと\r\n",
      "   1 弁護をする\tと\r\n",
      "   1 広告を出す\tば\r\n",
      "   1 左右を見る\tに\r\n",
      "   1 対面をする\tと\r\n",
      "   1 対話を聞く\tで\r\n",
      "   1 定義をする\tて\r\n",
      "   1 安心を求む\tに\r\n",
      "   1 安心を得る\tで\r\n",
      "   1 学問をする\tて\r\n",
      "   1 失礼をする\tが\r\n",
      "   1 失恋をする\tて\r\n",
      "   1 報道をする\tに\r\n",
      "   1 喧嘩を譲る\tに\r\n",
      "   1 喧嘩を見る\tと\r\n",
      "   1 喧嘩をする\tも\r\n",
      "   1 喧嘩をする\tで\r\n",
      "   1 問答をやる\tで\r\n",
      "   1 問答をする\tは\r\n",
      "   1 吶喊を喰う\tと\r\n",
      "   1 含嗽をやる\tで\r\n",
      "   1 同情を錬る\tに\r\n",
      "   1 同情を起す\tて\r\n",
      "   1 同情を表す\tに\r\n",
      "   1 同情を持つ\tに\r\n",
      "   1 反響を起す\tが\r\n",
      "   1 反応をする\tも\r\n",
      "   1 午睡をする\tて\r\n",
      "   1 勘定をする\tて\r\n",
      "   1 出所をする\tに\r\n",
      "   1 倹約をする\tと\r\n",
      "   1 修行をする\tて\r\n",
      "   1 供給を仰ぐ\tも\r\n",
      "   1 会釈をする\tに\r\n",
      "   1 了見を抱く\tと\r\n",
      "   1 乱暴を働く\tて\r\n",
      "   1 不足を云う\tで\r\n",
      "   1 話を聞く\tとして に まで\r\n",
      "   1 撰をする\tけれど で に は\r\n",
      "   1 話をする\tながら\r\n",
      "   1 話をする\tって でも も\r\n",
      "   1 息をする\tから と と は\r\n",
      "   1 話をする\tたり て は\r\n",
      "   1 撰をする\tから が て\r\n",
      "   1 話をする\tから に\r\n",
      "   1 賭をする\tから\r\n",
      "   1 噂をする\tまで\r\n",
      "   1 話をする\tて と\r\n",
      "   1 話をする\tか は\r\n",
      "   1 話をする\tか て\r\n",
      "   1 息をつく\tと は\r\n",
      "   1 噂をする\tが に\r\n",
      "   1 話を聞く\tは\r\n",
      "   1 話をする\tは\r\n",
      "   1 話をする\tに\r\n",
      "   1 話をする\tと\r\n",
      "   1 話をする\tて\r\n",
      "   1 算を乱す\tが\r\n"
     ]
    }
   ],
   "source": [
    "# コーパス中で頻出する述語と助詞パターン\n",
    "!cat out_chapter5_47.txt | cut -f 1,2 | sort | uniq -c | sort -rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. 名詞から根へのパスの抽出\n",
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 各文節は（表層形の）形態素列で表現する\n",
    "- パスの開始文節から終了文節に至るまで，各文節の表現を \"`->`\" で連結する\n",
    "\n",
    "「吾輩はここで始めて人間というものを見た」という文（neko.txt.cabochaの8文目）から，次のような出力が得られるはずである．\n",
    "\n",
    "```\n",
    "吾輩は -> 見た\n",
    "ここで -> 始めて -> 人間という -> ものを -> 見た\n",
    "人間という -> ものを -> 見た\n",
    "ものを -> 見た\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_path(chunk, sentence, carry):\n",
    "    carry.append(chunk.wo_signs().surface)\n",
    "    if chunk.dst == -1:\n",
    "        return carry\n",
    "    else:\n",
    "        return walk_path(sentence[chunk.dst], sentence, carry)    \n",
    "\n",
    "paths = []\n",
    "for sentence in sentences:\n",
    "    for chunk in sentence:\n",
    "        if '名詞' not in map(lambda m: m.pos, chunk.morphs):\n",
    "            continue\n",
    "        paths.append(walk_path(chunk, sentence, []))\n",
    "\n",
    "with open('out_chapter5_48.txt', 'w') as f:\n",
    "    for path in paths:\n",
    "        print(*path, sep=' -> ', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一\r\n",
      "吾輩は -> 猫である\r\n",
      "猫である\r\n",
      "名前は -> 無い\r\n",
      "どこで -> 生れたか -> つかぬ\r\n",
      "見当が -> つかぬ\r\n",
      "何でも -> 薄暗い -> 所で -> 泣いて -> 記憶している\r\n",
      "所で -> 泣いて -> 記憶している\r\n",
      "ニャーニャー -> 泣いて -> 記憶している\r\n",
      "いた事だけは -> 記憶している\r\n",
      "記憶している\r\n",
      "吾輩は -> 見た\r\n",
      "ここで -> 始めて -> 人間という -> ものを -> 見た\r\n",
      "人間という -> ものを -> 見た\r\n",
      "ものを -> 見た\r\n",
      "あとで -> 聞くと -> 種族であったそうだ\r\n",
      "それは -> 種族であったそうだ\r\n",
      "書生という -> 人間中で -> 種族であったそうだ\r\n",
      "人間中で -> 種族であったそうだ\r\n",
      "一番 -> 獰悪な -> 種族であったそうだ\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 out_chapter5_48.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49. 名詞間の係り受けパスの抽出\n",
    "文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を\"->\"で連結して表現する\n",
    "- 文節iとjに含まれる名詞句はそれぞれ，XとYに置換する\n",
    "\n",
    "また，係り受けパスの形状は，以下の2通りが考えられる．\n",
    "\n",
    "- 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n",
    "- 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を\"|\"で連結して表示\n",
    "\n",
    "例えば，「吾輩はここで始めて人間というものを見た。」という文（neko.txt.cabochaの8文目）から，次のような出力が得られるはずである．\n",
    "\n",
    "```\n",
    "Xは | Yで -> 始めて -> 人間という -> ものを | 見た\n",
    "Xは | Yという -> ものを | 見た\n",
    "Xは | Yを | 見た\n",
    "Xで -> 始めて -> Y\n",
    "Xで -> 始めて -> 人間という -> Y\n",
    "Xという -> Y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力のイメージを得るために、8文目の木を可視化してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"332pt\" viewBox=\"0.00 0.00 197.89 332.00\" width=\"198pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-328 193.8916,-328 193.8916,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>0</title>\n",
       "<ellipse cx=\"38.3466\" cy=\"-90\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.3466\" y=\"-86.3\">吾輩は</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5</title>\n",
       "<ellipse cx=\"85.3466\" cy=\"-18\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.3466\" y=\"-14.3\">見た。</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>0-&gt;5</title>\n",
       "<path d=\"M49.724,-72.5708C55.3816,-63.9038 62.3302,-53.2592 68.5835,-43.6796\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"71.5385,-45.5557 74.074,-35.2687 65.6769,-41.7293 71.5385,-45.5557\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1</title>\n",
       "<ellipse cx=\"133.3466\" cy=\"-306\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.3466\" y=\"-302.3\">ここで</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>2</title>\n",
       "<ellipse cx=\"133.3466\" cy=\"-234\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.3466\" y=\"-230.3\">始めて</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1-&gt;2</title>\n",
       "<path d=\"M133.3466,-287.8314C133.3466,-280.131 133.3466,-270.9743 133.3466,-262.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.8467,-262.4132 133.3466,-252.4133 129.8467,-262.4133 136.8467,-262.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>3</title>\n",
       "<ellipse cx=\"133.3466\" cy=\"-162\" fill=\"none\" rx=\"56.59\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.3466\" y=\"-158.3\">人間という</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>2-&gt;3</title>\n",
       "<path d=\"M133.3466,-215.8314C133.3466,-208.131 133.3466,-198.9743 133.3466,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.8467,-190.4132 133.3466,-180.4133 129.8467,-190.4133 136.8467,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4</title>\n",
       "<ellipse cx=\"133.3466\" cy=\"-90\" fill=\"none\" rx=\"38.1938\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.3466\" y=\"-86.3\">ものを</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>3-&gt;4</title>\n",
       "<path d=\"M133.3466,-143.8314C133.3466,-136.131 133.3466,-126.9743 133.3466,-118.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.8467,-118.4132 133.3466,-108.4133 129.8467,-118.4133 136.8467,-118.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4-&gt;5</title>\n",
       "<path d=\"M121.7271,-72.5708C115.9491,-63.9038 108.8527,-53.2592 102.4663,-43.6796\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"105.3183,-41.6477 96.8591,-35.2687 99.4939,-45.5307 105.3183,-41.6477\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2tree(sentences[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_path_idx(i_chunk, sentence, carry):\n",
    "    carry.append(i_chunk)\n",
    "    dst = sentence[i_chunk].dst\n",
    "    if dst == -1:\n",
    "        return carry\n",
    "    else:\n",
    "        return walk_path_idx(dst, sentence, carry)\n",
    "\n",
    "def get_paths_from_noun(sentence):\n",
    "    return [\n",
    "        walk_path_idx(i_chunk, sentence, [])\n",
    "        for i_chunk in range(len(sentence))\n",
    "        if '名詞' in map(lambda m: m.pos, sentence[i_chunk].morphs)\n",
    "    ]\n",
    "\n",
    "import itertools\n",
    "\n",
    "def print_chunk_with_noun_repl(sentence, i_chunk, repl_dict):\n",
    "    if i_chunk not in repl_dict:\n",
    "        return sentence[i_chunk].wo_signs().surface\n",
    "    morphs = sentence[i_chunk].wo_signs().morphs\n",
    "    \n",
    "    # 「人間中」など、名詞が連続する表現は「YY」として出力せずに1つのYにまとめる\n",
    "    cum = ''\n",
    "    repl_done = False\n",
    "    for m in morphs:\n",
    "        if m.pos == '名詞':\n",
    "            if not repl_done:\n",
    "                cum += repl_dict[i_chunk]\n",
    "                repl_done = True\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            cum += m.surface\n",
    "            repl_done = False\n",
    "    return cum\n",
    "\n",
    "lines = []\n",
    "for sentence in sentences:\n",
    "    paths_from_noun = get_paths_from_noun(sentence)\n",
    "    for path_i, path_j in itertools.combinations(paths_from_noun, 2):\n",
    "        assert path_i[0] < path_j[0]\n",
    "                \n",
    "        # 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n",
    "        if path_j[0] in path_i:\n",
    "            idx_j_in_path_i = path_i.index(path_j[0])\n",
    "            path_i_to_j = path_i[:idx_j_in_path_i + 1]\n",
    "            # 出力例を見ると文節jは助詞等を取り除いているので、それに倣う\n",
    "            lines.append(\" -> \".join(\n",
    "                list(map(lambda i: print_chunk_with_noun_repl(sentence, i, {path_i[0]: 'X'}), path_i_to_j[:-1])) + ['Y', ]\n",
    "            ))\n",
    "        # 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: \n",
    "        # 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を\"|\"で連結して表示\n",
    "        else:\n",
    "            path_i_to_k = list(itertools.takewhile(lambda x: x not in path_j, path_i))\n",
    "            path_j_to_k = list(itertools.takewhile(lambda x: x not in path_i, path_j))\n",
    "            k = path_i[len(path_i_to_k)]\n",
    "            assert k == path_j[len(path_j_to_k)]\n",
    "            lines.append(\" | \".join([\n",
    "                \" -> \".join(map(lambda i: print_chunk_with_noun_repl(sentence, i, {path_i[0]: 'X'}), path_i_to_k)),\n",
    "                \" -> \".join(map(lambda i: print_chunk_with_noun_repl(sentence, i, {path_j[0]: 'Y'}), path_j_to_k)),\n",
    "                sentence[k].wo_signs().surface\n",
    "            ]))\n",
    "\n",
    "with open('out_chapter5_49.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        print(line, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xは -> Y\r\n",
      "Xで -> 生れたか | Yが | つかぬ\r\n",
      "Xでも -> 薄暗い -> Y\r\n",
      "Xでも -> 薄暗い -> 所で | Y | 泣いて\r\n",
      "Xでも -> 薄暗い -> 所で -> 泣いて | Yだけは | 記憶している\r\n",
      "Xでも -> 薄暗い -> 所で -> 泣いて -> Y\r\n",
      "Xで | Y | 泣いて\r\n",
      "Xで -> 泣いて | Yだけは | 記憶している\r\n",
      "Xで -> 泣いて -> Y\r\n",
      "X -> 泣いて | Yだけは | 記憶している\r\n",
      "X -> 泣いて -> Y\r\n",
      "Xだけは -> Y\r\n",
      "Xは | Yで -> 始めて -> 人間という -> ものを | 見た\r\n",
      "Xは | Yという -> ものを | 見た\r\n",
      "Xは | Yを | 見た\r\n",
      "Xで -> 始めて -> Y\r\n",
      "Xで -> 始めて -> 人間という -> Y\r\n",
      "Xという -> Y\r\n",
      "Xで -> 聞くと | Yは | 種族であったそうだ\r\n",
      "Xで -> 聞くと | Yという -> 人間中で | 種族であったそうだ\r\n",
      "Xで -> 聞くと | Yで | 種族であったそうだ\r\n",
      "Xで -> 聞くと | Y -> 獰悪な | 種族であったそうだ\r\n",
      "Xで -> 聞くと | Yな | 種族であったそうだ\r\n",
      "Xで -> 聞くと -> Y\r\n",
      "Xは | Yという -> 人間中で | 種族であったそうだ\r\n",
      "Xは | Yで | 種族であったそうだ\r\n",
      "Xは | Y -> 獰悪な | 種族であったそうだ\r\n",
      "Xは | Yな | 種族であったそうだ\r\n",
      "Xは -> Y\r\n",
      "Xという -> Y\r\n"
     ]
    }
   ],
   "source": [
    "!head -30 out_chapter5_49.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
