{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章: 英語テキストの処理\n",
    "Stanford Core NLPを用いた英語のテキスト処理を通じて，自然言語処理の様々な基盤技術を概観します．\n",
    "\n",
    "- [Stanford Core NLP](http://nlp.stanford.edu/software/corenlp.shtml), ステミング, 品詞タグ付け, 固有表現抽出, 共参照解析, 係り受け解析, 句構造解析, S式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章: 英語テキストの処理\n",
    "英語のテキスト（[nlp.txt](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/nlp.txt)）に対して，以下の処理を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8594  100  8594    0     0  41516      0 --:--:-- --:--:-- --:--:-- 41718\n"
     ]
    }
   ],
   "source": [
    "!curl -O http://www.cl.ecei.tohoku.ac.jp/nlp100/data/nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\r\n",
      "From Wikipedia, the free encyclopedia\r\n",
      "\r\n",
      "Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of humani-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.\r\n",
      "\r\n",
      "History\r\n",
      "\r\n",
      "The history of NLP generally starts in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.\r\n",
      "\r\n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, which found that ten year long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\r\n"
     ]
    }
   ],
   "source": [
    "!head nlp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. 文区切り\n",
    "(. or ; or : or ? or !) → 空白文字 → 英大文字というパターンを文の区切りと見なし，入力された文書を1行1文の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing\\nFrom Wikipedia, the free encyclopedia\\n\\nNatural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages.',\n",
       " 'As such, NLP is related to the area of humani-computer interaction.',\n",
       " 'Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.',\n",
       " 'History\\n\\nThe history of NLP generally starts in the 1950s, although work can be found from earlier periods.',\n",
       " 'In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.',\n",
       " 'The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English.',\n",
       " 'The authors claimed that within three or five years, machine translation would be a solved problem.',\n",
       " 'However, real progress was much slower, and after the ALPAC report in 1966, which found that ten year long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.',\n",
       " 'Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.',\n",
       " 'Some notably successful NLP systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 to 1966.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "with open('nlp.txt') as f:\n",
    "    nlp_txt = f.read()\n",
    "\n",
    "sentences = re.split(r'(?<=[.;:?!])\\s+(?=[A-Z])', nlp_txt)\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Natural language processing\\nFrom Wikipedia, the free encyclopedia\\n\\nNatural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages.'\n",
      "'As such, NLP is related to the area of humani-computer interaction.'\n",
      "'Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.'\n",
      "'History\\n\\nThe history of NLP generally starts in the 1950s, although work can be found from earlier periods.'\n",
      "'In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.'\n",
      "'The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English.'\n",
      "'The authors claimed that within three or five years, machine translation would be a solved problem.'\n",
      "'However, real progress was much slower, and after the ALPAC report in 1966, which found that ten year long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced.'\n",
      "'Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.'\n",
      "'Some notably successful NLP systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 to 1966.'\n",
      "'Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction.'\n",
      "'When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".'\n",
      "\"During the 1970s many programmers began to write 'conceptual ontologies', which structured real-world information into computer-understandable data.\"\n",
      "'Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981).'\n",
      "'During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.'\n",
      "'Up to the 1980s, most NLP systems were based on complex sets of hand-written rules.'\n",
      "'Starting in the late 1980s, however, there was a revolution in NLP with the introduction of machine learning algorithms for language processing.'\n",
      "\"This was due to both the steady increase in computational power resulting from Moore's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.\"\n",
      "'Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.'\n",
      "'However, Part of speech tagging introduced the use of Hidden Markov Models to NLP, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data.'\n",
      "'The cache language models upon which many speech recognition systems now rely are examples of such statistical models.'\n",
      "'Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.'\n",
      "'Many of the notable early successes occurred in the field of machine translation, due especially to work at IBM Research, where successively more complicated statistical models were developed.'\n",
      "'These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government.'\n",
      "'However, most other systems depended on corpora specifically developed for the tasks implemented by these systems, which was (and often continues to be) a major limitation in the success of these systems.'\n",
      "'As a result, a great deal of research has gone into methods of more effectively learning from limited amounts of data.'\n",
      "'Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.'\n",
      "'Such algorithms are able to learn from data that has not been hand-annotated with the desired answers, or using a combination of annotated and non-annotated data.'\n",
      "'Generally, this task is much more difficult than supervised learning, and typically produces less accurate results for a given amount of input data.'\n",
      "'However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the inferior results.'\n",
      "'NLP using machine learning\\n\\nModern NLP algorithms are based on machine learning, especially statistical machine learning.'\n",
      "'The paradigm of machine learning is different from that of most prior attempts at language processing.'\n",
      "'Prior implementations of language-processing tasks typically involved the direct hand coding of large sets of rules.'\n",
      "'The machine-learning paradigm calls instead for using general learning algorithms - often, although not always, grounded in statistical inference - to automatically learn such rules through the analysis of large corpora of typical real-world examples.'\n",
      "'A corpus (plural, \"corpora\") is a set of documents (or sometimes, individual sentences) that have been hand-annotated with the correct values to be learned.'\n",
      "'Many different classes of machine learning algorithms have been applied to NLP tasks.'\n",
      "'These algorithms take as input a large set of \"features\" that are generated from the input data.'\n",
      "'Some of the earliest-used algorithms, such as decision trees, produced systems of hard if-then rules similar to the systems of hand-written rules that were then common.'\n",
      "'Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature.'\n",
      "'Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.'\n",
      "'Systems based on machine-learning algorithms have many advantages over hand-produced rules:'\n",
      "'The learning procedures used during machine learning automatically focus on the most common cases, whereas when writing rules by hand it is often not obvious at all where the effort should be directed.'\n",
      "'Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input (e.g. containing words or structures that have not been seen before) and to erroneous input (e.g. with misspelled words or words accidentally omitted).'\n",
      "'Generally, handling such input gracefully with hand-written rules -- or more generally, creating systems of hand-written rules that make soft decisions -- extremely difficult, error-prone and time-consuming.'\n",
      "'Systems based on automatically learning the rules can be made more accurate simply by supplying more input data.'\n",
      "'However, systems based on hand-written rules can only be made more accurate by increasing the complexity of the rules, which is a much more difficult task.'\n",
      "'In particular, there is a limit to the complexity of systems based on hand-crafted rules, beyond which the systems become more and more unmanageable.'\n",
      "'However, creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked, generally without significant increases in the complexity of the annotation process.'\n",
      "'The subfield of NLP devoted to learning approaches is known as Natural Language Learning (NLL) and its conference CoNLL and peak body SIGNLL are sponsored by ACL, recognizing also their links with Computational Linguistics and Language Acquisition.'\n",
      "'When the aims of computational language learning research is to understand more about human language acquisition, or psycholinguistics, NLL overlaps into the related field of Computational Psycholinguistics.\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "# 設問通りの区切り方だと文中に改行が入ってしまう。ひとまず文中の改行は\\nとして出力する。\n",
    "for sentence in sentences:\n",
    "    print(repr(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51. 単語の切り出し\n",
    "空白を単語の区切りとみなし，50の出力を入力として受け取り，1行1単語の形式で出力せよ．ただし，文の終端では空行を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "From\n",
      "Wikipedia\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "NLP\n",
      "is\n",
      "a\n",
      "field\n",
      "of\n",
      "computer\n",
      "science\n",
      "artificial\n",
      "intelligence\n",
      "and\n",
      "linguistics\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interactions\n",
      "between\n",
      "computers\n",
      "and\n",
      "human\n",
      "natural\n",
      "languages\n",
      "\n",
      "As\n",
      "such\n",
      "NLP\n",
      "is\n",
      "related\n",
      "to\n",
      "the\n",
      "area\n",
      "of\n",
      "humani-computer\n",
      "interaction\n",
      "\n",
      "Many\n",
      "challenges\n",
      "in\n",
      "NLP\n",
      "involve\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "that\n",
      "is\n",
      "enabling\n",
      "computers\n",
      "to\n",
      "derive\n",
      "meaning\n",
      "from\n",
      "human\n",
      "or\n",
      "natural\n",
      "language\n",
      "input\n",
      "and\n",
      "others\n",
      "involve\n",
      "natural\n",
      "language\n",
      "generation\n",
      "\n",
      "History\n",
      "The\n",
      "history\n",
      "of\n",
      "NLP\n",
      "generally\n",
      "starts\n",
      "in\n",
      "the\n",
      "1950s\n",
      "although\n",
      "work\n",
      "can\n",
      "be\n",
      "found\n",
      "from\n",
      "earlier\n",
      "periods\n",
      "\n",
      "In\n",
      "1950\n",
      "Alan\n",
      "Turing\n",
      "published\n",
      "an\n",
      "article\n",
      "titled\n",
      "Computing\n",
      "Machinery\n",
      "and\n",
      "Intelligence\n",
      "which\n",
      "proposed\n",
      "what\n",
      "is\n",
      "now\n",
      "called\n",
      "the\n",
      "Turing\n",
      "test\n",
      "as\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intelligence\n",
      "\n",
      "The\n",
      "Georgetown\n",
      "experiment\n",
      "in\n",
      "1954\n",
      "involved\n",
      "fully\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "more\n",
      "than\n",
      "sixty\n",
      "Russian\n",
      "sentences\n",
      "into\n",
      "English\n",
      "\n",
      "The\n",
      "authors\n",
      "claimed\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "years\n",
      "machine\n",
      "translation\n",
      "would\n",
      "be\n",
      "a\n",
      "solved\n",
      "problem\n",
      "\n",
      "However\n",
      "real\n",
      "progress\n",
      "was\n",
      "much\n",
      "slower\n",
      "and\n",
      "after\n",
      "the\n",
      "ALPAC\n",
      "report\n",
      "in\n",
      "1966\n",
      "which\n",
      "found\n",
      "that\n",
      "ten\n",
      "year\n",
      "long\n",
      "research\n",
      "had\n",
      "failed\n",
      "to\n",
      "fulfill\n",
      "the\n",
      "expectations\n",
      "funding\n",
      "for\n",
      "machine\n",
      "translation\n",
      "was\n",
      "dramatically\n",
      "reduced\n",
      "\n",
      "Little\n",
      "further\n",
      "research\n",
      "in\n",
      "machine\n",
      "translation\n",
      "was\n",
      "conducted\n",
      "until\n",
      "the\n",
      "late\n",
      "1980s\n",
      "when\n",
      "the\n",
      "first\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "systems\n",
      "were\n",
      "developed\n",
      "\n",
      "Some\n",
      "notably\n",
      "successful\n",
      "NLP\n",
      "systems\n",
      "developed\n",
      "in\n",
      "the\n",
      "1960s\n",
      "were\n",
      "SHRDLU\n",
      "a\n",
      "natural\n",
      "language\n",
      "system\n",
      "working\n",
      "in\n",
      "restricted\n",
      "blocks\n",
      "worlds\n",
      "with\n",
      "restricted\n",
      "vocabularies\n",
      "and\n",
      "ELIZA\n",
      "a\n",
      "simulation\n",
      "of\n",
      "a\n",
      "Rogerian\n",
      "psychotherapist\n",
      "written\n",
      "by\n",
      "Joseph\n",
      "Weizenbaum\n",
      "between\n",
      "1964\n",
      "to\n",
      "1966\n",
      "\n",
      "Using\n",
      "almost\n",
      "no\n",
      "information\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emotion\n",
      "ELIZA\n",
      "sometimes\n",
      "provided\n",
      "a\n",
      "startlingly\n",
      "human-like\n",
      "interaction\n",
      "\n",
      "When\n",
      "the\n",
      "patient\n",
      "exceeded\n",
      "the\n",
      "very\n",
      "small\n",
      "knowledge\n",
      "base\n",
      "ELIZA\n",
      "might\n",
      "provide\n",
      "a\n",
      "generic\n",
      "response\n",
      "for\n",
      "example\n",
      "responding\n",
      "to\n",
      "My\n",
      "head\n",
      "hurts\n",
      "with\n",
      "Why\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurts\n",
      "\n",
      "During\n",
      "the\n",
      "1970s\n",
      "many\n",
      "programmers\n",
      "began\n",
      "to\n",
      "write\n",
      "conceptual\n",
      "ontologies\n",
      "which\n",
      "structured\n",
      "real-world\n",
      "information\n",
      "into\n",
      "computer-understandable\n",
      "data\n",
      "\n",
      "Examples\n",
      "are\n",
      "MARGIE\n",
      "Schank\n",
      "1975\n",
      "SAM\n",
      "Cullingford\n",
      "1978\n",
      "PAM\n",
      "Wilensky\n",
      "1978\n",
      "TaleSpin\n",
      "Meehan\n",
      "1976\n",
      "QUALM\n",
      "Lehnert\n",
      "1977\n",
      "Politics\n",
      "Carbonell\n",
      "1979\n",
      "and\n",
      "Plot\n",
      "Units\n",
      "Lehnert\n",
      "1981\n",
      "\n",
      "During\n",
      "this\n",
      "time\n",
      "many\n",
      "chatterbots\n",
      "were\n",
      "written\n",
      "including\n",
      "PARRY\n",
      "Racter\n",
      "and\n",
      "Jabberwacky\n",
      "\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s\n",
      "most\n",
      "NLP\n",
      "systems\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "sets\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      "however\n",
      "there\n",
      "was\n",
      "a\n",
      "revolution\n",
      "in\n",
      "NLP\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "for\n",
      "language\n",
      "processing\n",
      "\n",
      "This\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "resulting\n",
      "from\n",
      "Moores\n",
      "Law\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theories\n",
      "of\n",
      "linguistics\n",
      "eg\n",
      "transformational\n",
      "grammar\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing\n",
      "\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "existing\n",
      "hand-written\n",
      "rules\n",
      "\n",
      "However\n",
      "Part\n",
      "of\n",
      "speech\n",
      "tagging\n",
      "introduced\n",
      "the\n",
      "use\n",
      "of\n",
      "Hidden\n",
      "Markov\n",
      "Models\n",
      "to\n",
      "NLP\n",
      "and\n",
      "increasingly\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      "which\n",
      "make\n",
      "soft\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "the\n",
      "features\n",
      "making\n",
      "up\n",
      "the\n",
      "input\n",
      "data\n",
      "\n",
      "The\n",
      "cache\n",
      "language\n",
      "models\n",
      "upon\n",
      "which\n",
      "many\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "now\n",
      "rely\n",
      "are\n",
      "examples\n",
      "of\n",
      "such\n",
      "statistical\n",
      "models\n",
      "\n",
      "Such\n",
      "models\n",
      "are\n",
      "generally\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input\n",
      "especially\n",
      "input\n",
      "that\n",
      "contains\n",
      "errors\n",
      "as\n",
      "is\n",
      "very\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data\n",
      "and\n",
      "produce\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "integrated\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "comprising\n",
      "multiple\n",
      "subtasks\n",
      "\n",
      "Many\n",
      "of\n",
      "the\n",
      "notable\n",
      "early\n",
      "successes\n",
      "occurred\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machine\n",
      "translation\n",
      "due\n",
      "especially\n",
      "to\n",
      "work\n",
      "at\n",
      "IBM\n",
      "Research\n",
      "where\n",
      "successively\n",
      "more\n",
      "complicated\n",
      "statistical\n",
      "models\n",
      "were\n",
      "developed\n",
      "\n",
      "These\n",
      "systems\n",
      "were\n",
      "able\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "existing\n",
      "multilingual\n",
      "textual\n",
      "corpora\n",
      "that\n",
      "had\n",
      "been\n",
      "produced\n",
      "by\n",
      "the\n",
      "Parliament\n",
      "of\n",
      "Canada\n",
      "and\n",
      "the\n",
      "European\n",
      "Union\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "laws\n",
      "calling\n",
      "for\n",
      "the\n",
      "translation\n",
      "of\n",
      "all\n",
      "governmental\n",
      "proceedings\n",
      "into\n",
      "all\n",
      "official\n",
      "languages\n",
      "of\n",
      "the\n",
      "corresponding\n",
      "systems\n",
      "of\n",
      "government\n",
      "\n",
      "However\n",
      "most\n",
      "other\n",
      "systems\n",
      "depended\n",
      "on\n",
      "corpora\n",
      "specifically\n",
      "developed\n",
      "for\n",
      "the\n",
      "tasks\n",
      "implemented\n",
      "by\n",
      "these\n",
      "systems\n",
      "which\n",
      "was\n",
      "and\n",
      "often\n",
      "continues\n",
      "to\n",
      "be\n",
      "a\n",
      "major\n",
      "limitation\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "systems\n",
      "\n",
      "As\n",
      "a\n",
      "result\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "has\n",
      "gone\n",
      "into\n",
      "methods\n",
      "of\n",
      "more\n",
      "effectively\n",
      "learning\n",
      "from\n",
      "limited\n",
      "amounts\n",
      "of\n",
      "data\n",
      "\n",
      "Recent\n",
      "research\n",
      "has\n",
      "increasingly\n",
      "focused\n",
      "on\n",
      "unsupervised\n",
      "and\n",
      "semi-supervised\n",
      "learning\n",
      "algorithms\n",
      "\n",
      "Such\n",
      "algorithms\n",
      "are\n",
      "able\n",
      "to\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "has\n",
      "not\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "desired\n",
      "answers\n",
      "or\n",
      "using\n",
      "a\n",
      "combination\n",
      "of\n",
      "annotated\n",
      "and\n",
      "non-annotated\n",
      "data\n",
      "\n",
      "Generally\n",
      "this\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervised\n",
      "learning\n",
      "and\n",
      "typically\n",
      "produces\n",
      "less\n",
      "accurate\n",
      "results\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data\n",
      "\n",
      "However\n",
      "there\n",
      "is\n",
      "an\n",
      "enormous\n",
      "amount\n",
      "of\n",
      "non-annotated\n",
      "data\n",
      "available\n",
      "including\n",
      "among\n",
      "other\n",
      "things\n",
      "the\n",
      "entire\n",
      "content\n",
      "of\n",
      "the\n",
      "World\n",
      "Wide\n",
      "Web\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "results\n",
      "\n",
      "NLP\n",
      "using\n",
      "machine\n",
      "learning\n",
      "Modern\n",
      "NLP\n",
      "algorithms\n",
      "are\n",
      "based\n",
      "on\n",
      "machine\n",
      "learning\n",
      "especially\n",
      "statistical\n",
      "machine\n",
      "learning\n",
      "\n",
      "The\n",
      "paradigm\n",
      "of\n",
      "machine\n",
      "learning\n",
      "is\n",
      "different\n",
      "from\n",
      "that\n",
      "of\n",
      "most\n",
      "prior\n",
      "attempts\n",
      "at\n",
      "language\n",
      "processing\n",
      "\n",
      "Prior\n",
      "implementations\n",
      "of\n",
      "language-processing\n",
      "tasks\n",
      "typically\n",
      "involved\n",
      "the\n",
      "direct\n",
      "hand\n",
      "coding\n",
      "of\n",
      "large\n",
      "sets\n",
      "of\n",
      "rules\n",
      "\n",
      "The\n",
      "machine-learning\n",
      "paradigm\n",
      "calls\n",
      "instead\n",
      "for\n",
      "using\n",
      "general\n",
      "learning\n",
      "algorithms\n",
      "-\n",
      "often\n",
      "although\n",
      "not\n",
      "always\n",
      "grounded\n",
      "in\n",
      "statistical\n",
      "inference\n",
      "-\n",
      "to\n",
      "automatically\n",
      "learn\n",
      "such\n",
      "rules\n",
      "through\n",
      "the\n",
      "analysis\n",
      "of\n",
      "large\n",
      "corpora\n",
      "of\n",
      "typical\n",
      "real-world\n",
      "examples\n",
      "\n",
      "A\n",
      "corpus\n",
      "plural\n",
      "corpora\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "documents\n",
      "or\n",
      "sometimes\n",
      "individual\n",
      "sentences\n",
      "that\n",
      "have\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "correct\n",
      "values\n",
      "to\n",
      "be\n",
      "learned\n",
      "\n",
      "Many\n",
      "different\n",
      "classes\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "have\n",
      "been\n",
      "applied\n",
      "to\n",
      "NLP\n",
      "tasks\n",
      "\n",
      "These\n",
      "algorithms\n",
      "take\n",
      "as\n",
      "input\n",
      "a\n",
      "large\n",
      "set\n",
      "of\n",
      "features\n",
      "that\n",
      "are\n",
      "generated\n",
      "from\n",
      "the\n",
      "input\n",
      "data\n",
      "\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "algorithms\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "the\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "were\n",
      "then\n",
      "common\n",
      "\n",
      "Increasingly\n",
      "however\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      "which\n",
      "make\n",
      "soft\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "each\n",
      "input\n",
      "feature\n",
      "\n",
      "Such\n",
      "models\n",
      "have\n",
      "the\n",
      "advantage\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "relative\n",
      "certainty\n",
      "of\n",
      "many\n",
      "different\n",
      "possible\n",
      "answers\n",
      "rather\n",
      "than\n",
      "only\n",
      "one\n",
      "producing\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "included\n",
      "as\n",
      "a\n",
      "component\n",
      "of\n",
      "a\n",
      "larger\n",
      "system\n",
      "\n",
      "Systems\n",
      "based\n",
      "on\n",
      "machine-learning\n",
      "algorithms\n",
      "have\n",
      "many\n",
      "advantages\n",
      "over\n",
      "hand-produced\n",
      "rules\n",
      "\n",
      "The\n",
      "learning\n",
      "procedures\n",
      "used\n",
      "during\n",
      "machine\n",
      "learning\n",
      "automatically\n",
      "focus\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "cases\n",
      "whereas\n",
      "when\n",
      "writing\n",
      "rules\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "obvious\n",
      "at\n",
      "all\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "directed\n",
      "\n",
      "Automatic\n",
      "learning\n",
      "procedures\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statistical\n",
      "inference\n",
      "algorithms\n",
      "to\n",
      "produce\n",
      "models\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "eg\n",
      "containing\n",
      "words\n",
      "or\n",
      "structures\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "before\n",
      "and\n",
      "to\n",
      "erroneous\n",
      "input\n",
      "eg\n",
      "with\n",
      "misspelled\n",
      "words\n",
      "or\n",
      "words\n",
      "accidentally\n",
      "omitted\n",
      "\n",
      "Generally\n",
      "handling\n",
      "such\n",
      "input\n",
      "gracefully\n",
      "with\n",
      "hand-written\n",
      "rules\n",
      "--\n",
      "or\n",
      "more\n",
      "generally\n",
      "creating\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "make\n",
      "soft\n",
      "decisions\n",
      "--\n",
      "extremely\n",
      "difficult\n",
      "error-prone\n",
      "and\n",
      "time-consuming\n",
      "\n",
      "Systems\n",
      "based\n",
      "on\n",
      "automatically\n",
      "learning\n",
      "the\n",
      "rules\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "simply\n",
      "by\n",
      "supplying\n",
      "more\n",
      "input\n",
      "data\n",
      "\n",
      "However\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-written\n",
      "rules\n",
      "can\n",
      "only\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "by\n",
      "increasing\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "rules\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task\n",
      "\n",
      "In\n",
      "particular\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complexity\n",
      "of\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-crafted\n",
      "rules\n",
      "beyond\n",
      "which\n",
      "the\n",
      "systems\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanageable\n",
      "\n",
      "However\n",
      "creating\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learning\n",
      "systems\n",
      "simply\n",
      "requires\n",
      "a\n",
      "corresponding\n",
      "increase\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hours\n",
      "worked\n",
      "generally\n",
      "without\n",
      "significant\n",
      "increases\n",
      "in\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "annotation\n",
      "process\n",
      "\n",
      "The\n",
      "subfield\n",
      "of\n",
      "NLP\n",
      "devoted\n",
      "to\n",
      "learning\n",
      "approaches\n",
      "is\n",
      "known\n",
      "as\n",
      "Natural\n",
      "Language\n",
      "Learning\n",
      "NLL\n",
      "and\n",
      "its\n",
      "conference\n",
      "CoNLL\n",
      "and\n",
      "peak\n",
      "body\n",
      "SIGNLL\n",
      "are\n",
      "sponsored\n",
      "by\n",
      "ACL\n",
      "recognizing\n",
      "also\n",
      "their\n",
      "links\n",
      "with\n",
      "Computational\n",
      "Linguistics\n",
      "and\n",
      "Language\n",
      "Acquisition\n",
      "\n",
      "When\n",
      "the\n",
      "aims\n",
      "of\n",
      "computational\n",
      "language\n",
      "learning\n",
      "research\n",
      "is\n",
      "to\n",
      "understand\n",
      "more\n",
      "about\n",
      "human\n",
      "language\n",
      "acquisition\n",
      "or\n",
      "psycholinguistics\n",
      "NLL\n",
      "overlaps\n",
      "into\n",
      "the\n",
      "related\n",
      "field\n",
      "of\n",
      "Computational\n",
      "Psycholinguistics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_per_sentences = [sentence.split() for sentence in sentences]\n",
    "\n",
    "# 52で記号が邪魔だったので消しておく\n",
    "words_per_sentences = [[re.sub(r'[^A-Za-z0-9\\-]', '', word) for word in sentence] for sentence in words_per_sentences]\n",
    "\n",
    "for sentence in words_per_sentences:\n",
    "    for word in sentence:\n",
    "        print(word)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52. ステミング\n",
    "51の出力を入力として受け取り，Porterのステミングアルゴリズムを適用し，単語と語幹をタブ区切り形式で出力せよ． Pythonでは，Porterのステミングアルゴリズムの実装として[stemming](https://pypi.python.org/pypi/stemming)モジュールを利用するとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stemming\n",
    "dir(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (porter.py, line 176)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3291\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5d5253869c2e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import stemming.porter\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/anaconda/lib/python3.6/site-packages/stemming/porter.py\"\u001b[0;36m, line \u001b[0;32m176\u001b[0m\n\u001b[0;31m    print stem(\"fundamentally\")\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import stemming.porter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python 3非対応？！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ぐぐってみたところ下記の記事がヒットした。nltkを使ってみる。\n",
    "\n",
    "https://www.haya-programming.com/entry/2018/03/25/203836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.stem.porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\tnatur\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "From\tfrom\n",
      "Wikipedia\twikipedia\n",
      "the\tthe\n",
      "free\tfree\n",
      "encyclopedia\tencyclopedia\n",
      "Natural\tnatur\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "NLP\tnlp\n",
      "is\tis\n",
      "a\ta\n",
      "field\tfield\n",
      "of\tof\n",
      "computer\tcomput\n",
      "science\tscienc\n",
      "artificial\tartifici\n",
      "intelligence\tintellig\n",
      "and\tand\n",
      "linguistics\tlinguist\n",
      "concerned\tconcern\n",
      "with\twith\n",
      "the\tthe\n",
      "interactions\tinteract\n",
      "between\tbetween\n",
      "computers\tcomput\n",
      "and\tand\n",
      "human\thuman\n",
      "natural\tnatur\n",
      "languages\tlanguag\n",
      "\n",
      "As\tAs\n",
      "such\tsuch\n",
      "NLP\tnlp\n",
      "is\tis\n",
      "related\trelat\n",
      "to\tto\n",
      "the\tthe\n",
      "area\tarea\n",
      "of\tof\n",
      "humani-computer\thumani-comput\n",
      "interaction\tinteract\n",
      "\n",
      "Many\tmani\n",
      "challenges\tchalleng\n",
      "in\tin\n",
      "NLP\tnlp\n",
      "involve\tinvolv\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "understanding\tunderstand\n",
      "that\tthat\n",
      "is\tis\n",
      "enabling\tenabl\n",
      "computers\tcomput\n",
      "to\tto\n",
      "derive\tderiv\n",
      "meaning\tmean\n",
      "from\tfrom\n",
      "human\thuman\n",
      "or\tor\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "input\tinput\n",
      "and\tand\n",
      "others\tother\n",
      "involve\tinvolv\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "generation\tgener\n",
      "\n",
      "History\thistori\n",
      "The\tthe\n",
      "history\thistori\n",
      "of\tof\n",
      "NLP\tnlp\n",
      "generally\tgener\n",
      "starts\tstart\n",
      "in\tin\n",
      "the\tthe\n",
      "1950s\t1950\n",
      "although\talthough\n",
      "work\twork\n",
      "can\tcan\n",
      "be\tbe\n",
      "found\tfound\n",
      "from\tfrom\n",
      "earlier\tearlier\n",
      "periods\tperiod\n",
      "\n",
      "In\tIn\n",
      "1950\t1950\n",
      "Alan\talan\n",
      "Turing\tture\n",
      "published\tpublish\n",
      "an\tan\n",
      "article\tarticl\n",
      "titled\ttitl\n",
      "Computing\tcomput\n",
      "Machinery\tmachineri\n",
      "and\tand\n",
      "Intelligence\tintellig\n",
      "which\twhich\n",
      "proposed\tpropos\n",
      "what\twhat\n",
      "is\tis\n",
      "now\tnow\n",
      "called\tcall\n",
      "the\tthe\n",
      "Turing\tture\n",
      "test\ttest\n",
      "as\tas\n",
      "a\ta\n",
      "criterion\tcriterion\n",
      "of\tof\n",
      "intelligence\tintellig\n",
      "\n",
      "The\tthe\n",
      "Georgetown\tgeorgetown\n",
      "experiment\texperi\n",
      "in\tin\n",
      "1954\t1954\n",
      "involved\tinvolv\n",
      "fully\tfulli\n",
      "automatic\tautomat\n",
      "translation\ttranslat\n",
      "of\tof\n",
      "more\tmore\n",
      "than\tthan\n",
      "sixty\tsixti\n",
      "Russian\trussian\n",
      "sentences\tsentenc\n",
      "into\tinto\n",
      "English\tenglish\n",
      "\n",
      "The\tthe\n",
      "authors\tauthor\n",
      "claimed\tclaim\n",
      "that\tthat\n",
      "within\twithin\n",
      "three\tthree\n",
      "or\tor\n",
      "five\tfive\n",
      "years\tyear\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "would\twould\n",
      "be\tbe\n",
      "a\ta\n",
      "solved\tsolv\n",
      "problem\tproblem\n",
      "\n",
      "However\thowev\n",
      "real\treal\n",
      "progress\tprogress\n",
      "was\twa\n",
      "much\tmuch\n",
      "slower\tslower\n",
      "and\tand\n",
      "after\tafter\n",
      "the\tthe\n",
      "ALPAC\talpac\n",
      "report\treport\n",
      "in\tin\n",
      "1966\t1966\n",
      "which\twhich\n",
      "found\tfound\n",
      "that\tthat\n",
      "ten\tten\n",
      "year\tyear\n",
      "long\tlong\n",
      "research\tresearch\n",
      "had\thad\n",
      "failed\tfail\n",
      "to\tto\n",
      "fulfill\tfulfil\n",
      "the\tthe\n",
      "expectations\texpect\n",
      "funding\tfund\n",
      "for\tfor\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "was\twa\n",
      "dramatically\tdramat\n",
      "reduced\treduc\n",
      "\n",
      "Little\tlittl\n",
      "further\tfurther\n",
      "research\tresearch\n",
      "in\tin\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "was\twa\n",
      "conducted\tconduct\n",
      "until\tuntil\n",
      "the\tthe\n",
      "late\tlate\n",
      "1980s\t1980\n",
      "when\twhen\n",
      "the\tthe\n",
      "first\tfirst\n",
      "statistical\tstatist\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "systems\tsystem\n",
      "were\twere\n",
      "developed\tdevelop\n",
      "\n",
      "Some\tsome\n",
      "notably\tnotabl\n",
      "successful\tsuccess\n",
      "NLP\tnlp\n",
      "systems\tsystem\n",
      "developed\tdevelop\n",
      "in\tin\n",
      "the\tthe\n",
      "1960s\t1960\n",
      "were\twere\n",
      "SHRDLU\tshrdlu\n",
      "a\ta\n",
      "natural\tnatur\n",
      "language\tlanguag\n",
      "system\tsystem\n",
      "working\twork\n",
      "in\tin\n",
      "restricted\trestrict\n",
      "blocks\tblock\n",
      "worlds\tworld\n",
      "with\twith\n",
      "restricted\trestrict\n",
      "vocabularies\tvocabulari\n",
      "and\tand\n",
      "ELIZA\teliza\n",
      "a\ta\n",
      "simulation\tsimul\n",
      "of\tof\n",
      "a\ta\n",
      "Rogerian\trogerian\n",
      "psychotherapist\tpsychotherapist\n",
      "written\twritten\n",
      "by\tby\n",
      "Joseph\tjoseph\n",
      "Weizenbaum\tweizenbaum\n",
      "between\tbetween\n",
      "1964\t1964\n",
      "to\tto\n",
      "1966\t1966\n",
      "\n",
      "Using\tuse\n",
      "almost\talmost\n",
      "no\tno\n",
      "information\tinform\n",
      "about\tabout\n",
      "human\thuman\n",
      "thought\tthought\n",
      "or\tor\n",
      "emotion\temot\n",
      "ELIZA\teliza\n",
      "sometimes\tsometim\n",
      "provided\tprovid\n",
      "a\ta\n",
      "startlingly\tstartlingli\n",
      "human-like\thuman-lik\n",
      "interaction\tinteract\n",
      "\n",
      "When\twhen\n",
      "the\tthe\n",
      "patient\tpatient\n",
      "exceeded\texceed\n",
      "the\tthe\n",
      "very\tveri\n",
      "small\tsmall\n",
      "knowledge\tknowledg\n",
      "base\tbase\n",
      "ELIZA\teliza\n",
      "might\tmight\n",
      "provide\tprovid\n",
      "a\ta\n",
      "generic\tgener\n",
      "response\trespons\n",
      "for\tfor\n",
      "example\texampl\n",
      "responding\trespond\n",
      "to\tto\n",
      "My\tMy\n",
      "head\thead\n",
      "hurts\thurt\n",
      "with\twith\n",
      "Why\twhi\n",
      "do\tdo\n",
      "you\tyou\n",
      "say\tsay\n",
      "your\tyour\n",
      "head\thead\n",
      "hurts\thurt\n",
      "\n",
      "During\tdure\n",
      "the\tthe\n",
      "1970s\t1970\n",
      "many\tmani\n",
      "programmers\tprogramm\n",
      "began\tbegan\n",
      "to\tto\n",
      "write\twrite\n",
      "conceptual\tconceptu\n",
      "ontologies\tontolog\n",
      "which\twhich\n",
      "structured\tstructur\n",
      "real-world\treal-world\n",
      "information\tinform\n",
      "into\tinto\n",
      "computer-understandable\tcomputer-understand\n",
      "data\tdata\n",
      "\n",
      "Examples\texampl\n",
      "are\tare\n",
      "MARGIE\tmargi\n",
      "Schank\tschank\n",
      "1975\t1975\n",
      "SAM\tsam\n",
      "Cullingford\tcullingford\n",
      "1978\t1978\n",
      "PAM\tpam\n",
      "Wilensky\twilenski\n",
      "1978\t1978\n",
      "TaleSpin\ttalespin\n",
      "Meehan\tmeehan\n",
      "1976\t1976\n",
      "QUALM\tqualm\n",
      "Lehnert\tlehnert\n",
      "1977\t1977\n",
      "Politics\tpolit\n",
      "Carbonell\tcarbonel\n",
      "1979\t1979\n",
      "and\tand\n",
      "Plot\tplot\n",
      "Units\tunit\n",
      "Lehnert\tlehnert\n",
      "1981\t1981\n",
      "\n",
      "During\tdure\n",
      "this\tthi\n",
      "time\ttime\n",
      "many\tmani\n",
      "chatterbots\tchatterbot\n",
      "were\twere\n",
      "written\twritten\n",
      "including\tinclud\n",
      "PARRY\tparri\n",
      "Racter\tracter\n",
      "and\tand\n",
      "Jabberwacky\tjabberwacki\n",
      "\n",
      "Up\tUp\n",
      "to\tto\n",
      "the\tthe\n",
      "1980s\t1980\n",
      "most\tmost\n",
      "NLP\tnlp\n",
      "systems\tsystem\n",
      "were\twere\n",
      "based\tbase\n",
      "on\ton\n",
      "complex\tcomplex\n",
      "sets\tset\n",
      "of\tof\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "\n",
      "Starting\tstart\n",
      "in\tin\n",
      "the\tthe\n",
      "late\tlate\n",
      "1980s\t1980\n",
      "however\thowev\n",
      "there\tthere\n",
      "was\twa\n",
      "a\ta\n",
      "revolution\trevolut\n",
      "in\tin\n",
      "NLP\tnlp\n",
      "with\twith\n",
      "the\tthe\n",
      "introduction\tintroduct\n",
      "of\tof\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "for\tfor\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "\n",
      "This\tthi\n",
      "was\twa\n",
      "due\tdue\n",
      "to\tto\n",
      "both\tboth\n",
      "the\tthe\n",
      "steady\tsteadi\n",
      "increase\tincreas\n",
      "in\tin\n",
      "computational\tcomput\n",
      "power\tpower\n",
      "resulting\tresult\n",
      "from\tfrom\n",
      "Moores\tmoor\n",
      "Law\tlaw\n",
      "and\tand\n",
      "the\tthe\n",
      "gradual\tgradual\n",
      "lessening\tlessen\n",
      "of\tof\n",
      "the\tthe\n",
      "dominance\tdomin\n",
      "of\tof\n",
      "Chomskyan\tchomskyan\n",
      "theories\ttheori\n",
      "of\tof\n",
      "linguistics\tlinguist\n",
      "eg\teg\n",
      "transformational\ttransform\n",
      "grammar\tgrammar\n",
      "whose\twhose\n",
      "theoretical\ttheoret\n",
      "underpinnings\tunderpin\n",
      "discouraged\tdiscourag\n",
      "the\tthe\n",
      "sort\tsort\n",
      "of\tof\n",
      "corpus\tcorpu\n",
      "linguistics\tlinguist\n",
      "that\tthat\n",
      "underlies\tunderli\n",
      "the\tthe\n",
      "machine-learning\tmachine-learn\n",
      "approach\tapproach\n",
      "to\tto\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "\n",
      "Some\tsome\n",
      "of\tof\n",
      "the\tthe\n",
      "earliest-used\tearliest-us\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "such\tsuch\n",
      "as\tas\n",
      "decision\tdecis\n",
      "trees\ttree\n",
      "produced\tproduc\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hard\thard\n",
      "if-then\tif-then\n",
      "rules\trule\n",
      "similar\tsimilar\n",
      "to\tto\n",
      "existing\texist\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "\n",
      "However\thowev\n",
      "Part\tpart\n",
      "of\tof\n",
      "speech\tspeech\n",
      "tagging\ttag\n",
      "introduced\tintroduc\n",
      "the\tthe\n",
      "use\tuse\n",
      "of\tof\n",
      "Hidden\thidden\n",
      "Markov\tmarkov\n",
      "Models\tmodel\n",
      "to\tto\n",
      "NLP\tnlp\n",
      "and\tand\n",
      "increasingly\tincreasingli\n",
      "research\tresearch\n",
      "has\tha\n",
      "focused\tfocus\n",
      "on\ton\n",
      "statistical\tstatist\n",
      "models\tmodel\n",
      "which\twhich\n",
      "make\tmake\n",
      "soft\tsoft\n",
      "probabilistic\tprobabilist\n",
      "decisions\tdecis\n",
      "based\tbase\n",
      "on\ton\n",
      "attaching\tattach\n",
      "real-valued\treal-valu\n",
      "weights\tweight\n",
      "to\tto\n",
      "the\tthe\n",
      "features\tfeatur\n",
      "making\tmake\n",
      "up\tup\n",
      "the\tthe\n",
      "input\tinput\n",
      "data\tdata\n",
      "\n",
      "The\tthe\n",
      "cache\tcach\n",
      "language\tlanguag\n",
      "models\tmodel\n",
      "upon\tupon\n",
      "which\twhich\n",
      "many\tmani\n",
      "speech\tspeech\n",
      "recognition\trecognit\n",
      "systems\tsystem\n",
      "now\tnow\n",
      "rely\treli\n",
      "are\tare\n",
      "examples\texampl\n",
      "of\tof\n",
      "such\tsuch\n",
      "statistical\tstatist\n",
      "models\tmodel\n",
      "\n",
      "Such\tsuch\n",
      "models\tmodel\n",
      "are\tare\n",
      "generally\tgener\n",
      "more\tmore\n",
      "robust\trobust\n",
      "when\twhen\n",
      "given\tgiven\n",
      "unfamiliar\tunfamiliar\n",
      "input\tinput\n",
      "especially\tespeci\n",
      "input\tinput\n",
      "that\tthat\n",
      "contains\tcontain\n",
      "errors\terror\n",
      "as\tas\n",
      "is\tis\n",
      "very\tveri\n",
      "common\tcommon\n",
      "for\tfor\n",
      "real-world\treal-world\n",
      "data\tdata\n",
      "and\tand\n",
      "produce\tproduc\n",
      "more\tmore\n",
      "reliable\treliabl\n",
      "results\tresult\n",
      "when\twhen\n",
      "integrated\tintegr\n",
      "into\tinto\n",
      "a\ta\n",
      "larger\tlarger\n",
      "system\tsystem\n",
      "comprising\tcompris\n",
      "multiple\tmultipl\n",
      "subtasks\tsubtask\n",
      "\n",
      "Many\tmani\n",
      "of\tof\n",
      "the\tthe\n",
      "notable\tnotabl\n",
      "early\tearli\n",
      "successes\tsuccess\n",
      "occurred\toccur\n",
      "in\tin\n",
      "the\tthe\n",
      "field\tfield\n",
      "of\tof\n",
      "machine\tmachin\n",
      "translation\ttranslat\n",
      "due\tdue\n",
      "especially\tespeci\n",
      "to\tto\n",
      "work\twork\n",
      "at\tat\n",
      "IBM\tibm\n",
      "Research\tresearch\n",
      "where\twhere\n",
      "successively\tsuccess\n",
      "more\tmore\n",
      "complicated\tcomplic\n",
      "statistical\tstatist\n",
      "models\tmodel\n",
      "were\twere\n",
      "developed\tdevelop\n",
      "\n",
      "These\tthese\n",
      "systems\tsystem\n",
      "were\twere\n",
      "able\tabl\n",
      "to\tto\n",
      "take\ttake\n",
      "advantage\tadvantag\n",
      "of\tof\n",
      "existing\texist\n",
      "multilingual\tmultilingu\n",
      "textual\ttextual\n",
      "corpora\tcorpora\n",
      "that\tthat\n",
      "had\thad\n",
      "been\tbeen\n",
      "produced\tproduc\n",
      "by\tby\n",
      "the\tthe\n",
      "Parliament\tparliament\n",
      "of\tof\n",
      "Canada\tcanada\n",
      "and\tand\n",
      "the\tthe\n",
      "European\teuropean\n",
      "Union\tunion\n",
      "as\tas\n",
      "a\ta\n",
      "result\tresult\n",
      "of\tof\n",
      "laws\tlaw\n",
      "calling\tcall\n",
      "for\tfor\n",
      "the\tthe\n",
      "translation\ttranslat\n",
      "of\tof\n",
      "all\tall\n",
      "governmental\tgovernment\n",
      "proceedings\tproceed\n",
      "into\tinto\n",
      "all\tall\n",
      "official\toffici\n",
      "languages\tlanguag\n",
      "of\tof\n",
      "the\tthe\n",
      "corresponding\tcorrespond\n",
      "systems\tsystem\n",
      "of\tof\n",
      "government\tgovern\n",
      "\n",
      "However\thowev\n",
      "most\tmost\n",
      "other\tother\n",
      "systems\tsystem\n",
      "depended\tdepend\n",
      "on\ton\n",
      "corpora\tcorpora\n",
      "specifically\tspecif\n",
      "developed\tdevelop\n",
      "for\tfor\n",
      "the\tthe\n",
      "tasks\ttask\n",
      "implemented\timplement\n",
      "by\tby\n",
      "these\tthese\n",
      "systems\tsystem\n",
      "which\twhich\n",
      "was\twa\n",
      "and\tand\n",
      "often\toften\n",
      "continues\tcontinu\n",
      "to\tto\n",
      "be\tbe\n",
      "a\ta\n",
      "major\tmajor\n",
      "limitation\tlimit\n",
      "in\tin\n",
      "the\tthe\n",
      "success\tsuccess\n",
      "of\tof\n",
      "these\tthese\n",
      "systems\tsystem\n",
      "\n",
      "As\tAs\n",
      "a\ta\n",
      "result\tresult\n",
      "a\ta\n",
      "great\tgreat\n",
      "deal\tdeal\n",
      "of\tof\n",
      "research\tresearch\n",
      "has\tha\n",
      "gone\tgone\n",
      "into\tinto\n",
      "methods\tmethod\n",
      "of\tof\n",
      "more\tmore\n",
      "effectively\teffect\n",
      "learning\tlearn\n",
      "from\tfrom\n",
      "limited\tlimit\n",
      "amounts\tamount\n",
      "of\tof\n",
      "data\tdata\n",
      "\n",
      "Recent\trecent\n",
      "research\tresearch\n",
      "has\tha\n",
      "increasingly\tincreasingli\n",
      "focused\tfocus\n",
      "on\ton\n",
      "unsupervised\tunsupervis\n",
      "and\tand\n",
      "semi-supervised\tsemi-supervis\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "\n",
      "Such\tsuch\n",
      "algorithms\talgorithm\n",
      "are\tare\n",
      "able\tabl\n",
      "to\tto\n",
      "learn\tlearn\n",
      "from\tfrom\n",
      "data\tdata\n",
      "that\tthat\n",
      "has\tha\n",
      "not\tnot\n",
      "been\tbeen\n",
      "hand-annotated\thand-annot\n",
      "with\twith\n",
      "the\tthe\n",
      "desired\tdesir\n",
      "answers\tanswer\n",
      "or\tor\n",
      "using\tuse\n",
      "a\ta\n",
      "combination\tcombin\n",
      "of\tof\n",
      "annotated\tannot\n",
      "and\tand\n",
      "non-annotated\tnon-annot\n",
      "data\tdata\n",
      "\n",
      "Generally\tgener\n",
      "this\tthi\n",
      "task\ttask\n",
      "is\tis\n",
      "much\tmuch\n",
      "more\tmore\n",
      "difficult\tdifficult\n",
      "than\tthan\n",
      "supervised\tsupervis\n",
      "learning\tlearn\n",
      "and\tand\n",
      "typically\ttypic\n",
      "produces\tproduc\n",
      "less\tless\n",
      "accurate\taccur\n",
      "results\tresult\n",
      "for\tfor\n",
      "a\ta\n",
      "given\tgiven\n",
      "amount\tamount\n",
      "of\tof\n",
      "input\tinput\n",
      "data\tdata\n",
      "\n",
      "However\thowev\n",
      "there\tthere\n",
      "is\tis\n",
      "an\tan\n",
      "enormous\tenorm\n",
      "amount\tamount\n",
      "of\tof\n",
      "non-annotated\tnon-annot\n",
      "data\tdata\n",
      "available\tavail\n",
      "including\tinclud\n",
      "among\tamong\n",
      "other\tother\n",
      "things\tthing\n",
      "the\tthe\n",
      "entire\tentir\n",
      "content\tcontent\n",
      "of\tof\n",
      "the\tthe\n",
      "World\tworld\n",
      "Wide\twide\n",
      "Web\tweb\n",
      "which\twhich\n",
      "can\tcan\n",
      "often\toften\n",
      "make\tmake\n",
      "up\tup\n",
      "for\tfor\n",
      "the\tthe\n",
      "inferior\tinferior\n",
      "results\tresult\n",
      "\n",
      "NLP\tnlp\n",
      "using\tuse\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "Modern\tmodern\n",
      "NLP\tnlp\n",
      "algorithms\talgorithm\n",
      "are\tare\n",
      "based\tbase\n",
      "on\ton\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "especially\tespeci\n",
      "statistical\tstatist\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "\n",
      "The\tthe\n",
      "paradigm\tparadigm\n",
      "of\tof\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "is\tis\n",
      "different\tdiffer\n",
      "from\tfrom\n",
      "that\tthat\n",
      "of\tof\n",
      "most\tmost\n",
      "prior\tprior\n",
      "attempts\tattempt\n",
      "at\tat\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "\n",
      "Prior\tprior\n",
      "implementations\timplement\n",
      "of\tof\n",
      "language-processing\tlanguage-process\n",
      "tasks\ttask\n",
      "typically\ttypic\n",
      "involved\tinvolv\n",
      "the\tthe\n",
      "direct\tdirect\n",
      "hand\thand\n",
      "coding\tcode\n",
      "of\tof\n",
      "large\tlarg\n",
      "sets\tset\n",
      "of\tof\n",
      "rules\trule\n",
      "\n",
      "The\tthe\n",
      "machine-learning\tmachine-learn\n",
      "paradigm\tparadigm\n",
      "calls\tcall\n",
      "instead\tinstead\n",
      "for\tfor\n",
      "using\tuse\n",
      "general\tgener\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "-\t-\n",
      "often\toften\n",
      "although\talthough\n",
      "not\tnot\n",
      "always\talway\n",
      "grounded\tground\n",
      "in\tin\n",
      "statistical\tstatist\n",
      "inference\tinfer\n",
      "-\t-\n",
      "to\tto\n",
      "automatically\tautomat\n",
      "learn\tlearn\n",
      "such\tsuch\n",
      "rules\trule\n",
      "through\tthrough\n",
      "the\tthe\n",
      "analysis\tanalysi\n",
      "of\tof\n",
      "large\tlarg\n",
      "corpora\tcorpora\n",
      "of\tof\n",
      "typical\ttypic\n",
      "real-world\treal-world\n",
      "examples\texampl\n",
      "\n",
      "A\tA\n",
      "corpus\tcorpu\n",
      "plural\tplural\n",
      "corpora\tcorpora\n",
      "is\tis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\ta\n",
      "set\tset\n",
      "of\tof\n",
      "documents\tdocument\n",
      "or\tor\n",
      "sometimes\tsometim\n",
      "individual\tindividu\n",
      "sentences\tsentenc\n",
      "that\tthat\n",
      "have\thave\n",
      "been\tbeen\n",
      "hand-annotated\thand-annot\n",
      "with\twith\n",
      "the\tthe\n",
      "correct\tcorrect\n",
      "values\tvalu\n",
      "to\tto\n",
      "be\tbe\n",
      "learned\tlearn\n",
      "\n",
      "Many\tmani\n",
      "different\tdiffer\n",
      "classes\tclass\n",
      "of\tof\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "algorithms\talgorithm\n",
      "have\thave\n",
      "been\tbeen\n",
      "applied\tappli\n",
      "to\tto\n",
      "NLP\tnlp\n",
      "tasks\ttask\n",
      "\n",
      "These\tthese\n",
      "algorithms\talgorithm\n",
      "take\ttake\n",
      "as\tas\n",
      "input\tinput\n",
      "a\ta\n",
      "large\tlarg\n",
      "set\tset\n",
      "of\tof\n",
      "features\tfeatur\n",
      "that\tthat\n",
      "are\tare\n",
      "generated\tgener\n",
      "from\tfrom\n",
      "the\tthe\n",
      "input\tinput\n",
      "data\tdata\n",
      "\n",
      "Some\tsome\n",
      "of\tof\n",
      "the\tthe\n",
      "earliest-used\tearliest-us\n",
      "algorithms\talgorithm\n",
      "such\tsuch\n",
      "as\tas\n",
      "decision\tdecis\n",
      "trees\ttree\n",
      "produced\tproduc\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hard\thard\n",
      "if-then\tif-then\n",
      "rules\trule\n",
      "similar\tsimilar\n",
      "to\tto\n",
      "the\tthe\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "that\tthat\n",
      "were\twere\n",
      "then\tthen\n",
      "common\tcommon\n",
      "\n",
      "Increasingly\tincreasingli\n",
      "however\thowev\n",
      "research\tresearch\n",
      "has\tha\n",
      "focused\tfocus\n",
      "on\ton\n",
      "statistical\tstatist\n",
      "models\tmodel\n",
      "which\twhich\n",
      "make\tmake\n",
      "soft\tsoft\n",
      "probabilistic\tprobabilist\n",
      "decisions\tdecis\n",
      "based\tbase\n",
      "on\ton\n",
      "attaching\tattach\n",
      "real-valued\treal-valu\n",
      "weights\tweight\n",
      "to\tto\n",
      "each\teach\n",
      "input\tinput\n",
      "feature\tfeatur\n",
      "\n",
      "Such\tsuch\n",
      "models\tmodel\n",
      "have\thave\n",
      "the\tthe\n",
      "advantage\tadvantag\n",
      "that\tthat\n",
      "they\tthey\n",
      "can\tcan\n",
      "express\texpress\n",
      "the\tthe\n",
      "relative\trel\n",
      "certainty\tcertainti\n",
      "of\tof\n",
      "many\tmani\n",
      "different\tdiffer\n",
      "possible\tpossibl\n",
      "answers\tanswer\n",
      "rather\trather\n",
      "than\tthan\n",
      "only\tonli\n",
      "one\tone\n",
      "producing\tproduc\n",
      "more\tmore\n",
      "reliable\treliabl\n",
      "results\tresult\n",
      "when\twhen\n",
      "such\tsuch\n",
      "a\ta\n",
      "model\tmodel\n",
      "is\tis\n",
      "included\tinclud\n",
      "as\tas\n",
      "a\ta\n",
      "component\tcompon\n",
      "of\tof\n",
      "a\ta\n",
      "larger\tlarger\n",
      "system\tsystem\n",
      "\n",
      "Systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "machine-learning\tmachine-learn\n",
      "algorithms\talgorithm\n",
      "have\thave\n",
      "many\tmani\n",
      "advantages\tadvantag\n",
      "over\tover\n",
      "hand-produced\thand-produc\n",
      "rules\trule\n",
      "\n",
      "The\tthe\n",
      "learning\tlearn\n",
      "procedures\tprocedur\n",
      "used\tuse\n",
      "during\tdure\n",
      "machine\tmachin\n",
      "learning\tlearn\n",
      "automatically\tautomat\n",
      "focus\tfocu\n",
      "on\ton\n",
      "the\tthe\n",
      "most\tmost\n",
      "common\tcommon\n",
      "cases\tcase\n",
      "whereas\twherea\n",
      "when\twhen\n",
      "writing\twrite\n",
      "rules\trule\n",
      "by\tby\n",
      "hand\thand\n",
      "it\tit\n",
      "is\tis\n",
      "often\toften\n",
      "not\tnot\n",
      "obvious\tobviou\n",
      "at\tat\n",
      "all\tall\n",
      "where\twhere\n",
      "the\tthe\n",
      "effort\teffort\n",
      "should\tshould\n",
      "be\tbe\n",
      "directed\tdirect\n",
      "\n",
      "Automatic\tautomat\n",
      "learning\tlearn\n",
      "procedures\tprocedur\n",
      "can\tcan\n",
      "make\tmake\n",
      "use\tuse\n",
      "of\tof\n",
      "statistical\tstatist\n",
      "inference\tinfer\n",
      "algorithms\talgorithm\n",
      "to\tto\n",
      "produce\tproduc\n",
      "models\tmodel\n",
      "that\tthat\n",
      "are\tare\n",
      "robust\trobust\n",
      "to\tto\n",
      "unfamiliar\tunfamiliar\n",
      "input\tinput\n",
      "eg\teg\n",
      "containing\tcontain\n",
      "words\tword\n",
      "or\tor\n",
      "structures\tstructur\n",
      "that\tthat\n",
      "have\thave\n",
      "not\tnot\n",
      "been\tbeen\n",
      "seen\tseen\n",
      "before\tbefor\n",
      "and\tand\n",
      "to\tto\n",
      "erroneous\terron\n",
      "input\tinput\n",
      "eg\teg\n",
      "with\twith\n",
      "misspelled\tmisspel\n",
      "words\tword\n",
      "or\tor\n",
      "words\tword\n",
      "accidentally\taccident\n",
      "omitted\tomit\n",
      "\n",
      "Generally\tgener\n",
      "handling\thandl\n",
      "such\tsuch\n",
      "input\tinput\n",
      "gracefully\tgrace\n",
      "with\twith\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "--\t--\n",
      "or\tor\n",
      "more\tmore\n",
      "generally\tgener\n",
      "creating\tcreat\n",
      "systems\tsystem\n",
      "of\tof\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "that\tthat\n",
      "make\tmake\n",
      "soft\tsoft\n",
      "decisions\tdecis\n",
      "--\t--\n",
      "extremely\textrem\n",
      "difficult\tdifficult\n",
      "error-prone\terror-pron\n",
      "and\tand\n",
      "time-consuming\ttime-consum\n",
      "\n",
      "Systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "automatically\tautomat\n",
      "learning\tlearn\n",
      "the\tthe\n",
      "rules\trule\n",
      "can\tcan\n",
      "be\tbe\n",
      "made\tmade\n",
      "more\tmore\n",
      "accurate\taccur\n",
      "simply\tsimpli\n",
      "by\tby\n",
      "supplying\tsuppli\n",
      "more\tmore\n",
      "input\tinput\n",
      "data\tdata\n",
      "\n",
      "However\thowev\n",
      "systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "hand-written\thand-written\n",
      "rules\trule\n",
      "can\tcan\n",
      "only\tonli\n",
      "be\tbe\n",
      "made\tmade\n",
      "more\tmore\n",
      "accurate\taccur\n",
      "by\tby\n",
      "increasing\tincreas\n",
      "the\tthe\n",
      "complexity\tcomplex\n",
      "of\tof\n",
      "the\tthe\n",
      "rules\trule\n",
      "which\twhich\n",
      "is\tis\n",
      "a\ta\n",
      "much\tmuch\n",
      "more\tmore\n",
      "difficult\tdifficult\n",
      "task\ttask\n",
      "\n",
      "In\tIn\n",
      "particular\tparticular\n",
      "there\tthere\n",
      "is\tis\n",
      "a\ta\n",
      "limit\tlimit\n",
      "to\tto\n",
      "the\tthe\n",
      "complexity\tcomplex\n",
      "of\tof\n",
      "systems\tsystem\n",
      "based\tbase\n",
      "on\ton\n",
      "hand-crafted\thand-craft\n",
      "rules\trule\n",
      "beyond\tbeyond\n",
      "which\twhich\n",
      "the\tthe\n",
      "systems\tsystem\n",
      "become\tbecom\n",
      "more\tmore\n",
      "and\tand\n",
      "more\tmore\n",
      "unmanageable\tunmanag\n",
      "\n",
      "However\thowev\n",
      "creating\tcreat\n",
      "more\tmore\n",
      "data\tdata\n",
      "to\tto\n",
      "input\tinput\n",
      "to\tto\n",
      "machine-learning\tmachine-learn\n",
      "systems\tsystem\n",
      "simply\tsimpli\n",
      "requires\trequir\n",
      "a\ta\n",
      "corresponding\tcorrespond\n",
      "increase\tincreas\n",
      "in\tin\n",
      "the\tthe\n",
      "number\tnumber\n",
      "of\tof\n",
      "man-hours\tman-hour\n",
      "worked\twork\n",
      "generally\tgener\n",
      "without\twithout\n",
      "significant\tsignific\n",
      "increases\tincreas\n",
      "in\tin\n",
      "the\tthe\n",
      "complexity\tcomplex\n",
      "of\tof\n",
      "the\tthe\n",
      "annotation\tannot\n",
      "process\tprocess\n",
      "\n",
      "The\tthe\n",
      "subfield\tsubfield\n",
      "of\tof\n",
      "NLP\tnlp\n",
      "devoted\tdevot\n",
      "to\tto\n",
      "learning\tlearn\n",
      "approaches\tapproach\n",
      "is\tis\n",
      "known\tknown\n",
      "as\tas\n",
      "Natural\tnatur\n",
      "Language\tlanguag\n",
      "Learning\tlearn\n",
      "NLL\tnll\n",
      "and\tand\n",
      "its\tit\n",
      "conference\tconfer\n",
      "CoNLL\tconll\n",
      "and\tand\n",
      "peak\tpeak\n",
      "body\tbodi\n",
      "SIGNLL\tsignll\n",
      "are\tare\n",
      "sponsored\tsponsor\n",
      "by\tby\n",
      "ACL\tacl\n",
      "recognizing\trecogn\n",
      "also\talso\n",
      "their\ttheir\n",
      "links\tlink\n",
      "with\twith\n",
      "Computational\tcomput\n",
      "Linguistics\tlinguist\n",
      "and\tand\n",
      "Language\tlanguag\n",
      "Acquisition\tacquisit\n",
      "\n",
      "When\twhen\n",
      "the\tthe\n",
      "aims\taim\n",
      "of\tof\n",
      "computational\tcomput\n",
      "language\tlanguag\n",
      "learning\tlearn\n",
      "research\tresearch\n",
      "is\tis\n",
      "to\tto\n",
      "understand\tunderstand\n",
      "more\tmore\n",
      "about\tabout\n",
      "human\thuman\n",
      "language\tlanguag\n",
      "acquisition\tacquisit\n",
      "or\tor\n",
      "psycholinguistics\tpsycholinguist\n",
      "NLL\tnll\n",
      "overlaps\toverlap\n",
      "into\tinto\n",
      "the\tthe\n",
      "related\trelat\n",
      "field\tfield\n",
      "of\tof\n",
      "Computational\tcomput\n",
      "Psycholinguistics\tpsycholinguist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ws_per_sentences = [[(word, ps.stem(word)) for word in sentence] for sentence in words_per_sentences]\n",
    "\n",
    "for sentence in ws_per_sentences:\n",
    "    for word, stem in sentence:\n",
    "        print(word, stem, sep='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53. Tokenization\n",
    "[Stanford Core NLP](http://nlp.stanford.edu/software/corenlp.shtml)を用い，入力テキストの解析結果をXML形式で得よ．また，このXMLファイルを読み込み，入力テキストを1行1単語の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Searching for resource: StanfordCoreNLP.properties ... found.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.2 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580704 unique entries out of 581863 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4869 unique entries out of 4869 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585573 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat edu.stanford.nlp.parser.nndep.Classifier.preCompute(Classifier.java:662)\n",
      "\tat edu.stanford.nlp.parser.nndep.Classifier.preCompute(Classifier.java:644)\n",
      "\tat edu.stanford.nlp.parser.nndep.DependencyParser.initialize(DependencyParser.java:1189)\n",
      "\tat edu.stanford.nlp.parser.nndep.DependencyParser.loadModelFile(DependencyParser.java:630)\n",
      "\tat edu.stanford.nlp.parser.nndep.DependencyParser.loadFromModelFile(DependencyParser.java:499)\n",
      "\tat edu.stanford.nlp.pipeline.DependencyParseAnnotator.<init>(DependencyParseAnnotator.java:57)\n",
      "\tat edu.stanford.nlp.pipeline.AnnotatorImplementations.dependencies(AnnotatorImplementations.java:240)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.lambda$getNamedAnnotators$18(StanfordCoreNLP.java:536)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP$$Lambda$29/2083562754.apply(Unknown Source)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.lambda$null$30(StanfordCoreNLP.java:602)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP$$Lambda$38/1360767589.get(Unknown Source)\n",
      "\tat edu.stanford.nlp.util.Lazy$3.compute(Lazy.java:126)\n",
      "\tat edu.stanford.nlp.util.Lazy.get(Lazy.java:31)\n",
      "\tat edu.stanford.nlp.pipeline.AnnotatorPool.get(AnnotatorPool.java:149)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>(StanfordCoreNLP.java:251)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>(StanfordCoreNLP.java:192)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.<init>(StanfordCoreNLP.java:188)\n",
      "\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.main(StanfordCoreNLP.java:1388)\n"
     ]
    }
   ],
   "source": [
    "!java -cp \"stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -file nlp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリが足りないらしい。エラーメッセージでぐぐると下記がヒットした。最大1GBに設定している\n",
    "\n",
    "https://stackoverflow.com/questions/8967544/using-stanford-corenlp\n",
    "\n",
    "公式ドキュメンテーションによると2GBくらい必要とのこと。\n",
    "\n",
    "https://stanfordnlp.github.io/CoreNLP/cmdline.html#notes\n",
    "\n",
    "念のためjavaの引数を見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用方法: java [-options] class [args...]\r\n",
      "           (クラスを実行する場合)\r\n",
      "   または  java [-options] -jar jarfile [args...]\r\n",
      "           (jarファイルを実行する場合)\r\n",
      "optionsには次のものがあります。\r\n",
      "    -d32\t  使用可能な場合は32ビットのデータ・モデルを使用する\r\n",
      "    -d64\t  使用可能な場合は64ビットのデータ・モデルを使用する\r\n",
      "    -server\t  \"server\" VMを選択する場合\r\n",
      "                  デフォルトVMはserverです,\r\n",
      "                  これはサーバークラスのマシンで実行しているためです。\r\n",
      "\r\n",
      "\r\n",
      "    -cp <ディレクトリおよびzip/jarファイルのクラス検索パス>\r\n",
      "    -classpath <ディレクトリおよびzip/jarファイルのクラス検索パス>\r\n",
      "                  クラス・ファイルを検索するディレクトリ、\r\n",
      "                  JARアーカイブおよびZIPアーカイブの:で区切られたリストです。\r\n",
      "    -D<name>=<value>\r\n",
      "                  システム・プロパティを設定する\r\n",
      "    -verbose:[class|gc|jni]\r\n",
      "                  詳細な出力を行う\r\n",
      "    -version      製品バージョンを出力して終了する\r\n",
      "    -version:<value>\r\n",
      "                  警告: この機能は非推奨であり、詳細のリリースで\r\n",
      "                  廃止されます。\r\n",
      "                  指定したバージョンを実行に必須にする\r\n",
      "    -showversion  製品バージョンを出力して続行する\r\n",
      "    -jre-restrict-search | -no-jre-restrict-search\r\n",
      "                  警告: この機能は非推奨であり、詳細のリリースで\r\n",
      "                  廃止されます。\r\n",
      "                  ユーザーのプライベートJREをバージョン検索に含める/除外する\r\n",
      "    -? -help      このヘルプ・メッセージを出力する\r\n",
      "    -X            非標準オプションに関するヘルプを出力する\r\n",
      "    -ea[:<packagename>...|:<classname>]\r\n",
      "    -enableassertions[:<packagename>...|:<classname>]\r\n",
      "                  指定した粒度でアサーションを有効にする\r\n",
      "    -da[:<packagename>...|:<classname>]\r\n",
      "    -disableassertions[:<packagename>...|:<classname>]\r\n",
      "                  指定した粒度でアサーションを無効にする\r\n",
      "    -esa | -enablesystemassertions\r\n",
      "                  システム・アサーションを有効にする\r\n",
      "    -dsa | -disablesystemassertions\r\n",
      "                  システム・アサーションを無効にする\r\n",
      "    -agentlib:<libname>[=<options>]\r\n",
      "                  ネイティブ・エージェント・ライブラリ<libname>をロードする。例: -agentlib:hprof\r\n",
      "                  -agentlib:jdwp=helpと-agentlib:hprof=helpも参照\r\n",
      "    -agentpath:<pathname>[=<options>]\r\n",
      "                  フルパス名でネイティブ・エージェント・ライブラリをロードする\r\n",
      "    -javaagent:<jarpath>[=<options>]\r\n",
      "                  Javaプログラミング言語エージェントをロードする。java.lang.instrumentを参照\r\n",
      "    -splash:<imagepath>\r\n",
      "                  指定したイメージでスプラッシュ画面を表示する\r\n",
      "詳細はhttp://www.oracle.com/technetwork/java/javase/documentation/index.htmlを参照してください。\r\n"
     ]
    }
   ],
   "source": [
    "!java -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -Xmixed           混合モードの実行(デフォルト)\r\n",
      "    -Xint             インタプリタ・モードの実行のみ\r\n",
      "    -Xbootclasspath:<:で区切られたディレクトリおよびzip/jarファイル>\r\n",
      "                      ブートストラップのクラスとリソースの検索パスを設定する\r\n",
      "    -Xbootclasspath/a:<:で区切られたディレクトリおよびzip/jarファイル>\r\n",
      "                      ブートストラップ・クラス・パスの最後に追加する\r\n",
      "    -Xbootclasspath/p:<:で区切られたディレクトリおよびzip/jarファイル>\r\n",
      "                      ブートストラップ・クラス・パスの前に付加する\r\n",
      "    -Xdiag            追加の診断メッセージを表示する\r\n",
      "    -Xnoclassgc       クラスのガベージ・コレクションを無効にする\r\n",
      "    -Xincgc           増分ガベージ・コレクションを有効にする\r\n",
      "    -Xloggc:<file>    タイムスタンプが付いたファイルにGCステータスのログを記録する\r\n",
      "    -Xbatch           バックグラウンドのコンパイルを無効にする\r\n",
      "    -Xms<size>        Javaの初期ヒープ・サイズを設定する\r\n",
      "    -Xmx<size>        Javaの最大ヒープ・サイズを設定する\r\n",
      "    -Xss<size>        Javaのスレッド・スタック・サイズを設定する\r\n",
      "    -Xprof            CPUプロファイル・データを出力する\r\n",
      "    -Xfuture          将来のデフォルトを見越して、最も厳密なチェックを有効にする\r\n",
      "    -Xrs              Java/VMによるOSシグナルの使用を削減する(ドキュメントを参照)\r\n",
      "    -Xcheck:jni       JNI関数に対する追加のチェックを実行する\r\n",
      "    -Xshare:off       共有クラスのデータを使用しようとしない\r\n",
      "    -Xshare:auto      可能であれば共有クラスのデータを使用する(デフォルト)\r\n",
      "    -Xshare:on        共有クラス・データの使用を必須にし、できなければ失敗する。\r\n",
      "    -XshowSettings    すべての設定を表示して続行する\r\n",
      "    -XshowSettings:all\r\n",
      "                      すべての設定を表示して続行する\r\n",
      "    -XshowSettings:vm すべてのVM関連の設定を表示して続行する\r\n",
      "    -XshowSettings:properties\r\n",
      "                      すべてのプロパティ設定を表示して続行する\r\n",
      "    -XshowSettings:locale\r\n",
      "                      すべてのロケール関連の設定を表示して続行する\r\n",
      "\r\n",
      "-Xオプションは非標準なので、予告なく変更される場合があります。\r\n",
      "\r\n",
      "\r\n",
      "次のオプションはMac OS X固有です。\r\n",
      "    -XstartOnFirstThread\r\n",
      "                      main()メソッドを最初(AppKit)のスレッドで実行する\r\n",
      "    -Xdock:name=<application name>\"\r\n",
      "                      Dockに表示されるデフォルト・アプリケーション名をオーバーライドする\r\n",
      "    -Xdock:icon=<path to icon file>\r\n",
      "                      Dockに表示されるデフォルト・アイコンをオーバーライドする\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!java -X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Searching for resource: StanfordCoreNLP.properties ... found.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.3 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [2.1 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580704 unique entries out of 581863 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4869 unique entries out of 4869 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585573 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 16.93 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [27.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n",
      "[main] INFO edu.stanford.nlp.coref.statistical.SimpleLinearClassifier - Loading coref model edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz ... done [3.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency\n",
      "\n",
      "Processing file /Users/masato/Desktop/nlp100/nlp.txt ... writing to /Users/masato/Desktop/nlp100/nlp.txt.xml\n",
      "Annotating file /Users/masato/Desktop/nlp100/nlp.txt ... done [167.5 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "POSTaggerAnnotator: 0.2 sec.\n",
      "MorphaAnnotator: 0.1 sec.\n",
      "NERCombinerAnnotator: 117.2 sec.\n",
      "DependencyParseAnnotator: 1.7 sec.\n",
      "CorefAnnotator: 48.2 sec.\n",
      "TOTAL: 167.5 sec. for 1452 tokens at 8.7 tokens/sec.\n",
      "Pipeline setup: 109.3 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 277.1 sec.\n"
     ]
    }
   ],
   "source": [
    "# ヒープメモリを2GBにしてもエラーが消えなかったので、4GBでリトライ\n",
    "!java -Xmx4g -cp \"stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -file nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r",
      "\r\n",
      "<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\r",
      "\r\n",
      "<root>\r",
      "\r\n",
      "  <document>\r",
      "\r\n",
      "    <docId>nlp.txt</docId>\r",
      "\r\n",
      "    <sentences>\r",
      "\r\n",
      "      <sentence id=\"1\">\r",
      "\r\n",
      "        <tokens>\r",
      "\r\n",
      "          <token id=\"1\">\r",
      "\r\n",
      "            <word>Natural</word>\r",
      "\r\n",
      "            <lemma>natural</lemma>\r",
      "\r\n",
      "            <CharacterOffsetBegin>0</CharacterOffsetBegin>\r",
      "\r\n",
      "            <CharacterOffsetEnd>7</CharacterOffsetEnd>\r",
      "\r\n",
      "            <POS>JJ</POS>\r",
      "\r\n",
      "            <NER>O</NER>\r",
      "\r\n",
      "            <Speaker>PER0</Speaker>\r",
      "\r\n",
      "          </token>\r",
      "\r\n",
      "          <token id=\"2\">\r",
      "\r\n",
      "            <word>language</word>\r",
      "\r\n",
      "            <lemma>language</lemma>\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 nlp.txt.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ETree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlp.txt.xml') as f:\n",
    "    root = ETree.fromstring(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'root' at 0x1a18e674f8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'document' at 0x1a18e679f8>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'docId' at 0x1a18e675e8>,\n",
       " <Element 'sentences' at 0x1a18e67408>,\n",
       " <Element 'coreference' at 0x1a1a051868>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.getchildren()[0].getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'word' at 0x1a18e78cc8>,\n",
       " <Element 'word' at 0x1a18e787c8>,\n",
       " <Element 'word' at 0x1a18e78a48>,\n",
       " <Element 'word' at 0x1a18e780e8>,\n",
       " <Element 'word' at 0x1a18e78458>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_nodes = root.findall('./document/sentences/sentence/tokens/token/word')\n",
    "word_nodes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "From\n",
      "Wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "-LRB-\n",
      "NLP\n",
      "-RRB-\n",
      "is\n",
      "a\n",
      "field\n",
      "of\n",
      "computer\n",
      "science\n",
      ",\n",
      "artificial\n",
      "intelligence\n",
      ",\n",
      "and\n",
      "linguistics\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interactions\n",
      "between\n",
      "computers\n",
      "and\n",
      "human\n",
      "-LRB-\n",
      "natural\n",
      "-RRB-\n",
      "languages\n",
      ".\n",
      "As\n",
      "such\n",
      ",\n",
      "NLP\n",
      "is\n",
      "related\n",
      "to\n",
      "the\n",
      "area\n",
      "of\n",
      "humani-computer\n",
      "interaction\n",
      ".\n",
      "Many\n",
      "challenges\n",
      "in\n",
      "NLP\n",
      "involve\n",
      "natural\n",
      "language\n",
      "understanding\n",
      ",\n",
      "that\n",
      "is\n",
      ",\n",
      "enabling\n",
      "computers\n",
      "to\n",
      "derive\n",
      "meaning\n",
      "from\n",
      "human\n",
      "or\n",
      "natural\n",
      "language\n",
      "input\n",
      ",\n",
      "and\n",
      "others\n",
      "involve\n",
      "natural\n",
      "language\n",
      "generation\n",
      ".\n",
      "History\n",
      "The\n",
      "history\n",
      "of\n",
      "NLP\n",
      "generally\n",
      "starts\n",
      "in\n",
      "the\n",
      "1950s\n",
      ",\n",
      "although\n",
      "work\n",
      "can\n",
      "be\n",
      "found\n",
      "from\n",
      "earlier\n",
      "periods\n",
      ".\n",
      "In\n",
      "1950\n",
      ",\n",
      "Alan\n",
      "Turing\n",
      "published\n",
      "an\n",
      "article\n",
      "titled\n",
      "``\n",
      "Computing\n",
      "Machinery\n",
      "and\n",
      "Intelligence\n",
      "''\n",
      "which\n",
      "proposed\n",
      "what\n",
      "is\n",
      "now\n",
      "called\n",
      "the\n",
      "Turing\n",
      "test\n",
      "as\n",
      "a\n",
      "criterion\n",
      "of\n",
      "intelligence\n",
      ".\n",
      "The\n",
      "Georgetown\n",
      "experiment\n",
      "in\n",
      "1954\n",
      "involved\n",
      "fully\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "more\n",
      "than\n",
      "sixty\n",
      "Russian\n",
      "sentences\n",
      "into\n",
      "English\n",
      ".\n",
      "The\n",
      "authors\n",
      "claimed\n",
      "that\n",
      "within\n",
      "three\n",
      "or\n",
      "five\n",
      "years\n",
      ",\n",
      "machine\n",
      "translation\n",
      "would\n",
      "be\n",
      "a\n",
      "solved\n",
      "problem\n",
      ".\n",
      "However\n",
      ",\n",
      "real\n",
      "progress\n",
      "was\n",
      "much\n",
      "slower\n",
      ",\n",
      "and\n",
      "after\n",
      "the\n",
      "ALPAC\n",
      "report\n",
      "in\n",
      "1966\n",
      ",\n",
      "which\n",
      "found\n",
      "that\n",
      "ten\n",
      "year\n",
      "long\n",
      "research\n",
      "had\n",
      "failed\n",
      "to\n",
      "fulfill\n",
      "the\n",
      "expectations\n",
      ",\n",
      "funding\n",
      "for\n",
      "machine\n",
      "translation\n",
      "was\n",
      "dramatically\n",
      "reduced\n",
      ".\n",
      "Little\n",
      "further\n",
      "research\n",
      "in\n",
      "machine\n",
      "translation\n",
      "was\n",
      "conducted\n",
      "until\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "when\n",
      "the\n",
      "first\n",
      "statistical\n",
      "machine\n",
      "translation\n",
      "systems\n",
      "were\n",
      "developed\n",
      ".\n",
      "Some\n",
      "notably\n",
      "successful\n",
      "NLP\n",
      "systems\n",
      "developed\n",
      "in\n",
      "the\n",
      "1960s\n",
      "were\n",
      "SHRDLU\n",
      ",\n",
      "a\n",
      "natural\n",
      "language\n",
      "system\n",
      "working\n",
      "in\n",
      "restricted\n",
      "``\n",
      "blocks\n",
      "worlds\n",
      "''\n",
      "with\n",
      "restricted\n",
      "vocabularies\n",
      ",\n",
      "and\n",
      "ELIZA\n",
      ",\n",
      "a\n",
      "simulation\n",
      "of\n",
      "a\n",
      "Rogerian\n",
      "psychotherapist\n",
      ",\n",
      "written\n",
      "by\n",
      "Joseph\n",
      "Weizenbaum\n",
      "between\n",
      "1964\n",
      "to\n",
      "1966\n",
      ".\n",
      "Using\n",
      "almost\n",
      "no\n",
      "information\n",
      "about\n",
      "human\n",
      "thought\n",
      "or\n",
      "emotion\n",
      ",\n",
      "ELIZA\n",
      "sometimes\n",
      "provided\n",
      "a\n",
      "startlingly\n",
      "human-like\n",
      "interaction\n",
      ".\n",
      "When\n",
      "the\n",
      "``\n",
      "patient\n",
      "''\n",
      "exceeded\n",
      "the\n",
      "very\n",
      "small\n",
      "knowledge\n",
      "base\n",
      ",\n",
      "ELIZA\n",
      "might\n",
      "provide\n",
      "a\n",
      "generic\n",
      "response\n",
      ",\n",
      "for\n",
      "example\n",
      ",\n",
      "responding\n",
      "to\n",
      "``\n",
      "My\n",
      "head\n",
      "hurts\n",
      "''\n",
      "with\n",
      "``\n",
      "Why\n",
      "do\n",
      "you\n",
      "say\n",
      "your\n",
      "head\n",
      "hurts\n",
      "?\n",
      "''\n",
      ".\n",
      "During\n",
      "the\n",
      "1970s\n",
      "many\n",
      "programmers\n",
      "began\n",
      "to\n",
      "write\n",
      "`\n",
      "conceptual\n",
      "ontologies\n",
      "'\n",
      ",\n",
      "which\n",
      "structured\n",
      "real-world\n",
      "information\n",
      "into\n",
      "computer-understandable\n",
      "data\n",
      ".\n",
      "Examples\n",
      "are\n",
      "MARGIE\n",
      "-LRB-\n",
      "Schank\n",
      ",\n",
      "1975\n",
      "-RRB-\n",
      ",\n",
      "SAM\n",
      "-LRB-\n",
      "Cullingford\n",
      ",\n",
      "1978\n",
      "-RRB-\n",
      ",\n",
      "PAM\n",
      "-LRB-\n",
      "Wilensky\n",
      ",\n",
      "1978\n",
      "-RRB-\n",
      ",\n",
      "TaleSpin\n",
      "-LRB-\n",
      "Meehan\n",
      ",\n",
      "1976\n",
      "-RRB-\n",
      ",\n",
      "QUALM\n",
      "-LRB-\n",
      "Lehnert\n",
      ",\n",
      "1977\n",
      "-RRB-\n",
      ",\n",
      "Politics\n",
      "-LRB-\n",
      "Carbonell\n",
      ",\n",
      "1979\n",
      "-RRB-\n",
      ",\n",
      "and\n",
      "Plot\n",
      "Units\n",
      "-LRB-\n",
      "Lehnert\n",
      "1981\n",
      "-RRB-\n",
      ".\n",
      "During\n",
      "this\n",
      "time\n",
      ",\n",
      "many\n",
      "chatterbots\n",
      "were\n",
      "written\n",
      "including\n",
      "PARRY\n",
      ",\n",
      "Racter\n",
      ",\n",
      "and\n",
      "Jabberwacky\n",
      ".\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "NLP\n",
      "systems\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "sets\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      ".\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "however\n",
      ",\n",
      "there\n",
      "was\n",
      "a\n",
      "revolution\n",
      "in\n",
      "NLP\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "for\n",
      "language\n",
      "processing\n",
      ".\n",
      "This\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "resulting\n",
      "from\n",
      "Moore\n",
      "'s\n",
      "Law\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theories\n",
      "of\n",
      "linguistics\n",
      "-LRB-\n",
      "e.g.\n",
      "transformational\n",
      "grammar\n",
      "-RRB-\n",
      ",\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      ",\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      ",\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "existing\n",
      "hand-written\n",
      "rules\n",
      ".\n",
      "However\n",
      ",\n",
      "Part\n",
      "of\n",
      "speech\n",
      "tagging\n",
      "introduced\n",
      "the\n",
      "use\n",
      "of\n",
      "Hidden\n",
      "Markov\n",
      "Models\n",
      "to\n",
      "NLP\n",
      ",\n",
      "and\n",
      "increasingly\n",
      ",\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "the\n",
      "features\n",
      "making\n",
      "up\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "The\n",
      "cache\n",
      "language\n",
      "models\n",
      "upon\n",
      "which\n",
      "many\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "now\n",
      "rely\n",
      "are\n",
      "examples\n",
      "of\n",
      "such\n",
      "statistical\n",
      "models\n",
      ".\n",
      "Such\n",
      "models\n",
      "are\n",
      "generally\n",
      "more\n",
      "robust\n",
      "when\n",
      "given\n",
      "unfamiliar\n",
      "input\n",
      ",\n",
      "especially\n",
      "input\n",
      "that\n",
      "contains\n",
      "errors\n",
      "-LRB-\n",
      "as\n",
      "is\n",
      "very\n",
      "common\n",
      "for\n",
      "real-world\n",
      "data\n",
      "-RRB-\n",
      ",\n",
      "and\n",
      "produce\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "integrated\n",
      "into\n",
      "a\n",
      "larger\n",
      "system\n",
      "comprising\n",
      "multiple\n",
      "subtasks\n",
      ".\n",
      "Many\n",
      "of\n",
      "the\n",
      "notable\n",
      "early\n",
      "successes\n",
      "occurred\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "machine\n",
      "translation\n",
      ",\n",
      "due\n",
      "especially\n",
      "to\n",
      "work\n",
      "at\n",
      "IBM\n",
      "Research\n",
      ",\n",
      "where\n",
      "successively\n",
      "more\n",
      "complicated\n",
      "statistical\n",
      "models\n",
      "were\n",
      "developed\n",
      ".\n",
      "These\n",
      "systems\n",
      "were\n",
      "able\n",
      "to\n",
      "take\n",
      "advantage\n",
      "of\n",
      "existing\n",
      "multilingual\n",
      "textual\n",
      "corpora\n",
      "that\n",
      "had\n",
      "been\n",
      "produced\n",
      "by\n",
      "the\n",
      "Parliament\n",
      "of\n",
      "Canada\n",
      "and\n",
      "the\n",
      "European\n",
      "Union\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "laws\n",
      "calling\n",
      "for\n",
      "the\n",
      "translation\n",
      "of\n",
      "all\n",
      "governmental\n",
      "proceedings\n",
      "into\n",
      "all\n",
      "official\n",
      "languages\n",
      "of\n",
      "the\n",
      "corresponding\n",
      "systems\n",
      "of\n",
      "government\n",
      ".\n",
      "However\n",
      ",\n",
      "most\n",
      "other\n",
      "systems\n",
      "depended\n",
      "on\n",
      "corpora\n",
      "specifically\n",
      "developed\n",
      "for\n",
      "the\n",
      "tasks\n",
      "implemented\n",
      "by\n",
      "these\n",
      "systems\n",
      ",\n",
      "which\n",
      "was\n",
      "-LRB-\n",
      "and\n",
      "often\n",
      "continues\n",
      "to\n",
      "be\n",
      "-RRB-\n",
      "a\n",
      "major\n",
      "limitation\n",
      "in\n",
      "the\n",
      "success\n",
      "of\n",
      "these\n",
      "systems\n",
      ".\n",
      "As\n",
      "a\n",
      "result\n",
      ",\n",
      "a\n",
      "great\n",
      "deal\n",
      "of\n",
      "research\n",
      "has\n",
      "gone\n",
      "into\n",
      "methods\n",
      "of\n",
      "more\n",
      "effectively\n",
      "learning\n",
      "from\n",
      "limited\n",
      "amounts\n",
      "of\n",
      "data\n",
      ".\n",
      "Recent\n",
      "research\n",
      "has\n",
      "increasingly\n",
      "focused\n",
      "on\n",
      "unsupervised\n",
      "and\n",
      "semi-supervised\n",
      "learning\n",
      "algorithms\n",
      ".\n",
      "Such\n",
      "algorithms\n",
      "are\n",
      "able\n",
      "to\n",
      "learn\n",
      "from\n",
      "data\n",
      "that\n",
      "has\n",
      "not\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "desired\n",
      "answers\n",
      ",\n",
      "or\n",
      "using\n",
      "a\n",
      "combination\n",
      "of\n",
      "annotated\n",
      "and\n",
      "non-annotated\n",
      "data\n",
      ".\n",
      "Generally\n",
      ",\n",
      "this\n",
      "task\n",
      "is\n",
      "much\n",
      "more\n",
      "difficult\n",
      "than\n",
      "supervised\n",
      "learning\n",
      ",\n",
      "and\n",
      "typically\n",
      "produces\n",
      "less\n",
      "accurate\n",
      "results\n",
      "for\n",
      "a\n",
      "given\n",
      "amount\n",
      "of\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "there\n",
      "is\n",
      "an\n",
      "enormous\n",
      "amount\n",
      "of\n",
      "non-annotated\n",
      "data\n",
      "available\n",
      "-LRB-\n",
      "including\n",
      ",\n",
      "among\n",
      "other\n",
      "things\n",
      ",\n",
      "the\n",
      "entire\n",
      "content\n",
      "of\n",
      "the\n",
      "World\n",
      "Wide\n",
      "Web\n",
      "-RRB-\n",
      ",\n",
      "which\n",
      "can\n",
      "often\n",
      "make\n",
      "up\n",
      "for\n",
      "the\n",
      "inferior\n",
      "results\n",
      ".\n",
      "NLP\n",
      "using\n",
      "machine\n",
      "learning\n",
      "Modern\n",
      "NLP\n",
      "algorithms\n",
      "are\n",
      "based\n",
      "on\n",
      "machine\n",
      "learning\n",
      ",\n",
      "especially\n",
      "statistical\n",
      "machine\n",
      "learning\n",
      ".\n",
      "The\n",
      "paradigm\n",
      "of\n",
      "machine\n",
      "learning\n",
      "is\n",
      "different\n",
      "from\n",
      "that\n",
      "of\n",
      "most\n",
      "prior\n",
      "attempts\n",
      "at\n",
      "language\n",
      "processing\n",
      ".\n",
      "Prior\n",
      "implementations\n",
      "of\n",
      "language-processing\n",
      "tasks\n",
      "typically\n",
      "involved\n",
      "the\n",
      "direct\n",
      "hand\n",
      "coding\n",
      "of\n",
      "large\n",
      "sets\n",
      "of\n",
      "rules\n",
      ".\n",
      "The\n",
      "machine-learning\n",
      "paradigm\n",
      "calls\n",
      "instead\n",
      "for\n",
      "using\n",
      "general\n",
      "learning\n",
      "algorithms\n",
      "-\n",
      "often\n",
      ",\n",
      "although\n",
      "not\n",
      "always\n",
      ",\n",
      "grounded\n",
      "in\n",
      "statistical\n",
      "inference\n",
      "-\n",
      "to\n",
      "automatically\n",
      "learn\n",
      "such\n",
      "rules\n",
      "through\n",
      "the\n",
      "analysis\n",
      "of\n",
      "large\n",
      "corpora\n",
      "of\n",
      "typical\n",
      "real-world\n",
      "examples\n",
      ".\n",
      "A\n",
      "corpus\n",
      "-LRB-\n",
      "plural\n",
      ",\n",
      "``\n",
      "corpora\n",
      "''\n",
      "-RRB-\n",
      "is\n",
      "a\n",
      "set\n",
      "of\n",
      "documents\n",
      "-LRB-\n",
      "or\n",
      "sometimes\n",
      ",\n",
      "individual\n",
      "sentences\n",
      "-RRB-\n",
      "that\n",
      "have\n",
      "been\n",
      "hand-annotated\n",
      "with\n",
      "the\n",
      "correct\n",
      "values\n",
      "to\n",
      "be\n",
      "learned\n",
      ".\n",
      "Many\n",
      "different\n",
      "classes\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithms\n",
      "have\n",
      "been\n",
      "applied\n",
      "to\n",
      "NLP\n",
      "tasks\n",
      ".\n",
      "These\n",
      "algorithms\n",
      "take\n",
      "as\n",
      "input\n",
      "a\n",
      "large\n",
      "set\n",
      "of\n",
      "``\n",
      "features\n",
      "''\n",
      "that\n",
      "are\n",
      "generated\n",
      "from\n",
      "the\n",
      "input\n",
      "data\n",
      ".\n",
      "Some\n",
      "of\n",
      "the\n",
      "earliest-used\n",
      "algorithms\n",
      ",\n",
      "such\n",
      "as\n",
      "decision\n",
      "trees\n",
      ",\n",
      "produced\n",
      "systems\n",
      "of\n",
      "hard\n",
      "if-then\n",
      "rules\n",
      "similar\n",
      "to\n",
      "the\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "were\n",
      "then\n",
      "common\n",
      ".\n",
      "Increasingly\n",
      ",\n",
      "however\n",
      ",\n",
      "research\n",
      "has\n",
      "focused\n",
      "on\n",
      "statistical\n",
      "models\n",
      ",\n",
      "which\n",
      "make\n",
      "soft\n",
      ",\n",
      "probabilistic\n",
      "decisions\n",
      "based\n",
      "on\n",
      "attaching\n",
      "real-valued\n",
      "weights\n",
      "to\n",
      "each\n",
      "input\n",
      "feature\n",
      ".\n",
      "Such\n",
      "models\n",
      "have\n",
      "the\n",
      "advantage\n",
      "that\n",
      "they\n",
      "can\n",
      "express\n",
      "the\n",
      "relative\n",
      "certainty\n",
      "of\n",
      "many\n",
      "different\n",
      "possible\n",
      "answers\n",
      "rather\n",
      "than\n",
      "only\n",
      "one\n",
      ",\n",
      "producing\n",
      "more\n",
      "reliable\n",
      "results\n",
      "when\n",
      "such\n",
      "a\n",
      "model\n",
      "is\n",
      "included\n",
      "as\n",
      "a\n",
      "component\n",
      "of\n",
      "a\n",
      "larger\n",
      "system\n",
      ".\n",
      "Systems\n",
      "based\n",
      "on\n",
      "machine-learning\n",
      "algorithms\n",
      "have\n",
      "many\n",
      "advantages\n",
      "over\n",
      "hand-produced\n",
      "rules\n",
      ":\n",
      "The\n",
      "learning\n",
      "procedures\n",
      "used\n",
      "during\n",
      "machine\n",
      "learning\n",
      "automatically\n",
      "focus\n",
      "on\n",
      "the\n",
      "most\n",
      "common\n",
      "cases\n",
      ",\n",
      "whereas\n",
      "when\n",
      "writing\n",
      "rules\n",
      "by\n",
      "hand\n",
      "it\n",
      "is\n",
      "often\n",
      "not\n",
      "obvious\n",
      "at\n",
      "all\n",
      "where\n",
      "the\n",
      "effort\n",
      "should\n",
      "be\n",
      "directed\n",
      ".\n",
      "Automatic\n",
      "learning\n",
      "procedures\n",
      "can\n",
      "make\n",
      "use\n",
      "of\n",
      "statistical\n",
      "inference\n",
      "algorithms\n",
      "to\n",
      "produce\n",
      "models\n",
      "that\n",
      "are\n",
      "robust\n",
      "to\n",
      "unfamiliar\n",
      "input\n",
      "-LRB-\n",
      "e.g.\n",
      "containing\n",
      "words\n",
      "or\n",
      "structures\n",
      "that\n",
      "have\n",
      "not\n",
      "been\n",
      "seen\n",
      "before\n",
      "-RRB-\n",
      "and\n",
      "to\n",
      "erroneous\n",
      "input\n",
      "-LRB-\n",
      "e.g.\n",
      "with\n",
      "misspelled\n",
      "words\n",
      "or\n",
      "words\n",
      "accidentally\n",
      "omitted\n",
      "-RRB-\n",
      ".\n",
      "Generally\n",
      ",\n",
      "handling\n",
      "such\n",
      "input\n",
      "gracefully\n",
      "with\n",
      "hand-written\n",
      "rules\n",
      "--\n",
      "or\n",
      "more\n",
      "generally\n",
      ",\n",
      "creating\n",
      "systems\n",
      "of\n",
      "hand-written\n",
      "rules\n",
      "that\n",
      "make\n",
      "soft\n",
      "decisions\n",
      "--\n",
      "extremely\n",
      "difficult\n",
      ",\n",
      "error-prone\n",
      "and\n",
      "time-consuming\n",
      ".\n",
      "Systems\n",
      "based\n",
      "on\n",
      "automatically\n",
      "learning\n",
      "the\n",
      "rules\n",
      "can\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "simply\n",
      "by\n",
      "supplying\n",
      "more\n",
      "input\n",
      "data\n",
      ".\n",
      "However\n",
      ",\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-written\n",
      "rules\n",
      "can\n",
      "only\n",
      "be\n",
      "made\n",
      "more\n",
      "accurate\n",
      "by\n",
      "increasing\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "rules\n",
      ",\n",
      "which\n",
      "is\n",
      "a\n",
      "much\n",
      "more\n",
      "difficult\n",
      "task\n",
      ".\n",
      "In\n",
      "particular\n",
      ",\n",
      "there\n",
      "is\n",
      "a\n",
      "limit\n",
      "to\n",
      "the\n",
      "complexity\n",
      "of\n",
      "systems\n",
      "based\n",
      "on\n",
      "hand-crafted\n",
      "rules\n",
      ",\n",
      "beyond\n",
      "which\n",
      "the\n",
      "systems\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "unmanageable\n",
      ".\n",
      "However\n",
      ",\n",
      "creating\n",
      "more\n",
      "data\n",
      "to\n",
      "input\n",
      "to\n",
      "machine-learning\n",
      "systems\n",
      "simply\n",
      "requires\n",
      "a\n",
      "corresponding\n",
      "increase\n",
      "in\n",
      "the\n",
      "number\n",
      "of\n",
      "man-hours\n",
      "worked\n",
      ",\n",
      "generally\n",
      "without\n",
      "significant\n",
      "increases\n",
      "in\n",
      "the\n",
      "complexity\n",
      "of\n",
      "the\n",
      "annotation\n",
      "process\n",
      ".\n",
      "The\n",
      "subfield\n",
      "of\n",
      "NLP\n",
      "devoted\n",
      "to\n",
      "learning\n",
      "approaches\n",
      "is\n",
      "known\n",
      "as\n",
      "Natural\n",
      "Language\n",
      "Learning\n",
      "-LRB-\n",
      "NLL\n",
      "-RRB-\n",
      "and\n",
      "its\n",
      "conference\n",
      "CoNLL\n",
      "and\n",
      "peak\n",
      "body\n",
      "SIGNLL\n",
      "are\n",
      "sponsored\n",
      "by\n",
      "ACL\n",
      ",\n",
      "recognizing\n",
      "also\n",
      "their\n",
      "links\n",
      "with\n",
      "Computational\n",
      "Linguistics\n",
      "and\n",
      "Language\n",
      "Acquisition\n",
      ".\n",
      "When\n",
      "the\n",
      "aims\n",
      "of\n",
      "computational\n",
      "language\n",
      "learning\n",
      "research\n",
      "is\n",
      "to\n",
      "understand\n",
      "more\n",
      "about\n",
      "human\n",
      "language\n",
      "acquisition\n",
      ",\n",
      "or\n",
      "psycholinguistics\n",
      ",\n",
      "NLL\n",
      "overlaps\n",
      "into\n",
      "the\n",
      "related\n",
      "field\n",
      "of\n",
      "Computational\n",
      "Psycholinguistics\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word_node in word_nodes:\n",
    "    print(word_node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54. 品詞タグ付け\n",
    "Stanford Core NLPの解析結果XMLを読み込み，単語，レンマ，品詞をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = root.findall('./document/sentences/sentence/tokens/token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      "From\tfrom\tIN\n",
      "Wikipedia\tWikipedia\tNNP\n",
      ",\t,\t,\n",
      "the\tthe\tDT\n",
      "free\tfree\tJJ\n",
      "encyclopedia\tencyclopedia\tNN\n",
      "Natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "NLP\tnlp\tNN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "field\tfield\tNN\n",
      "of\tof\tIN\n",
      "computer\tcomputer\tNN\n",
      "science\tscience\tNN\n",
      ",\t,\t,\n",
      "artificial\tartificial\tJJ\n",
      "intelligence\tintelligence\tNN\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "linguistics\tlinguistics\tNNS\n",
      "concerned\tconcern\tVBN\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "interactions\tinteraction\tNNS\n",
      "between\tbetween\tIN\n",
      "computers\tcomputer\tNNS\n",
      "and\tand\tCC\n",
      "human\thuman\tJJ\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "natural\tnatural\tJJ\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "languages\tlanguage\tNNS\n",
      ".\t.\t.\n",
      "As\tas\tIN\n",
      "such\tsuch\tJJ\n",
      ",\t,\t,\n",
      "NLP\tnlp\tNN\n",
      "is\tbe\tVBZ\n",
      "related\trelate\tVBN\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "area\tarea\tNN\n",
      "of\tof\tIN\n",
      "humani-computer\thumani-computer\tJJ\n",
      "interaction\tinteraction\tNN\n",
      ".\t.\t.\n",
      "Many\tmany\tJJ\n",
      "challenges\tchallenge\tNNS\n",
      "in\tin\tIN\n",
      "NLP\tnlp\tNN\n",
      "involve\tinvolve\tVBP\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "understanding\tunderstanding\tNN\n",
      ",\t,\t,\n",
      "that\tthat\tWDT\n",
      "is\tbe\tVBZ\n",
      ",\t,\t,\n",
      "enabling\tenable\tVBG\n",
      "computers\tcomputer\tNNS\n",
      "to\tto\tTO\n",
      "derive\tderive\tVB\n",
      "meaning\tmeaning\tNN\n",
      "from\tfrom\tIN\n",
      "human\thuman\tJJ\n",
      "or\tor\tCC\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "input\tinput\tNN\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "others\tother\tNNS\n",
      "involve\tinvolve\tVBP\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "generation\tgeneration\tNN\n",
      ".\t.\t.\n",
      "History\thistory\tNN\n",
      "The\tthe\tDT\n",
      "history\thistory\tNN\n",
      "of\tof\tIN\n",
      "NLP\tNLP\tNNP\n",
      "generally\tgenerally\tRB\n",
      "starts\tstart\tVBZ\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "1950s\t1950s\tCD\n",
      ",\t,\t,\n",
      "although\talthough\tIN\n",
      "work\twork\tNN\n",
      "can\tcan\tMD\n",
      "be\tbe\tVB\n",
      "found\tfind\tVBN\n",
      "from\tfrom\tIN\n",
      "earlier\tearlier\tJJR\n",
      "periods\tperiod\tNNS\n",
      ".\t.\t.\n",
      "In\tin\tIN\n",
      "1950\t1950\tCD\n",
      ",\t,\t,\n",
      "Alan\tAlan\tNNP\n",
      "Turing\tTuring\tNNP\n",
      "published\tpublish\tVBD\n",
      "an\ta\tDT\n",
      "article\tarticle\tNN\n",
      "titled\ttitle\tVBN\n",
      "``\t``\t``\n",
      "Computing\tComputing\tNNP\n",
      "Machinery\tMachinery\tNNP\n",
      "and\tand\tCC\n",
      "Intelligence\tIntelligence\tNNP\n",
      "''\t''\t''\n",
      "which\twhich\tWDT\n",
      "proposed\tpropose\tVBD\n",
      "what\twhat\tWP\n",
      "is\tbe\tVBZ\n",
      "now\tnow\tRB\n",
      "called\tcall\tVBN\n",
      "the\tthe\tDT\n",
      "Turing\tturing\tJJ\n",
      "test\ttest\tNN\n",
      "as\tas\tIN\n",
      "a\ta\tDT\n",
      "criterion\tcriterion\tNN\n",
      "of\tof\tIN\n",
      "intelligence\tintelligence\tNN\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "Georgetown\tGeorgetown\tNNP\n",
      "experiment\texperiment\tNN\n",
      "in\tin\tIN\n",
      "1954\t1954\tCD\n",
      "involved\tinvolve\tVBN\n",
      "fully\tfully\tRB\n",
      "automatic\tautomatic\tJJ\n",
      "translation\ttranslation\tNN\n",
      "of\tof\tIN\n",
      "more\tmore\tJJR\n",
      "than\tthan\tIN\n",
      "sixty\tsixty\tCD\n",
      "Russian\trussian\tJJ\n",
      "sentences\tsentence\tNNS\n",
      "into\tinto\tIN\n",
      "English\tEnglish\tNNP\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "authors\tauthor\tNNS\n",
      "claimed\tclaim\tVBD\n",
      "that\tthat\tIN\n",
      "within\twithin\tIN\n",
      "three\tthree\tCD\n",
      "or\tor\tCC\n",
      "five\tfive\tCD\n",
      "years\tyear\tNNS\n",
      ",\t,\t,\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "would\twould\tMD\n",
      "be\tbe\tVB\n",
      "a\ta\tDT\n",
      "solved\tsolve\tVBN\n",
      "problem\tproblem\tNN\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "real\treal\tJJ\n",
      "progress\tprogress\tNN\n",
      "was\tbe\tVBD\n",
      "much\tmuch\tRB\n",
      "slower\tslower\tJJR\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "after\tafter\tIN\n",
      "the\tthe\tDT\n",
      "ALPAC\tALPAC\tNNP\n",
      "report\treport\tNN\n",
      "in\tin\tIN\n",
      "1966\t1966\tCD\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "found\tfind\tVBD\n",
      "that\tthat\tIN\n",
      "ten\tten\tCD\n",
      "year\tyear\tNN\n",
      "long\tlong\tRB\n",
      "research\tresearch\tNN\n",
      "had\thave\tVBD\n",
      "failed\tfail\tVBN\n",
      "to\tto\tTO\n",
      "fulfill\tfulfill\tVB\n",
      "the\tthe\tDT\n",
      "expectations\texpectation\tNNS\n",
      ",\t,\t,\n",
      "funding\tfund\tVBG\n",
      "for\tfor\tIN\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "was\tbe\tVBD\n",
      "dramatically\tdramatically\tRB\n",
      "reduced\treduce\tVBN\n",
      ".\t.\t.\n",
      "Little\tlittle\tJJ\n",
      "further\tfurther\tJJ\n",
      "research\tresearch\tNN\n",
      "in\tin\tIN\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "was\tbe\tVBD\n",
      "conducted\tconduct\tVBN\n",
      "until\tuntil\tIN\n",
      "the\tthe\tDT\n",
      "late\tlate\tJJ\n",
      "1980s\t1980\tNNS\n",
      ",\t,\t,\n",
      "when\twhen\tWRB\n",
      "the\tthe\tDT\n",
      "first\tfirst\tJJ\n",
      "statistical\tstatistical\tJJ\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      "systems\tsystem\tNNS\n",
      "were\tbe\tVBD\n",
      "developed\tdevelop\tVBN\n",
      ".\t.\t.\n",
      "Some\tsome\tDT\n",
      "notably\tnotably\tRB\n",
      "successful\tsuccessful\tJJ\n",
      "NLP\tnlp\tNN\n",
      "systems\tsystem\tNNS\n",
      "developed\tdevelop\tVBN\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "1960s\t1960\tNNS\n",
      "were\tbe\tVBD\n",
      "SHRDLU\tSHRDLU\tNNP\n",
      ",\t,\t,\n",
      "a\ta\tDT\n",
      "natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "system\tsystem\tNN\n",
      "working\twork\tVBG\n",
      "in\tin\tIN\n",
      "restricted\trestricted\tJJ\n",
      "``\t``\t``\n",
      "blocks\tblock\tNNS\n",
      "worlds\tworld\tNNS\n",
      "''\t''\t''\n",
      "with\twith\tIN\n",
      "restricted\trestricted\tJJ\n",
      "vocabularies\tvocabulary\tNNS\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "ELIZA\tELIZA\tNNP\n",
      ",\t,\t,\n",
      "a\ta\tDT\n",
      "simulation\tsimulation\tNN\n",
      "of\tof\tIN\n",
      "a\ta\tDT\n",
      "Rogerian\trogerian\tJJ\n",
      "psychotherapist\tpsychotherapist\tNN\n",
      ",\t,\t,\n",
      "written\twrite\tVBN\n",
      "by\tby\tIN\n",
      "Joseph\tJoseph\tNNP\n",
      "Weizenbaum\tWeizenbaum\tNNP\n",
      "between\tbetween\tIN\n",
      "1964\t1964\tCD\n",
      "to\tto\tTO\n",
      "1966\t1966\tCD\n",
      ".\t.\t.\n",
      "Using\tuse\tVBG\n",
      "almost\talmost\tRB\n",
      "no\tno\tDT\n",
      "information\tinformation\tNN\n",
      "about\tabout\tIN\n",
      "human\thuman\tJJ\n",
      "thought\tthought\tNN\n",
      "or\tor\tCC\n",
      "emotion\temotion\tNN\n",
      ",\t,\t,\n",
      "ELIZA\teliza\tNN\n",
      "sometimes\tsometimes\tRB\n",
      "provided\tprovide\tVBD\n",
      "a\ta\tDT\n",
      "startlingly\tstartlingly\tRB\n",
      "human-like\thuman-like\tJJ\n",
      "interaction\tinteraction\tNN\n",
      ".\t.\t.\n",
      "When\twhen\tWRB\n",
      "the\tthe\tDT\n",
      "``\t``\t``\n",
      "patient\tpatient\tNN\n",
      "''\t''\t''\n",
      "exceeded\texceed\tVBD\n",
      "the\tthe\tDT\n",
      "very\tvery\tRB\n",
      "small\tsmall\tJJ\n",
      "knowledge\tknowledge\tNN\n",
      "base\tbase\tNN\n",
      ",\t,\t,\n",
      "ELIZA\tELIZA\tNNP\n",
      "might\tmight\tMD\n",
      "provide\tprovide\tVB\n",
      "a\ta\tDT\n",
      "generic\tgeneric\tJJ\n",
      "response\tresponse\tNN\n",
      ",\t,\t,\n",
      "for\tfor\tIN\n",
      "example\texample\tNN\n",
      ",\t,\t,\n",
      "responding\trespond\tVBG\n",
      "to\tto\tTO\n",
      "``\t``\t``\n",
      "My\tmy\tPRP$\n",
      "head\thead\tNN\n",
      "hurts\thurt\tVBZ\n",
      "''\t''\t''\n",
      "with\twith\tIN\n",
      "``\t``\t``\n",
      "Why\twhy\tWRB\n",
      "do\tdo\tVBP\n",
      "you\tyou\tPRP\n",
      "say\tsay\tVB\n",
      "your\tyou\tPRP$\n",
      "head\thead\tNN\n",
      "hurts\thurt\tVBZ\n",
      "?\t?\t.\n",
      "''\t''\t''\n",
      ".\t.\t.\n",
      "During\tduring\tIN\n",
      "the\tthe\tDT\n",
      "1970s\t1970s\tCD\n",
      "many\tmany\tJJ\n",
      "programmers\tprogrammer\tNNS\n",
      "began\tbegin\tVBD\n",
      "to\tto\tTO\n",
      "write\twrite\tVB\n",
      "`\t`\t``\n",
      "conceptual\tconceptual\tJJ\n",
      "ontologies\tontology\tNNS\n",
      "'\t'\tPOS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "structured\tstructure\tVBD\n",
      "real-world\treal-world\tJJ\n",
      "information\tinformation\tNN\n",
      "into\tinto\tIN\n",
      "computer-understandable\tcomputer-understandable\tJJ\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Examples\texample\tNNS\n",
      "are\tbe\tVBP\n",
      "MARGIE\tMARGIE\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Schank\tSchank\tNNP\n",
      ",\t,\t,\n",
      "1975\t1975\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "SAM\tSAM\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Cullingford\tCullingford\tNNP\n",
      ",\t,\t,\n",
      "1978\t1978\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "PAM\tpam\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Wilensky\tWilensky\tNNP\n",
      ",\t,\t,\n",
      "1978\t1978\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "TaleSpin\tTaleSpin\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Meehan\tMeehan\tNNP\n",
      ",\t,\t,\n",
      "1976\t1976\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "QUALM\tqualm\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Lehnert\tlehnert\tNN\n",
      ",\t,\t,\n",
      "1977\t1977\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "Politics\tpolitics\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Carbonell\tCarbonell\tNNP\n",
      ",\t,\t,\n",
      "1979\t1979\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "Plot\tplot\tNN\n",
      "Units\tunit\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "Lehnert\tLehnert\tNNP\n",
      "1981\t1981\tCD\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ".\t.\t.\n",
      "During\tduring\tIN\n",
      "this\tthis\tDT\n",
      "time\ttime\tNN\n",
      ",\t,\t,\n",
      "many\tmany\tJJ\n",
      "chatterbots\tchatterbot\tNNS\n",
      "were\tbe\tVBD\n",
      "written\twrite\tVBN\n",
      "including\tinclude\tVBG\n",
      "PARRY\tPARRY\tNNP\n",
      ",\t,\t,\n",
      "Racter\tRacter\tNNP\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "Jabberwacky\tJabberwacky\tNNP\n",
      ".\t.\t.\n",
      "Up\tup\tIN\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "1980s\t1980\tNNS\n",
      ",\t,\t,\n",
      "most\tmost\tJJS\n",
      "NLP\tnlp\tNNS\n",
      "systems\tsystem\tNNS\n",
      "were\tbe\tVBD\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "complex\tcomplex\tJJ\n",
      "sets\tset\tNNS\n",
      "of\tof\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      ".\t.\t.\n",
      "Starting\tstart\tVBG\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "late\tlate\tJJ\n",
      "1980s\t1980\tNNS\n",
      ",\t,\t,\n",
      "however\thowever\tRB\n",
      ",\t,\t,\n",
      "there\tthere\tEX\n",
      "was\tbe\tVBD\n",
      "a\ta\tDT\n",
      "revolution\trevolution\tNN\n",
      "in\tin\tIN\n",
      "NLP\tnlp\tNN\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "introduction\tintroduction\tNN\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "for\tfor\tIN\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      ".\t.\t.\n",
      "This\tthis\tDT\n",
      "was\tbe\tVBD\n",
      "due\tdue\tJJ\n",
      "to\tto\tTO\n",
      "both\tboth\tCC\n",
      "the\tthe\tDT\n",
      "steady\tsteady\tJJ\n",
      "increase\tincrease\tNN\n",
      "in\tin\tIN\n",
      "computational\tcomputational\tJJ\n",
      "power\tpower\tNN\n",
      "resulting\tresult\tVBG\n",
      "from\tfrom\tIN\n",
      "Moore\tMoore\tNNP\n",
      "'s\t's\tPOS\n",
      "Law\tlaw\tNN\n",
      "and\tand\tCC\n",
      "the\tthe\tDT\n",
      "gradual\tgradual\tJJ\n",
      "lessening\tlessen\tVBG\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "dominance\tdominance\tNN\n",
      "of\tof\tIN\n",
      "Chomskyan\tChomskyan\tNNP\n",
      "theories\ttheory\tNNS\n",
      "of\tof\tIN\n",
      "linguistics\tlinguistics\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "e.g.\te.g.\tFW\n",
      "transformational\ttransformational\tJJ\n",
      "grammar\tgrammar\tNN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "whose\twhose\tWP$\n",
      "theoretical\ttheoretical\tJJ\n",
      "underpinnings\tunderpinning\tNNS\n",
      "discouraged\tdiscourage\tVBD\n",
      "the\tthe\tDT\n",
      "sort\tsort\tNN\n",
      "of\tof\tIN\n",
      "corpus\tcorpus\tNN\n",
      "linguistics\tlinguistics\tNNS\n",
      "that\tthat\tWDT\n",
      "underlies\tunderlie\tVBZ\n",
      "the\tthe\tDT\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "approach\tapproach\tNN\n",
      "to\tto\tTO\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      ".\t.\t.\n",
      "Some\tsome\tDT\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "earliest-used\tearliest-used\tJJ\n",
      "machine\tmachine\tNN\n",
      "learning\tlearn\tVBG\n",
      "algorithms\talgorithm\tNNS\n",
      ",\t,\t,\n",
      "such\tsuch\tJJ\n",
      "as\tas\tIN\n",
      "decision\tdecision\tNN\n",
      "trees\ttree\tNNS\n",
      ",\t,\t,\n",
      "produced\tproduce\tVBD\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hard\thard\tJJ\n",
      "if-then\tif-then\tJJ\n",
      "rules\trule\tNNS\n",
      "similar\tsimilar\tJJ\n",
      "to\tto\tTO\n",
      "existing\texist\tVBG\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "Part\tpart\tNN\n",
      "of\tof\tIN\n",
      "speech\tspeech\tNN\n",
      "tagging\ttag\tVBG\n",
      "introduced\tintroduce\tVBN\n",
      "the\tthe\tDT\n",
      "use\tuse\tNN\n",
      "of\tof\tIN\n",
      "Hidden\tHidden\tNNP\n",
      "Markov\tMarkov\tNNP\n",
      "Models\tmodel\tNNS\n",
      "to\tto\tTO\n",
      "NLP\tNLP\tNNP\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "increasingly\tincreasingly\tRB\n",
      ",\t,\t,\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "focused\tfocus\tVBN\n",
      "on\ton\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "make\tmake\tVBP\n",
      "soft\tsoft\tJJ\n",
      ",\t,\t,\n",
      "probabilistic\tprobabilistic\tJJ\n",
      "decisions\tdecision\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "attaching\tattach\tVBG\n",
      "real-valued\treal-valued\tJJ\n",
      "weights\tweight\tNNS\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "features\tfeature\tNNS\n",
      "making\tmake\tVBG\n",
      "up\tup\tRP\n",
      "the\tthe\tDT\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "cache\tcache\tNN\n",
      "language\tlanguage\tNN\n",
      "models\tmodel\tNNS\n",
      "upon\tupon\tIN\n",
      "which\twhich\tWDT\n",
      "many\tmany\tJJ\n",
      "speech\tspeech\tNN\n",
      "recognition\trecognition\tNN\n",
      "systems\tsystem\tNNS\n",
      "now\tnow\tRB\n",
      "rely\trely\tVBP\n",
      "are\tbe\tVBP\n",
      "examples\texample\tNNS\n",
      "of\tof\tIN\n",
      "such\tsuch\tJJ\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      ".\t.\t.\n",
      "Such\tsuch\tJJ\n",
      "models\tmodel\tNNS\n",
      "are\tbe\tVBP\n",
      "generally\tgenerally\tRB\n",
      "more\tmore\tRBR\n",
      "robust\trobust\tJJ\n",
      "when\twhen\tWRB\n",
      "given\tgive\tVBN\n",
      "unfamiliar\tunfamiliar\tJJ\n",
      "input\tinput\tNN\n",
      ",\t,\t,\n",
      "especially\tespecially\tRB\n",
      "input\tinput\tNN\n",
      "that\tthat\tWDT\n",
      "contains\tcontain\tVBZ\n",
      "errors\terror\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "as\tas\tRB\n",
      "is\tbe\tVBZ\n",
      "very\tvery\tRB\n",
      "common\tcommon\tJJ\n",
      "for\tfor\tIN\n",
      "real-world\treal-world\tJJ\n",
      "data\tdatum\tNNS\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "produce\tproduce\tVB\n",
      "more\tmore\tJJR\n",
      "reliable\treliable\tJJ\n",
      "results\tresult\tNNS\n",
      "when\twhen\tWRB\n",
      "integrated\tintegrate\tVBN\n",
      "into\tinto\tIN\n",
      "a\ta\tDT\n",
      "larger\tlarger\tJJR\n",
      "system\tsystem\tNN\n",
      "comprising\tcomprise\tVBG\n",
      "multiple\tmultiple\tJJ\n",
      "subtasks\tsubtask\tNNS\n",
      ".\t.\t.\n",
      "Many\tmany\tJJ\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "notable\tnotable\tJJ\n",
      "early\tearly\tJJ\n",
      "successes\tsuccess\tNNS\n",
      "occurred\toccur\tVBD\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field\tfield\tNN\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "translation\ttranslation\tNN\n",
      ",\t,\t,\n",
      "due\tdue\tJJ\n",
      "especially\tespecially\tRB\n",
      "to\tto\tTO\n",
      "work\twork\tVB\n",
      "at\tat\tIN\n",
      "IBM\tIBM\tNNP\n",
      "Research\tResearch\tNNP\n",
      ",\t,\t,\n",
      "where\twhere\tWRB\n",
      "successively\tsuccessively\tRB\n",
      "more\tmore\tRBR\n",
      "complicated\tcomplicated\tJJ\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      "were\tbe\tVBD\n",
      "developed\tdevelop\tVBN\n",
      ".\t.\t.\n",
      "These\tthese\tDT\n",
      "systems\tsystem\tNNS\n",
      "were\tbe\tVBD\n",
      "able\table\tJJ\n",
      "to\tto\tTO\n",
      "take\ttake\tVB\n",
      "advantage\tadvantage\tNN\n",
      "of\tof\tIN\n",
      "existing\texist\tVBG\n",
      "multilingual\tmultilingual\tJJ\n",
      "textual\ttextual\tJJ\n",
      "corpora\tcorpora\tNN\n",
      "that\tthat\tWDT\n",
      "had\thave\tVBD\n",
      "been\tbe\tVBN\n",
      "produced\tproduce\tVBN\n",
      "by\tby\tIN\n",
      "the\tthe\tDT\n",
      "Parliament\tParliament\tNNP\n",
      "of\tof\tIN\n",
      "Canada\tCanada\tNNP\n",
      "and\tand\tCC\n",
      "the\tthe\tDT\n",
      "European\tEuropean\tNNP\n",
      "Union\tUnion\tNNP\n",
      "as\tas\tIN\n",
      "a\ta\tDT\n",
      "result\tresult\tNN\n",
      "of\tof\tIN\n",
      "laws\tlaw\tNNS\n",
      "calling\tcall\tVBG\n",
      "for\tfor\tIN\n",
      "the\tthe\tDT\n",
      "translation\ttranslation\tNN\n",
      "of\tof\tIN\n",
      "all\tall\tDT\n",
      "governmental\tgovernmental\tJJ\n",
      "proceedings\tproceedings\tNNS\n",
      "into\tinto\tIN\n",
      "all\tall\tDT\n",
      "official\tofficial\tJJ\n",
      "languages\tlanguage\tNNS\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "corresponding\tcorresponding\tJJ\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "government\tgovernment\tNN\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "most\tmost\tRBS\n",
      "other\tother\tJJ\n",
      "systems\tsystem\tNNS\n",
      "depended\tdepend\tVBD\n",
      "on\ton\tIN\n",
      "corpora\tcorpora\tNN\n",
      "specifically\tspecifically\tRB\n",
      "developed\tdevelop\tVBD\n",
      "for\tfor\tIN\n",
      "the\tthe\tDT\n",
      "tasks\ttask\tNNS\n",
      "implemented\timplement\tVBN\n",
      "by\tby\tIN\n",
      "these\tthese\tDT\n",
      "systems\tsystem\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "was\tbe\tVBD\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "and\tand\tCC\n",
      "often\toften\tRB\n",
      "continues\tcontinue\tVBZ\n",
      "to\tto\tTO\n",
      "be\tbe\tVB\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "a\ta\tDT\n",
      "major\tmajor\tJJ\n",
      "limitation\tlimitation\tNN\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "success\tsuccess\tNN\n",
      "of\tof\tIN\n",
      "these\tthese\tDT\n",
      "systems\tsystem\tNNS\n",
      ".\t.\t.\n",
      "As\tas\tIN\n",
      "a\ta\tDT\n",
      "result\tresult\tNN\n",
      ",\t,\t,\n",
      "a\ta\tDT\n",
      "great\tgreat\tJJ\n",
      "deal\tdeal\tNN\n",
      "of\tof\tIN\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "gone\tgo\tVBN\n",
      "into\tinto\tIN\n",
      "methods\tmethod\tNNS\n",
      "of\tof\tIN\n",
      "more\tmore\tJJR\n",
      "effectively\teffectively\tRB\n",
      "learning\tlearn\tVBG\n",
      "from\tfrom\tIN\n",
      "limited\tlimited\tJJ\n",
      "amounts\tamount\tNNS\n",
      "of\tof\tIN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Recent\trecent\tJJ\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "increasingly\tincreasingly\tRB\n",
      "focused\tfocus\tVBN\n",
      "on\ton\tIN\n",
      "unsupervised\tunsupervised\tJJ\n",
      "and\tand\tCC\n",
      "semi-supervised\tsemi-supervised\tJJ\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      ".\t.\t.\n",
      "Such\tsuch\tJJ\n",
      "algorithms\talgorithm\tNNS\n",
      "are\tbe\tVBP\n",
      "able\table\tJJ\n",
      "to\tto\tTO\n",
      "learn\tlearn\tVB\n",
      "from\tfrom\tIN\n",
      "data\tdatum\tNNS\n",
      "that\tthat\tWDT\n",
      "has\thave\tVBZ\n",
      "not\tnot\tRB\n",
      "been\tbe\tVBN\n",
      "hand-annotated\thand-annotate\tVBN\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "desired\tdesire\tVBN\n",
      "answers\tanswer\tNNS\n",
      ",\t,\t,\n",
      "or\tor\tCC\n",
      "using\tuse\tVBG\n",
      "a\ta\tDT\n",
      "combination\tcombination\tNN\n",
      "of\tof\tIN\n",
      "annotated\tannotated\tJJ\n",
      "and\tand\tCC\n",
      "non-annotated\tnon-annotated\tJJ\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Generally\tgenerally\tRB\n",
      ",\t,\t,\n",
      "this\tthis\tDT\n",
      "task\ttask\tNN\n",
      "is\tbe\tVBZ\n",
      "much\tmuch\tRB\n",
      "more\tmore\tRBR\n",
      "difficult\tdifficult\tJJ\n",
      "than\tthan\tIN\n",
      "supervised\tsupervised\tJJ\n",
      "learning\tlearning\tNN\n",
      ",\t,\t,\n",
      "and\tand\tCC\n",
      "typically\ttypically\tRB\n",
      "produces\tproduce\tVBZ\n",
      "less\tless\tJJR\n",
      "accurate\taccurate\tJJ\n",
      "results\tresult\tNNS\n",
      "for\tfor\tIN\n",
      "a\ta\tDT\n",
      "given\tgive\tVBN\n",
      "amount\tamount\tNN\n",
      "of\tof\tIN\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "there\tthere\tEX\n",
      "is\tbe\tVBZ\n",
      "an\ta\tDT\n",
      "enormous\tenormous\tJJ\n",
      "amount\tamount\tNN\n",
      "of\tof\tIN\n",
      "non-annotated\tnon-annotated\tJJ\n",
      "data\tdatum\tNNS\n",
      "available\tavailable\tJJ\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "including\tinclude\tVBG\n",
      ",\t,\t,\n",
      "among\tamong\tIN\n",
      "other\tother\tJJ\n",
      "things\tthing\tNNS\n",
      ",\t,\t,\n",
      "the\tthe\tDT\n",
      "entire\tentire\tJJ\n",
      "content\tcontent\tNN\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "World\tWorld\tNNP\n",
      "Wide\twide\tNN\n",
      "Web\tweb\tNN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "can\tcan\tMD\n",
      "often\toften\tRB\n",
      "make\tmake\tVB\n",
      "up\tup\tRP\n",
      "for\tfor\tIN\n",
      "the\tthe\tDT\n",
      "inferior\tinferior\tJJ\n",
      "results\tresult\tNNS\n",
      ".\t.\t.\n",
      "NLP\tnlp\tNN\n",
      "using\tuse\tVBG\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "Modern\tModern\tNNP\n",
      "NLP\tNLP\tNNP\n",
      "algorithms\talgorithm\tNNS\n",
      "are\tbe\tVBP\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      ",\t,\t,\n",
      "especially\tespecially\tRB\n",
      "statistical\tstatistical\tJJ\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "paradigm\tparadigm\tNN\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "is\tbe\tVBZ\n",
      "different\tdifferent\tJJ\n",
      "from\tfrom\tIN\n",
      "that\tthat\tDT\n",
      "of\tof\tIN\n",
      "most\tmost\tJJS\n",
      "prior\tprior\tJJ\n",
      "attempts\tattempt\tNNS\n",
      "at\tat\tIN\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      ".\t.\t.\n",
      "Prior\tprior\tRB\n",
      "implementations\timplementation\tNNS\n",
      "of\tof\tIN\n",
      "language-processing\tlanguage-processing\tJJ\n",
      "tasks\ttask\tNNS\n",
      "typically\ttypically\tRB\n",
      "involved\tinvolve\tVBD\n",
      "the\tthe\tDT\n",
      "direct\tdirect\tJJ\n",
      "hand\thand\tNN\n",
      "coding\tcoding\tNN\n",
      "of\tof\tIN\n",
      "large\tlarge\tJJ\n",
      "sets\tset\tNNS\n",
      "of\tof\tIN\n",
      "rules\trule\tNNS\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "paradigm\tparadigm\tNN\n",
      "calls\tcall\tVBZ\n",
      "instead\tinstead\tRB\n",
      "for\tfor\tIN\n",
      "using\tuse\tVBG\n",
      "general\tgeneral\tJJ\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "-\t-\t:\n",
      "often\toften\tRB\n",
      ",\t,\t,\n",
      "although\talthough\tIN\n",
      "not\tnot\tRB\n",
      "always\talways\tRB\n",
      ",\t,\t,\n",
      "grounded\tground\tVBN\n",
      "in\tin\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "inference\tinference\tNN\n",
      "-\t-\t:\n",
      "to\tto\tTO\n",
      "automatically\tautomatically\tRB\n",
      "learn\tlearn\tVB\n",
      "such\tsuch\tJJ\n",
      "rules\trule\tNNS\n",
      "through\tthrough\tIN\n",
      "the\tthe\tDT\n",
      "analysis\tanalysis\tNN\n",
      "of\tof\tIN\n",
      "large\tlarge\tJJ\n",
      "corpora\tcorpora\tNN\n",
      "of\tof\tIN\n",
      "typical\ttypical\tJJ\n",
      "real-world\treal-world\tJJ\n",
      "examples\texample\tNNS\n",
      ".\t.\t.\n",
      "A\ta\tDT\n",
      "corpus\tcorpus\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "plural\tplural\tNN\n",
      ",\t,\t,\n",
      "``\t``\t``\n",
      "corpora\tcorpora\tNN\n",
      "''\t''\t''\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "set\tset\tNN\n",
      "of\tof\tIN\n",
      "documents\tdocument\tNNS\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "or\tor\tCC\n",
      "sometimes\tsometimes\tRB\n",
      ",\t,\t,\n",
      "individual\tindividual\tJJ\n",
      "sentences\tsentence\tNNS\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "that\tthat\tWDT\n",
      "have\thave\tVBP\n",
      "been\tbe\tVBN\n",
      "hand-annotated\thand-annotated\tJJ\n",
      "with\twith\tIN\n",
      "the\tthe\tDT\n",
      "correct\tcorrect\tJJ\n",
      "values\tvalue\tNNS\n",
      "to\tto\tTO\n",
      "be\tbe\tVB\n",
      "learned\tlearn\tVBN\n",
      ".\t.\t.\n",
      "Many\tmany\tJJ\n",
      "different\tdifferent\tJJ\n",
      "classes\tclass\tNNS\n",
      "of\tof\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "have\thave\tVBP\n",
      "been\tbe\tVBN\n",
      "applied\tapply\tVBN\n",
      "to\tto\tTO\n",
      "NLP\tnlp\tNN\n",
      "tasks\ttask\tNNS\n",
      ".\t.\t.\n",
      "These\tthese\tDT\n",
      "algorithms\talgorithm\tNNS\n",
      "take\ttake\tVBP\n",
      "as\tas\tRB\n",
      "input\tinput\tNN\n",
      "a\ta\tDT\n",
      "large\tlarge\tJJ\n",
      "set\tset\tNN\n",
      "of\tof\tIN\n",
      "``\t``\t``\n",
      "features\tfeature\tNNS\n",
      "''\t''\t''\n",
      "that\tthat\tWDT\n",
      "are\tbe\tVBP\n",
      "generated\tgenerate\tVBN\n",
      "from\tfrom\tIN\n",
      "the\tthe\tDT\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "Some\tsome\tDT\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "earliest-used\tearliest-used\tJJ\n",
      "algorithms\talgorithm\tNNS\n",
      ",\t,\t,\n",
      "such\tsuch\tJJ\n",
      "as\tas\tIN\n",
      "decision\tdecision\tNN\n",
      "trees\ttree\tNNS\n",
      ",\t,\t,\n",
      "produced\tproduce\tVBD\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hard\thard\tJJ\n",
      "if-then\tif-then\tJJ\n",
      "rules\trule\tNNS\n",
      "similar\tsimilar\tJJ\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "that\tthat\tWDT\n",
      "were\tbe\tVBD\n",
      "then\tthen\tRB\n",
      "common\tcommon\tJJ\n",
      ".\t.\t.\n",
      "Increasingly\tincreasingly\tRB\n",
      ",\t,\t,\n",
      "however\thowever\tRB\n",
      ",\t,\t,\n",
      "research\tresearch\tNN\n",
      "has\thave\tVBZ\n",
      "focused\tfocus\tVBN\n",
      "on\ton\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "models\tmodel\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "make\tmake\tVBP\n",
      "soft\tsoft\tJJ\n",
      ",\t,\t,\n",
      "probabilistic\tprobabilistic\tJJ\n",
      "decisions\tdecision\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "attaching\tattach\tVBG\n",
      "real-valued\treal-valued\tJJ\n",
      "weights\tweight\tNNS\n",
      "to\tto\tTO\n",
      "each\teach\tDT\n",
      "input\tinput\tNN\n",
      "feature\tfeature\tNN\n",
      ".\t.\t.\n",
      "Such\tsuch\tJJ\n",
      "models\tmodel\tNNS\n",
      "have\thave\tVBP\n",
      "the\tthe\tDT\n",
      "advantage\tadvantage\tNN\n",
      "that\tthat\tIN\n",
      "they\tthey\tPRP\n",
      "can\tcan\tMD\n",
      "express\texpress\tVB\n",
      "the\tthe\tDT\n",
      "relative\trelative\tJJ\n",
      "certainty\tcertainty\tNN\n",
      "of\tof\tIN\n",
      "many\tmany\tJJ\n",
      "different\tdifferent\tJJ\n",
      "possible\tpossible\tJJ\n",
      "answers\tanswer\tNNS\n",
      "rather\trather\tRB\n",
      "than\tthan\tIN\n",
      "only\tonly\tRB\n",
      "one\tone\tCD\n",
      ",\t,\t,\n",
      "producing\tproduce\tVBG\n",
      "more\tmore\tJJR\n",
      "reliable\treliable\tJJ\n",
      "results\tresult\tNNS\n",
      "when\twhen\tWRB\n",
      "such\tsuch\tPDT\n",
      "a\ta\tDT\n",
      "model\tmodel\tNN\n",
      "is\tbe\tVBZ\n",
      "included\tinclude\tVBN\n",
      "as\tas\tIN\n",
      "a\ta\tDT\n",
      "component\tcomponent\tNN\n",
      "of\tof\tIN\n",
      "a\ta\tDT\n",
      "larger\tlarger\tJJR\n",
      "system\tsystem\tNN\n",
      ".\t.\t.\n",
      "Systems\tSystems\tNNPS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "algorithms\talgorithm\tNNS\n",
      "have\thave\tVBP\n",
      "many\tmany\tJJ\n",
      "advantages\tadvantage\tNNS\n",
      "over\tover\tIN\n",
      "hand-produced\thand-produced\tJJ\n",
      "rules\trule\tNNS\n",
      ":\t:\t:\n",
      "The\tthe\tDT\n",
      "learning\tlearn\tVBG\n",
      "procedures\tprocedure\tNNS\n",
      "used\tuse\tVBN\n",
      "during\tduring\tIN\n",
      "machine\tmachine\tNN\n",
      "learning\tlearning\tNN\n",
      "automatically\tautomatically\tRB\n",
      "focus\tfocus\tVB\n",
      "on\ton\tIN\n",
      "the\tthe\tDT\n",
      "most\tmost\tRBS\n",
      "common\tcommon\tJJ\n",
      "cases\tcase\tNNS\n",
      ",\t,\t,\n",
      "whereas\twhereas\tIN\n",
      "when\twhen\tWRB\n",
      "writing\twrite\tVBG\n",
      "rules\trule\tNNS\n",
      "by\tby\tIN\n",
      "hand\thand\tNN\n",
      "it\tit\tPRP\n",
      "is\tbe\tVBZ\n",
      "often\toften\tRB\n",
      "not\tnot\tRB\n",
      "obvious\tobvious\tJJ\n",
      "at\tat\tIN\n",
      "all\tall\tDT\n",
      "where\twhere\tWRB\n",
      "the\tthe\tDT\n",
      "effort\teffort\tNN\n",
      "should\tshould\tMD\n",
      "be\tbe\tVB\n",
      "directed\tdirect\tVBN\n",
      ".\t.\t.\n",
      "Automatic\tAutomatic\tNNP\n",
      "learning\tlearn\tVBG\n",
      "procedures\tprocedure\tNNS\n",
      "can\tcan\tMD\n",
      "make\tmake\tVB\n",
      "use\tuse\tNN\n",
      "of\tof\tIN\n",
      "statistical\tstatistical\tJJ\n",
      "inference\tinference\tNN\n",
      "algorithms\talgorithm\tNNS\n",
      "to\tto\tTO\n",
      "produce\tproduce\tVB\n",
      "models\tmodel\tNNS\n",
      "that\tthat\tWDT\n",
      "are\tbe\tVBP\n",
      "robust\trobust\tJJ\n",
      "to\tto\tTO\n",
      "unfamiliar\tunfamiliar\tJJ\n",
      "input\tinput\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "e.g.\te.g.\tFW\n",
      "containing\tcontain\tVBG\n",
      "words\tword\tNNS\n",
      "or\tor\tCC\n",
      "structures\tstructure\tNNS\n",
      "that\tthat\tWDT\n",
      "have\thave\tVBP\n",
      "not\tnot\tRB\n",
      "been\tbe\tVBN\n",
      "seen\tsee\tVBN\n",
      "before\tbefore\tIN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "and\tand\tCC\n",
      "to\tto\tTO\n",
      "erroneous\terroneous\tJJ\n",
      "input\tinput\tNN\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "e.g.\te.g.\tFW\n",
      "with\twith\tIN\n",
      "misspelled\tmisspell\tVBN\n",
      "words\tword\tNNS\n",
      "or\tor\tCC\n",
      "words\tword\tNNS\n",
      "accidentally\taccidentally\tRB\n",
      "omitted\tomit\tVBN\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      ".\t.\t.\n",
      "Generally\tgenerally\tRB\n",
      ",\t,\t,\n",
      "handling\thandle\tVBG\n",
      "such\tsuch\tJJ\n",
      "input\tinput\tNN\n",
      "gracefully\tgracefully\tRB\n",
      "with\twith\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "--\t--\t:\n",
      "or\tor\tCC\n",
      "more\tmore\tJJR\n",
      "generally\tgenerally\tRB\n",
      ",\t,\t,\n",
      "creating\tcreate\tVBG\n",
      "systems\tsystem\tNNS\n",
      "of\tof\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "that\tthat\tWDT\n",
      "make\tmake\tVBP\n",
      "soft\tsoft\tJJ\n",
      "decisions\tdecision\tNNS\n",
      "--\t--\t:\n",
      "extremely\textremely\tRB\n",
      "difficult\tdifficult\tJJ\n",
      ",\t,\t,\n",
      "error-prone\terror-prone\tJJ\n",
      "and\tand\tCC\n",
      "time-consuming\ttime-consuming\tJJ\n",
      ".\t.\t.\n",
      "Systems\tSystems\tNNPS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "automatically\tautomatically\tRB\n",
      "learning\tlearn\tVBG\n",
      "the\tthe\tDT\n",
      "rules\trule\tNNS\n",
      "can\tcan\tMD\n",
      "be\tbe\tVB\n",
      "made\tmake\tVBN\n",
      "more\tmore\tRBR\n",
      "accurate\taccurate\tJJ\n",
      "simply\tsimply\tRB\n",
      "by\tby\tIN\n",
      "supplying\tsupply\tVBG\n",
      "more\tmore\tJJR\n",
      "input\tinput\tNN\n",
      "data\tdatum\tNNS\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "systems\tsystem\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "hand-written\thand-written\tJJ\n",
      "rules\trule\tNNS\n",
      "can\tcan\tMD\n",
      "only\tonly\tRB\n",
      "be\tbe\tVB\n",
      "made\tmake\tVBN\n",
      "more\tmore\tRBR\n",
      "accurate\taccurate\tJJ\n",
      "by\tby\tIN\n",
      "increasing\tincrease\tVBG\n",
      "the\tthe\tDT\n",
      "complexity\tcomplexity\tNN\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "rules\trule\tNNS\n",
      ",\t,\t,\n",
      "which\twhich\tWDT\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "much\tmuch\tRB\n",
      "more\tmore\tRBR\n",
      "difficult\tdifficult\tJJ\n",
      "task\ttask\tNN\n",
      ".\t.\t.\n",
      "In\tin\tIN\n",
      "particular\tparticular\tJJ\n",
      ",\t,\t,\n",
      "there\tthere\tEX\n",
      "is\tbe\tVBZ\n",
      "a\ta\tDT\n",
      "limit\tlimit\tNN\n",
      "to\tto\tTO\n",
      "the\tthe\tDT\n",
      "complexity\tcomplexity\tNN\n",
      "of\tof\tIN\n",
      "systems\tsystem\tNNS\n",
      "based\tbase\tVBN\n",
      "on\ton\tIN\n",
      "hand-crafted\thand-crafted\tJJ\n",
      "rules\trule\tNNS\n",
      ",\t,\t,\n",
      "beyond\tbeyond\tIN\n",
      "which\twhich\tWDT\n",
      "the\tthe\tDT\n",
      "systems\tsystem\tNNS\n",
      "become\tbecome\tVBP\n",
      "more\tmore\tRBR\n",
      "and\tand\tCC\n",
      "more\tmore\tRBR\n",
      "unmanageable\tunmanageable\tJJ\n",
      ".\t.\t.\n",
      "However\thowever\tRB\n",
      ",\t,\t,\n",
      "creating\tcreate\tVBG\n",
      "more\tmore\tJJR\n",
      "data\tdatum\tNNS\n",
      "to\tto\tTO\n",
      "input\tinput\tNN\n",
      "to\tto\tTO\n",
      "machine-learning\tmachine-learning\tJJ\n",
      "systems\tsystem\tNNS\n",
      "simply\tsimply\tRB\n",
      "requires\trequire\tVBZ\n",
      "a\ta\tDT\n",
      "corresponding\tcorresponding\tJJ\n",
      "increase\tincrease\tNN\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "number\tnumber\tNN\n",
      "of\tof\tIN\n",
      "man-hours\tman-hours\tNN\n",
      "worked\twork\tVBD\n",
      ",\t,\t,\n",
      "generally\tgenerally\tRB\n",
      "without\twithout\tIN\n",
      "significant\tsignificant\tJJ\n",
      "increases\tincrease\tNNS\n",
      "in\tin\tIN\n",
      "the\tthe\tDT\n",
      "complexity\tcomplexity\tNN\n",
      "of\tof\tIN\n",
      "the\tthe\tDT\n",
      "annotation\tannotation\tNN\n",
      "process\tprocess\tNN\n",
      ".\t.\t.\n",
      "The\tthe\tDT\n",
      "subfield\tsubfield\tNN\n",
      "of\tof\tIN\n",
      "NLP\tNLP\tNNP\n",
      "devoted\tdevote\tVBN\n",
      "to\tto\tIN\n",
      "learning\tlearn\tVBG\n",
      "approaches\tapproach\tNNS\n",
      "is\tbe\tVBZ\n",
      "known\tknow\tVBN\n",
      "as\tas\tIN\n",
      "Natural\tnatural\tJJ\n",
      "Language\tlanguage\tNN\n",
      "Learning\tLearning\tNNP\n",
      "-LRB-\t-lrb-\t-LRB-\n",
      "NLL\tNLL\tNNP\n",
      "-RRB-\t-rrb-\t-RRB-\n",
      "and\tand\tCC\n",
      "its\tits\tPRP$\n",
      "conference\tconference\tNN\n",
      "CoNLL\tconll\tNN\n",
      "and\tand\tCC\n",
      "peak\tpeak\tNN\n",
      "body\tbody\tNN\n",
      "SIGNLL\tSIGNLL\tNNP\n",
      "are\tbe\tVBP\n",
      "sponsored\tsponsor\tVBN\n",
      "by\tby\tIN\n",
      "ACL\tacl\tNN\n",
      ",\t,\t,\n",
      "recognizing\trecognize\tVBG\n",
      "also\talso\tRB\n",
      "their\tthey\tPRP$\n",
      "links\tlink\tNNS\n",
      "with\twith\tIN\n",
      "Computational\tcomputational\tJJ\n",
      "Linguistics\tlinguistics\tNNS\n",
      "and\tand\tCC\n",
      "Language\tLanguage\tNNP\n",
      "Acquisition\tAcquisition\tNNP\n",
      ".\t.\t.\n",
      "When\twhen\tWRB\n",
      "the\tthe\tDT\n",
      "aims\taim\tNNS\n",
      "of\tof\tIN\n",
      "computational\tcomputational\tJJ\n",
      "language\tlanguage\tNN\n",
      "learning\tlearn\tVBG\n",
      "research\tresearch\tNN\n",
      "is\tbe\tVBZ\n",
      "to\tto\tTO\n",
      "understand\tunderstand\tVB\n",
      "more\tmore\tJJR\n",
      "about\tabout\tIN\n",
      "human\thuman\tJJ\n",
      "language\tlanguage\tNN\n",
      "acquisition\tacquisition\tNN\n",
      ",\t,\t,\n",
      "or\tor\tCC\n",
      "psycholinguistics\tpsycholinguistic\tNNS\n",
      ",\t,\t,\n",
      "NLL\tnll\tNN\n",
      "overlaps\toverlap\tVBZ\n",
      "into\tinto\tIN\n",
      "the\tthe\tDT\n",
      "related\trelated\tJJ\n",
      "field\tfield\tNN\n",
      "of\tof\tIN\n",
      "Computational\tComputational\tNNP\n",
      "Psycholinguistics\tPsycholinguistics\tNNPS\n",
      ".\t.\t.\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(\n",
    "        token.find('word').text,\n",
    "        token.find('lemma').text,\n",
    "        token.find('POS').text,\n",
    "        sep='\\t'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55. 固有表現抽出\n",
    "入力文中の人名をすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人名の出力のされ方を調べるために、nlp.txtを眺めてみつけた\"Joseph\"のtokenの中身を見てみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('word', 'Joseph'),\n",
       " ('lemma', 'Joseph'),\n",
       " ('CharacterOffsetBegin', '1621'),\n",
       " ('CharacterOffsetEnd', '1627'),\n",
       " ('POS', 'NNP'),\n",
       " ('NER', 'PERSON'),\n",
       " ('Speaker', 'PER0')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_joseph = list(filter(lambda x: x.find('word').text == 'Joseph', tokens))[0]\n",
    "list(map(lambda child: (child.tag, child.text), token_joseph.getchildren()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NERがPERSONになるようす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan',\n",
       " 'Turing',\n",
       " 'Joseph',\n",
       " 'Weizenbaum',\n",
       " 'MARGIE',\n",
       " 'Schank',\n",
       " 'Wilensky',\n",
       " 'Meehan',\n",
       " 'Lehnert',\n",
       " 'Carbonell',\n",
       " 'Lehnert',\n",
       " 'Racter',\n",
       " 'Jabberwacky',\n",
       " 'Moore']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_person = list(filter(lambda token: token.find('NER').text == 'PERSON', tokens))\n",
    "list(map(lambda t: t.find('word').text, tokens_person))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56. 共参照解析\n",
    "Stanford Core NLPの共参照解析の結果に基づき，文中の参照表現（mention）を代表参照表現（representative mention）に置換せよ．ただし，置換するときは，「代表参照表現（参照表現）」のように，元の参照表現が分かるように配慮せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Searching for resource: StanfordCoreNLP.properties ... found.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.2 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [2.2 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 580704 unique entries out of 581863 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 4869 unique entries out of 4869 from edu/stanford/nlp/models/kbp/english/gazetteers/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - ner.fine.regexner: Read 585573 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 23.14 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [25.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator coref\n",
      "[main] INFO edu.stanford.nlp.coref.statistical.SimpleLinearClassifier - Loading coref model edu/stanford/nlp/models/coref/statistical/ranking_model.ser.gz ... done [3.7 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency\n",
      "\n",
      "Processing file /Users/masato/Desktop/nlp100/nlp.txt ... writing to /Users/masato/Desktop/nlp100/nlp.txt.xml\n",
      "Annotating file /Users/masato/Desktop/nlp100/nlp.txt ... done [172.8 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "POSTaggerAnnotator: 0.3 sec.\n",
      "MorphaAnnotator: 0.1 sec.\n",
      "NERCombinerAnnotator: 120.1 sec.\n",
      "DependencyParseAnnotator: 2.0 sec.\n",
      "CorefAnnotator: 50.1 sec.\n",
      "TOTAL: 172.8 sec. for 1452 tokens at 8.4 tokens/sec.\n",
      "Pipeline setup: 120.8 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 294.0 sec.\n"
     ]
    }
   ],
   "source": [
    "!java -Xmx4g -cp \"stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -file nlp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のcoreferenceを元に置換を進めればよさそう。\n",
    "```xml\n",
    "    </sentences>\n",
    "    <coreference>\n",
    "      <coreference>\n",
    "        <mention representative=\"true\">\n",
    "          <sentence>37</sentence>\n",
    "          <start>5</start>\n",
    "          <end>8</end>\n",
    "          <head>7</head>\n",
    "          <text>machine learning algorithms</text>\n",
    "        </mention>\n",
    "        <mention>\n",
    "          <sentence>38</sentence>\n",
    "          <start>1</start>\n",
    "          <end>3</end>\n",
    "          <head>2</head>\n",
    "          <text>These algorithms</text>\n",
    "        </mention>\n",
    "        <mention>\n",
    "          <sentence>39</sentence>\n",
    "          <start>3</start>\n",
    "          <end>6</end>\n",
    "          <head>5</head>\n",
    "          <text>the earliest-used algorithms</text>\n",
    "        </mention>\n",
    "      </coreference>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'coreference' at 0x1a1a0518b8>,\n",
       " <Element 'coreference' at 0x1a1a051cc8>,\n",
       " <Element 'coreference' at 0x1a1a058138>,\n",
       " <Element 'coreference' at 0x1a1a058958>,\n",
       " <Element 'coreference' at 0x1a1a058d68>,\n",
       " <Element 'coreference' at 0x1a1a05c458>,\n",
       " <Element 'coreference' at 0x1a1a05c868>,\n",
       " <Element 'coreference' at 0x1a1a05ccc8>,\n",
       " <Element 'coreference' at 0x1a1a060138>,\n",
       " <Element 'coreference' at 0x1a1a060548>,\n",
       " <Element 'coreference' at 0x1a1a060958>,\n",
       " <Element 'coreference' at 0x1a1a060f48>,\n",
       " <Element 'coreference' at 0x1a1a069138>,\n",
       " <Element 'coreference' at 0x1a1a069548>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corefs = root.findall('./document/coreference/coreference')\n",
    "corefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention2dict(mention, rep_text):\n",
    "    return {\n",
    "        'start_sid': mention.find('sentence').text,\n",
    "        'start_tid': mention.find('start').text,\n",
    "        'end': mention.find('end').text,\n",
    "        'text': mention.find('text').text,\n",
    "        'rep_text': rep_text\n",
    "    }\n",
    "\n",
    "mention_dicts_per_coref = []\n",
    "for coref in corefs:\n",
    "    rep_text = None\n",
    "    for mention in coref.findall('./mention'):\n",
    "        if mention.get('representative') == 'true':\n",
    "            rep_text = mention.find('text').text\n",
    "        else:\n",
    "            coref_dicts.append(mention2dict(mention, rep_text))\n",
    "    mention_dicts_per_coref.append(coref_dicts)\n",
    "\n",
    "import itertools\n",
    "mention_dict = {(m['start_sid'], m['start_tid']): m for m in itertools.chain(*mention_dicts_per_coref)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('50', '21'): {'start_sid': '50',\n",
       "  'start_tid': '21',\n",
       "  'end': '22',\n",
       "  'text': 'NLL',\n",
       "  'rep_text': 'NLL'},\n",
       " ('10', '45'): {'start_sid': '10',\n",
       "  'start_tid': '45',\n",
       "  'end': '46',\n",
       "  'text': '1966',\n",
       "  'rep_text': '1966'},\n",
       " ('15', '21'): {'start_sid': '15',\n",
       "  'start_tid': '21',\n",
       "  'end': '22',\n",
       "  'text': '1978',\n",
       "  'rep_text': '1978'},\n",
       " ('25', '1'): {'start_sid': '25',\n",
       "  'start_tid': '1',\n",
       "  'end': '3',\n",
       "  'text': 'These systems',\n",
       "  'rep_text': 'many speech recognition systems'},\n",
       " ('26', '35'): {'start_sid': '26',\n",
       "  'start_tid': '35',\n",
       "  'end': '37',\n",
       "  'text': 'these systems',\n",
       "  'rep_text': 'many speech recognition systems'},\n",
       " ('47', '20'): {'start_sid': '47',\n",
       "  'start_tid': '20',\n",
       "  'end': '22',\n",
       "  'text': 'the systems',\n",
       "  'rep_text': 'many speech recognition systems'},\n",
       " ('38', '17'): {'start_sid': '38',\n",
       "  'start_tid': '17',\n",
       "  'end': '20',\n",
       "  'text': 'the input data',\n",
       "  'rep_text': 'the input data'},\n",
       " ('38', '1'): {'start_sid': '38',\n",
       "  'start_tid': '1',\n",
       "  'end': '3',\n",
       "  'text': 'These algorithms',\n",
       "  'rep_text': 'machine learning algorithms'},\n",
       " ('39', '3'): {'start_sid': '39',\n",
       "  'start_tid': '3',\n",
       "  'end': '6',\n",
       "  'text': 'the earliest-used algorithms',\n",
       "  'rep_text': 'machine learning algorithms'},\n",
       " ('12', '13'): {'start_sid': '12',\n",
       "  'start_tid': '13',\n",
       "  'end': '14',\n",
       "  'text': 'ELIZA',\n",
       "  'rep_text': 'ELIZA'},\n",
       " ('33', '1'): {'start_sid': '33',\n",
       "  'start_tid': '1',\n",
       "  'end': '6',\n",
       "  'text': 'The paradigm of machine learning',\n",
       "  'rep_text': 'The machine-learning paradigm'},\n",
       " ('12', '36'): {'start_sid': '12',\n",
       "  'start_tid': '36',\n",
       "  'end': '38',\n",
       "  'text': 'your head',\n",
       "  'rep_text': 'My head'},\n",
       " ('41', '7'): {'start_sid': '41',\n",
       "  'start_tid': '7',\n",
       "  'end': '8',\n",
       "  'text': 'they',\n",
       "  'rep_text': 'Such models'},\n",
       " ('8', '33'): {'start_sid': '8',\n",
       "  'start_tid': '33',\n",
       "  'end': '35',\n",
       "  'text': 'machine translation',\n",
       "  'rep_text': 'machine translation'},\n",
       " ('9', '5'): {'start_sid': '9',\n",
       "  'start_tid': '5',\n",
       "  'end': '7',\n",
       "  'text': 'machine translation',\n",
       "  'rep_text': 'machine translation'},\n",
       " ('2', '4'): {'start_sid': '2',\n",
       "  'start_tid': '4',\n",
       "  'end': '5',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('3', '4'): {'start_sid': '3',\n",
       "  'start_tid': '4',\n",
       "  'end': '5',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('4', '5'): {'start_sid': '4',\n",
       "  'start_tid': '5',\n",
       "  'end': '6',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('17', '7'): {'start_sid': '17',\n",
       "  'start_tid': '7',\n",
       "  'end': '8',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('18', '14'): {'start_sid': '18',\n",
       "  'start_tid': '14',\n",
       "  'end': '15',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('37', '12'): {'start_sid': '37',\n",
       "  'start_tid': '12',\n",
       "  'end': '13',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('49', '4'): {'start_sid': '49',\n",
       "  'start_tid': '4',\n",
       "  'end': '5',\n",
       "  'text': 'NLP',\n",
       "  'rep_text': 'NLP'},\n",
       " ('49', '19'): {'start_sid': '49',\n",
       "  'start_tid': '19',\n",
       "  'end': '20',\n",
       "  'text': 'its',\n",
       "  'rep_text': 'NLP'},\n",
       " ('45', '6'): {'start_sid': '45',\n",
       "  'start_tid': '6',\n",
       "  'end': '8',\n",
       "  'text': 'the rules',\n",
       "  'rep_text': 'hand-written rules --'}}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing From Wikipedia , the free encyclopedia Natural language processing -LRB- NLP -RRB- is a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages . \n",
      "As such , NLP is related to the area of humani-computer interaction . \n",
      "Many challenges in NLP involve natural language understanding , that is , enabling computers to derive meaning from human or natural language input , and others involve natural language generation . \n",
      "History The history of NLP generally starts in the 1950s , although work can be found from earlier periods . \n",
      "In 1950 , Alan Turing published an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence . \n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English . \n",
      "The authors claimed that within three or five years , machine translation would be a solved problem . \n",
      "However , real progress was much slower , and after the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations , funding for machine translation was dramatically reduced . \n",
      "Little further research in machine translation was conducted until the late 1980s , when the first statistical machine translation systems were developed . \n",
      "Some notably successful NLP systems developed in the 1960s were SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies , and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 to 1966 . \n",
      "Using almost no information about human thought or emotion , ELIZA sometimes provided a startlingly human-like interaction . \n",
      "When the `` patient '' exceeded the very small knowledge base , ELIZA might provide a generic response , for example , responding to `` My head hurts '' with `` Why do you say your head hurts ? '' \n",
      ". \n",
      "During the 1970s many programmers began to write ` conceptual ontologies ' , which structured real-world information into computer-understandable data . \n",
      "Examples are MARGIE -LRB- Schank , 1975 -RRB- , SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB- . \n",
      "During this time , many chatterbots were written including PARRY , Racter , and Jabberwacky . \n",
      "Up to the 1980s , most NLP systems were based on complex sets of hand-written rules . \n",
      "Starting in the late 1980s , however , there was a revolution in NLP with the introduction of machine learning algorithms for language processing . \n",
      "This was due to both the steady increase in computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing . \n",
      "Some of the earliest-used machine learning algorithms , such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules . \n",
      "However , Part of speech tagging introduced the use of Hidden Markov Models to NLP , and increasingly , research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data . \n",
      "The cache language models upon which many speech recognition systems now rely are examples of such statistical models . \n",
      "Such models are generally more robust when given unfamiliar input , especially input that contains errors -LRB- as is very common for real-world data -RRB- , and produce more reliable results when integrated into a larger system comprising multiple subtasks . \n",
      "Many of the notable early successes occurred in the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed . \n",
      "These systems were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government . \n",
      "However , most other systems depended on corpora specifically developed for the tasks implemented by these systems , which was -LRB- and often continues to be -RRB- a major limitation in the success of these systems . \n",
      "As a result , a great deal of research has gone into methods of more effectively learning from limited amounts of data . \n",
      "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms . \n",
      "Such algorithms are able to learn from data that has not been hand-annotated with the desired answers , or using a combination of annotated and non-annotated data . \n",
      "Generally , this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data . \n",
      "However , there is an enormous amount of non-annotated data available -LRB- including , among other things , the entire content of the World Wide Web -RRB- , which can often make up for the inferior results . \n",
      "NLP using machine learning Modern NLP algorithms are based on machine learning , especially statistical machine learning . \n",
      "The paradigm of machine learning is different from that of most prior attempts at language processing . \n",
      "Prior implementations of language-processing tasks typically involved the direct hand coding of large sets of rules . \n",
      "The machine-learning paradigm calls instead for using general learning algorithms - often , although not always , grounded in statistical inference - to automatically learn such rules through the analysis of large corpora of typical real-world examples . \n",
      "A corpus -LRB- plural , `` corpora '' -RRB- is a set of documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned . \n",
      "Many different classes of machine learning algorithms have been applied to NLP tasks . \n",
      "These algorithms take as input a large set of `` features '' that are generated from the input data . \n",
      "Some of the earliest-used algorithms , such as decision trees , produced systems of hard if-then rules similar to the systems of hand-written rules that were then common . \n",
      "Increasingly , however , research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature . \n",
      "Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one , producing more reliable results when such a model is included as a component of a larger system . \n",
      "Systems based on machine-learning algorithms have many advantages over hand-produced rules : The learning procedures used during machine learning automatically focus on the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed . \n",
      "Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input -LRB- e.g. containing words or structures that have not been seen before -RRB- and to erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB- . \n",
      "Generally , handling such input gracefully with hand-written rules -- or more generally , creating systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming . \n",
      "Systems based on automatically learning the rules can be made more accurate simply by supplying more input data . \n",
      "However , systems based on hand-written rules can only be made more accurate by increasing the complexity of the rules , which is a much more difficult task . \n",
      "In particular , there is a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable . \n",
      "However , creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked , generally without significant increases in the complexity of the annotation process . \n",
      "The subfield of NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL are sponsored by ACL , recognizing also their links with Computational Linguistics and Language Acquisition . \n",
      "When the aims of computational language learning research is to understand more about human language acquisition , or psycholinguistics , NLL overlaps into the related field of Computational Psycholinguistics . \n"
     ]
    }
   ],
   "source": [
    "for sentence in root.findall('./document/sentences/sentence'):\n",
    "    sentence_id = sentence.get('id')\n",
    "    for token in sentence.find('tokens'):\n",
    "        token_id = token.get('id')\n",
    "        print(token.find('word').text, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing From Wikipedia , the free encyclopedia Natural language processing -LRB- NLP -RRB- is a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages . \n",
      "As such , NLP (NLP) is related to the area of humani-computer interaction . \n",
      "Many challenges in NLP (NLP) involve natural language understanding , that is , enabling computers to derive meaning from human or natural language input , and others involve natural language generation . \n",
      "History The history of NLP (NLP) generally starts in the 1950s , although work can be found from earlier periods . \n",
      "In 1950 , Alan Turing published an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence . \n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English . \n",
      "The authors claimed that within three or five years , machine translation would be a solved problem . \n",
      "However , real progress was much slower , and after the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations , funding for machine translation (machine translation) was dramatically reduced . \n",
      "Little further research in machine translation (machine translation) was conducted until the late 1980s , when the first statistical machine translation systems were developed . \n",
      "Some notably successful NLP systems developed in the 1960s were SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies , and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 to 1966 (1966) . \n",
      "Using almost no information about human thought or emotion , ELIZA sometimes provided a startlingly human-like interaction . \n",
      "When the `` patient '' exceeded the very small knowledge base , ELIZA (ELIZA) might provide a generic response , for example , responding to `` My head hurts '' with `` Why do you say My head (your head) hurts ? '' \n",
      ". \n",
      "During the 1970s many programmers began to write ` conceptual ontologies ' , which structured real-world information into computer-understandable data . \n",
      "Examples are MARGIE -LRB- Schank , 1975 -RRB- , SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 (1978) -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB- . \n",
      "During this time , many chatterbots were written including PARRY , Racter , and Jabberwacky . \n",
      "Up to the 1980s , most NLP (NLP) systems were based on complex sets of hand-written rules . \n",
      "Starting in the late 1980s , however , there was a revolution in NLP (NLP) with the introduction of machine learning algorithms for language processing . \n",
      "This was due to both the steady increase in computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing . \n",
      "Some of the earliest-used machine learning algorithms , such as decision trees , produced systems of hard if-then rules similar to existing hand-written rules . \n",
      "However , Part of speech tagging introduced the use of Hidden Markov Models to NLP , and increasingly , research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data . \n",
      "The cache language models upon which many speech recognition systems now rely are examples of such statistical models . \n",
      "Such models are generally more robust when given unfamiliar input , especially input that contains errors -LRB- as is very common for real-world data -RRB- , and produce more reliable results when integrated into a larger system comprising multiple subtasks . \n",
      "Many of the notable early successes occurred in the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed . \n",
      "many speech recognition systems (These systems) were able to take advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government . \n",
      "However , most other systems depended on corpora specifically developed for the tasks implemented by these systems , which was -LRB- and often continues to be -RRB- a major limitation in the success of many speech recognition systems (these systems) . \n",
      "As a result , a great deal of research has gone into methods of more effectively learning from limited amounts of data . \n",
      "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms . \n",
      "Such algorithms are able to learn from data that has not been hand-annotated with the desired answers , or using a combination of annotated and non-annotated data . \n",
      "Generally , this task is much more difficult than supervised learning , and typically produces less accurate results for a given amount of input data . \n",
      "However , there is an enormous amount of non-annotated data available -LRB- including , among other things , the entire content of the World Wide Web -RRB- , which can often make up for the inferior results . \n",
      "NLP using machine learning Modern NLP algorithms are based on machine learning , especially statistical machine learning . \n",
      "The machine-learning paradigm (The paradigm of machine learning) is different from that of most prior attempts at language processing . \n",
      "Prior implementations of language-processing tasks typically involved the direct hand coding of large sets of rules . \n",
      "The machine-learning paradigm calls instead for using general learning algorithms - often , although not always , grounded in statistical inference - to automatically learn such rules through the analysis of large corpora of typical real-world examples . \n",
      "A corpus -LRB- plural , `` corpora '' -RRB- is a set of documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned . \n",
      "Many different classes of machine learning algorithms have been applied to NLP (NLP) tasks . \n",
      "machine learning algorithms (These algorithms) take as input a large set of `` features '' that are generated from the input data (the input data) . \n",
      "Some of machine learning algorithms (the earliest-used algorithms) , such as decision trees , produced systems of hard if-then rules similar to the systems of hand-written rules that were then common . \n",
      "Increasingly , however , research has focused on statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature . \n",
      "Such models have the advantage that Such models (they) can express the relative certainty of many different possible answers rather than only one , producing more reliable results when such a model is included as a component of a larger system . \n",
      "Systems based on machine-learning algorithms have many advantages over hand-produced rules : The learning procedures used during machine learning automatically focus on the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed . \n",
      "Automatic learning procedures can make use of statistical inference algorithms to produce models that are robust to unfamiliar input -LRB- e.g. containing words or structures that have not been seen before -RRB- and to erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB- . \n",
      "Generally , handling such input gracefully with hand-written rules -- or more generally , creating systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming . \n",
      "Systems based on automatically learning hand-written rules -- (the rules) can be made more accurate simply by supplying more input data . \n",
      "However , systems based on hand-written rules can only be made more accurate by increasing the complexity of the rules , which is a much more difficult task . \n",
      "In particular , there is a limit to the complexity of systems based on hand-crafted rules , beyond which many speech recognition systems (the systems) become more and more unmanageable . \n",
      "However , creating more data to input to machine-learning systems simply requires a corresponding increase in the number of man-hours worked , generally without significant increases in the complexity of the annotation process . \n",
      "The subfield of NLP (NLP) devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and NLP (its) conference CoNLL and peak body SIGNLL are sponsored by ACL , recognizing also their links with Computational Linguistics and Language Acquisition . \n",
      "When the aims of computational language learning research is to understand more about human language acquisition , or psycholinguistics , NLL (NLL) overlaps into the related field of Computational Psycholinguistics . \n"
     ]
    }
   ],
   "source": [
    "for sentence in root.findall('./document/sentences/sentence'):\n",
    "    end_token_id = None\n",
    "    sentence_id = sentence.get('id')\n",
    "    for token in sentence.find('tokens'):\n",
    "        token_id = token.get('id')\n",
    "        \n",
    "        # end番目に達したので、状態をリセットする\n",
    "        if token_id == end_token_id:\n",
    "            end_token_id = None\n",
    "\n",
    "        # 置換用の辞書にある場合、end - 1番目の単語までを先に出力してしまう\n",
    "        mention = mention_dict.get((sentence_id, token_id))\n",
    "        if mention is not None:\n",
    "            print(mention['rep_text'] + ' (' + mention['text'] + ')', end=' ')\n",
    "            end_token_id = mention['end']\n",
    "            continue\n",
    "        \n",
    "        # 置換中 (end - 1番目まで) なので、出力せずcontinueする\n",
    "        if end_token_id is not None:\n",
    "            continue\n",
    "        \n",
    "        print(token.find('word').text, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57. 係り受け解析\n",
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）を有向グラフとして可視化せよ．可視化には，係り受け木をDOT言語に変換し，Graphvizを用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，pydotを使うとよい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collapsed-dependenciesの中身を見てみる。\n",
    "\n",
    "```xml\n",
    "        <dependencies type=\"collapsed-dependencies\">\n",
    "          <dep type=\"root\">\n",
    "            <governor idx=\"0\">ROOT</governor>\n",
    "            <dependent idx=\"18\">field</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"amod\">\n",
    "            <governor idx=\"3\">processing</governor>\n",
    "            <dependent idx=\"1\">Natural</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"compound\">\n",
    "            <governor idx=\"3\">processing</governor>\n",
    "            <dependent idx=\"2\">language</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"nsubj\">\n",
    "            <governor idx=\"18\">field</governor>\n",
    "            <dependent idx=\"3\">processing</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"case\">\n",
    "            <governor idx=\"5\">Wikipedia</governor>\n",
    "            <dependent idx=\"4\">From</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"nmod:from\">\n",
    "            <governor idx=\"3\">processing</governor>\n",
    "            <dependent idx=\"5\">Wikipedia</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"5\">Wikipedia</governor>\n",
    "            <dependent idx=\"6\">,</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"det\">\n",
    "            <governor idx=\"12\">processing</governor>\n",
    "            <dependent idx=\"7\">the</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"amod\">\n",
    "            <governor idx=\"12\">processing</governor>\n",
    "            <dependent idx=\"8\">free</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"compound\">\n",
    "            <governor idx=\"12\">processing</governor>\n",
    "            <dependent idx=\"9\">encyclopedia</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"amod\">\n",
    "            <governor idx=\"12\">processing</governor>\n",
    "            <dependent idx=\"10\">Natural</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"compound\">\n",
    "            <governor idx=\"12\">processing</governor>\n",
    "            <dependent idx=\"11\">language</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"appos\">\n",
    "            <governor idx=\"5\">Wikipedia</governor>\n",
    "            <dependent idx=\"12\">processing</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"14\">NLP</governor>\n",
    "            <dependent idx=\"13\">-LRB-</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"appos\">\n",
    "            <governor idx=\"12\">processing</governor>\n",
    "            <dependent idx=\"14\">NLP</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"14\">NLP</governor>\n",
    "            <dependent idx=\"15\">-RRB-</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"cop\">\n",
    "            <governor idx=\"18\">field</governor>\n",
    "            <dependent idx=\"16\">is</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"det\">\n",
    "            <governor idx=\"18\">field</governor>\n",
    "            <dependent idx=\"17\">a</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"case\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"19\">of</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"compound\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"20\">computer</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"nmod:of\">\n",
    "            <governor idx=\"18\">field</governor>\n",
    "            <dependent idx=\"21\">science</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"22\">,</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"amod\">\n",
    "            <governor idx=\"24\">intelligence</governor>\n",
    "            <dependent idx=\"23\">artificial</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"conj:and\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"24\">intelligence</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"25\">,</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"cc\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"26\">and</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"conj:and\">\n",
    "            <governor idx=\"21\">science</governor>\n",
    "            <dependent idx=\"27\">linguistics</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"acl\">\n",
    "            <governor idx=\"27\">linguistics</governor>\n",
    "            <dependent idx=\"28\">concerned</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"case\">\n",
    "            <governor idx=\"31\">interactions</governor>\n",
    "            <dependent idx=\"29\">with</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"det\">\n",
    "            <governor idx=\"31\">interactions</governor>\n",
    "            <dependent idx=\"30\">the</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"nmod:with\">\n",
    "            <governor idx=\"28\">concerned</governor>\n",
    "            <dependent idx=\"31\">interactions</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"case\">\n",
    "            <governor idx=\"33\">computers</governor>\n",
    "            <dependent idx=\"32\">between</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"nmod:between\">\n",
    "            <governor idx=\"31\">interactions</governor>\n",
    "            <dependent idx=\"33\">computers</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"cc\">\n",
    "            <governor idx=\"33\">computers</governor>\n",
    "            <dependent idx=\"34\">and</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"amod\">\n",
    "            <governor idx=\"39\">languages</governor>\n",
    "            <dependent idx=\"35\">human</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"37\">natural</governor>\n",
    "            <dependent idx=\"36\">-LRB-</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"dep\">\n",
    "            <governor idx=\"35\">human</governor>\n",
    "            <dependent idx=\"37\">natural</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"37\">natural</governor>\n",
    "            <dependent idx=\"38\">-RRB-</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"conj:and\">\n",
    "            <governor idx=\"33\">computers</governor>\n",
    "            <dependent idx=\"39\">languages</dependent>\n",
    "          </dep>\n",
    "          <dep type=\"punct\">\n",
    "            <governor idx=\"18\">field</governor>\n",
    "            <dependent idx=\"40\">.</dependent>\n",
    "          </dep>\n",
    "        </dependencies>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import SVG\n",
    "def sentence2tree(sentence):\n",
    "    dot = pydot.Dot()\n",
    "    nodes = [pydot.Node(t.get('id'), label=t.find('word').text) for t in sentence.findall('./tokens/token')]\n",
    "    edges = [\n",
    "        pydot.Edge(dep.find('governor').get('idx'), dep.find('dependent').get('idx')) \n",
    "        for dep in sentence.findall(\"./dependencies[@type='collapsed-dependencies']/dep\") \n",
    "        if dep.find('governor').get('idx') != \"0\"\n",
    "    ]\n",
    "    for node in nodes:\n",
    "        dot.add_node(node)\n",
    "    for edge in edges:\n",
    "        dot.add_edge(edge)\n",
    "    print(dot.to_string())\n",
    "    return SVG(dot.create(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph G {\n",
      "1 [label=Natural];\n",
      "2 [label=language];\n",
      "3 [label=processing];\n",
      "4 [label=From];\n",
      "5 [label=Wikipedia];\n",
      "6 [label=,];\n",
      "7 [label=the];\n",
      "8 [label=free];\n",
      "9 [label=encyclopedia];\n",
      "10 [label=Natural];\n",
      "11 [label=language];\n",
      "12 [label=processing];\n",
      "13 [label=\"-LRB-\"];\n",
      "14 [label=NLP];\n",
      "15 [label=\"-RRB-\"];\n",
      "16 [label=is];\n",
      "17 [label=a];\n",
      "18 [label=field];\n",
      "19 [label=of];\n",
      "20 [label=computer];\n",
      "21 [label=science];\n",
      "22 [label=,];\n",
      "23 [label=artificial];\n",
      "24 [label=intelligence];\n",
      "25 [label=,];\n",
      "26 [label=and];\n",
      "27 [label=linguistics];\n",
      "28 [label=concerned];\n",
      "29 [label=with];\n",
      "30 [label=the];\n",
      "31 [label=interactions];\n",
      "32 [label=between];\n",
      "33 [label=computers];\n",
      "34 [label=and];\n",
      "35 [label=human];\n",
      "36 [label=\"-LRB-\"];\n",
      "37 [label=natural];\n",
      "38 [label=\"-RRB-\"];\n",
      "39 [label=languages];\n",
      "40 [label=\".\"];\n",
      "3 -> 1;\n",
      "3 -> 2;\n",
      "18 -> 3;\n",
      "5 -> 4;\n",
      "3 -> 5;\n",
      "5 -> 6;\n",
      "12 -> 7;\n",
      "12 -> 8;\n",
      "12 -> 9;\n",
      "12 -> 10;\n",
      "12 -> 11;\n",
      "5 -> 12;\n",
      "14 -> 13;\n",
      "12 -> 14;\n",
      "14 -> 15;\n",
      "18 -> 16;\n",
      "18 -> 17;\n",
      "21 -> 19;\n",
      "21 -> 20;\n",
      "18 -> 21;\n",
      "21 -> 22;\n",
      "24 -> 23;\n",
      "21 -> 24;\n",
      "21 -> 25;\n",
      "21 -> 26;\n",
      "21 -> 27;\n",
      "27 -> 28;\n",
      "31 -> 29;\n",
      "31 -> 30;\n",
      "28 -> 31;\n",
      "33 -> 32;\n",
      "31 -> 33;\n",
      "33 -> 34;\n",
      "39 -> 35;\n",
      "37 -> 36;\n",
      "35 -> 37;\n",
      "37 -> 38;\n",
      "33 -> 39;\n",
      "18 -> 40;\n",
      "}\n",
      "\n",
      "['dot', '-Tsvg', '/var/folders/1f/1_lngqh578bf47_3t8wm466w0000gr/T/tmpjqoyac4t'] return code: 1\n",
      "\n",
      "stdout, stderr:\n",
      " b''\n",
      "b\"Error: /var/folders/1f/1_lngqh578bf47_3t8wm466w0000gr/T/tmpjqoyac4t: syntax error in line 7 near ','\\n\"\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-ba5be9f4d570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence2tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./document/sentences/sentence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-0c3e01cd7d91>\u001b[0m in \u001b[0;36msentence2tree\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                      \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m                      err=stderr_data))\n\u001b[0;32m-> 1885\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstdout_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "sentence2tree(root.find('./document/sentences/sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label=\",\" がエスケープされていないのが問題に見える。\n",
    "# double quotationで囲んでみる\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "def sentence2tree(sentence):\n",
    "    dot = pydot.Dot()\n",
    "    nodes = [pydot.Node(t.get('id'), label=('\"' + t.find('word').text + '\"')) for t in sentence.findall('./tokens/token')]\n",
    "    edges = [\n",
    "        pydot.Edge(dep.find('governor').get('idx'), dep.find('dependent').get('idx')) \n",
    "        for dep in sentence.findall(\"./dependencies[@type='collapsed-dependencies']/dep\") \n",
    "        if dep.find('governor').get('idx') != \"0\"\n",
    "    ]\n",
    "    for node in nodes:\n",
    "        dot.add_node(node)\n",
    "    for edge in edges:\n",
    "        dot.add_edge(edge)\n",
    "    print(dot.to_string())\n",
    "    print(' '.join(map(lambda w: w.text, sentence.findall('./tokens/token/word'))))\n",
    "    return SVG(dot.create(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph G {\n",
      "1 [label=\"Many\"];\n",
      "2 [label=\"challenges\"];\n",
      "3 [label=\"in\"];\n",
      "4 [label=\"NLP\"];\n",
      "5 [label=\"involve\"];\n",
      "6 [label=\"natural\"];\n",
      "7 [label=\"language\"];\n",
      "8 [label=\"understanding\"];\n",
      "9 [label=\",\"];\n",
      "10 [label=\"that\"];\n",
      "11 [label=\"is\"];\n",
      "12 [label=\",\"];\n",
      "13 [label=\"enabling\"];\n",
      "14 [label=\"computers\"];\n",
      "15 [label=\"to\"];\n",
      "16 [label=\"derive\"];\n",
      "17 [label=\"meaning\"];\n",
      "18 [label=\"from\"];\n",
      "19 [label=\"human\"];\n",
      "20 [label=\"or\"];\n",
      "21 [label=\"natural\"];\n",
      "22 [label=\"language\"];\n",
      "23 [label=\"input\"];\n",
      "24 [label=\",\"];\n",
      "25 [label=\"and\"];\n",
      "26 [label=\"others\"];\n",
      "27 [label=\"involve\"];\n",
      "28 [label=\"natural\"];\n",
      "29 [label=\"language\"];\n",
      "30 [label=\"generation\"];\n",
      "31 [label=\".\"];\n",
      "2 -> 1;\n",
      "5 -> 2;\n",
      "4 -> 3;\n",
      "2 -> 4;\n",
      "8 -> 6;\n",
      "8 -> 7;\n",
      "27 -> 8;\n",
      "8 -> 9;\n",
      "11 -> 10;\n",
      "8 -> 11;\n",
      "11 -> 12;\n",
      "11 -> 13;\n",
      "13 -> 14;\n",
      "16 -> 15;\n",
      "13 -> 16;\n",
      "16 -> 17;\n",
      "23 -> 18;\n",
      "23 -> 19;\n",
      "19 -> 20;\n",
      "19 -> 21;\n",
      "23 -> 22;\n",
      "17 -> 23;\n",
      "8 -> 24;\n",
      "8 -> 25;\n",
      "8 -> 26;\n",
      "5 -> 27;\n",
      "30 -> 28;\n",
      "30 -> 29;\n",
      "27 -> 30;\n",
      "5 -> 31;\n",
      "}\n",
      "\n",
      "Many challenges in NLP involve natural language understanding , that is , enabling computers to derive meaning from human or natural language input , and others involve natural language generation .\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"692pt\" viewBox=\"0.00 0.00 823.55 692.00\" width=\"824pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 688)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-688 819.5461,-688 819.5461,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>1</title>\n",
       "<ellipse cx=\"65\" cy=\"-522\" fill=\"none\" rx=\"31.6951\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-518.3\">Many</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>2</title>\n",
       "<ellipse cx=\"143\" cy=\"-594\" fill=\"none\" rx=\"49.2915\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-590.3\">challenges</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>2-&gt;1</title>\n",
       "<path d=\"M124.5151,-576.937C113.9734,-567.2062 100.6361,-554.8948 89.2605,-544.3943\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"91.479,-541.6789 81.7569,-537.4679 86.731,-546.8226 91.479,-541.6789\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4</title>\n",
       "<ellipse cx=\"143\" cy=\"-522\" fill=\"none\" rx=\"27.8951\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143\" y=\"-518.3\">NLP</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>2-&gt;4</title>\n",
       "<path d=\"M143,-575.8314C143,-568.131 143,-558.9743 143,-550.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.5001,-550.4132 143,-540.4133 139.5001,-550.4133 146.5001,-550.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>3</title>\n",
       "<ellipse cx=\"27\" cy=\"-450\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"27\" y=\"-446.3\">in</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4-&gt;3</title>\n",
       "<path d=\"M122.7943,-509.4586C104.2479,-497.9469 76.5692,-480.7671 55.7264,-467.8302\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"57.3163,-464.6977 46.9741,-462.3977 53.6247,-470.6451 57.3163,-464.6977\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5</title>\n",
       "<ellipse cx=\"366\" cy=\"-666\" fill=\"none\" rx=\"37.8943\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-662.3\">involve</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5-&gt;2</title>\n",
       "<path d=\"M334.5225,-655.8369C296.8752,-643.6817 233.503,-623.2207 190.0376,-609.187\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"190.856,-605.7734 180.2644,-606.0315 188.7052,-612.4348 190.856,-605.7734\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>27</title>\n",
       "<ellipse cx=\"366\" cy=\"-594\" fill=\"none\" rx=\"37.8943\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-590.3\">involve</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;27 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>5-&gt;27</title>\n",
       "<path d=\"M366,-647.8314C366,-640.131 366,-630.9743 366,-622.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"369.5001,-622.4132 366,-612.4133 362.5001,-622.4133 369.5001,-622.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>31</title>\n",
       "<ellipse cx=\"449\" cy=\"-594\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"449\" y=\"-590.3\">.</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;31 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>5-&gt;31</title>\n",
       "<path d=\"M384.4204,-650.0209C396.2855,-639.7283 411.8411,-626.2342 424.7121,-615.069\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"427.0618,-617.6641 432.3223,-608.4674 422.4749,-612.3764 427.0618,-617.6641\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>6</title>\n",
       "<ellipse cx=\"108\" cy=\"-450\" fill=\"none\" rx=\"35.9954\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-446.3\">natural</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>7</title>\n",
       "<ellipse cx=\"205\" cy=\"-450\" fill=\"none\" rx=\"43.5923\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205\" y=\"-446.3\">language</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>8</title>\n",
       "<ellipse cx=\"366\" cy=\"-522\" fill=\"none\" rx=\"62.2891\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-518.3\">understanding</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;6 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>8-&gt;6</title>\n",
       "<path d=\"M315.2684,-511.3221C271.5407,-501.6161 206.9629,-486.0768 152,-468 149.5989,-467.2103 147.1426,-466.352 144.6787,-465.4527\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"145.8287,-462.1453 135.2382,-461.84 143.3268,-468.6829 145.8287,-462.1453\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>8-&gt;7</title>\n",
       "<path d=\"M331.856,-506.7307C306.2068,-495.2602 271.0331,-479.5303 244.2282,-467.543\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"245.3221,-464.1982 234.7645,-463.3108 242.4644,-470.5884 245.3221,-464.1982\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>9</title>\n",
       "<ellipse cx=\"294\" cy=\"-450\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-446.3\">,</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>8-&gt;9</title>\n",
       "<path d=\"M348.5708,-504.5708C338.9258,-494.9258 326.8316,-482.8316 316.4816,-472.4816\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"318.8594,-469.9096 309.3134,-465.3134 313.9096,-474.8594 318.8594,-469.9096\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>11</title>\n",
       "<ellipse cx=\"366\" cy=\"-450\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-446.3\">is</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;11 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>8-&gt;11</title>\n",
       "<path d=\"M366,-503.8314C366,-496.131 366,-486.9743 366,-478.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"369.5001,-478.4132 366,-468.4133 362.5001,-478.4133 369.5001,-478.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>24</title>\n",
       "<ellipse cx=\"438\" cy=\"-450\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"438\" y=\"-446.3\">,</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;24 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>8-&gt;24</title>\n",
       "<path d=\"M383.4292,-504.5708C393.0742,-494.9258 405.1684,-482.8316 415.5184,-472.4816\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"418.0904,-474.8594 422.6866,-465.3134 413.1406,-469.9096 418.0904,-474.8594\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>25</title>\n",
       "<ellipse cx=\"510\" cy=\"-450\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-446.3\">and</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;25 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>8-&gt;25</title>\n",
       "<path d=\"M397.2459,-506.3771C421.49,-494.255 454.9263,-477.5369 479.086,-465.457\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"480.7945,-468.5159 488.1735,-460.9132 477.664,-462.2549 480.7945,-468.5159\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>26</title>\n",
       "<ellipse cx=\"588\" cy=\"-450\" fill=\"none\" rx=\"33.2948\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"588\" y=\"-446.3\">others</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;26 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>8-&gt;26</title>\n",
       "<path d=\"M411.9639,-509.7635C448.6168,-499.6349 501.0709,-484.3075 546,-468 548.2651,-467.1779 550.584,-466.2974 552.9119,-465.3841\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"554.4797,-468.5247 562.4191,-461.5092 551.8377,-462.0424 554.4797,-468.5247\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>10</title>\n",
       "<ellipse cx=\"294\" cy=\"-378\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-374.3\">that</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>11-&gt;10</title>\n",
       "<path d=\"M350.7307,-434.7307C340.803,-424.803 327.6847,-411.6847 316.5637,-400.5637\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"318.7933,-397.8436 309.2473,-393.2473 313.8436,-402.7933 318.7933,-397.8436\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>12</title>\n",
       "<ellipse cx=\"366\" cy=\"-378\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-374.3\">,</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>11-&gt;12</title>\n",
       "<path d=\"M366,-431.8314C366,-424.131 366,-414.9743 366,-406.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"369.5001,-406.4132 366,-396.4133 362.5001,-406.4133 369.5001,-406.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>13</title>\n",
       "<ellipse cx=\"453\" cy=\"-378\" fill=\"none\" rx=\"42.4939\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"453\" y=\"-374.3\">enabling</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>11-&gt;13</title>\n",
       "<path d=\"M383.1884,-435.7751C395.276,-425.7716 411.7054,-412.1748 425.5894,-400.6846\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"427.9454,-403.278 433.4179,-394.2059 423.4824,-397.8852 427.9454,-403.278\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>14</title>\n",
       "<ellipse cx=\"403\" cy=\"-306\" fill=\"none\" rx=\"48.9926\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"403\" y=\"-302.3\">computers</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>13-&gt;14</title>\n",
       "<path d=\"M440.8964,-360.5708C434.9219,-351.9675 427.5942,-341.4156 420.9799,-331.8911\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"423.7442,-329.7356 415.1654,-323.5182 417.9946,-333.7284 423.7442,-329.7356\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>16</title>\n",
       "<ellipse cx=\"503\" cy=\"-306\" fill=\"none\" rx=\"33.2948\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503\" y=\"-302.3\">derive</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;16 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>13-&gt;16</title>\n",
       "<path d=\"M465.1036,-360.5708C471.1224,-351.9038 478.5144,-341.2592 485.1669,-331.6796\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"488.1787,-333.4788 491.0079,-323.2687 482.4291,-329.486 488.1787,-333.4788\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>15</title>\n",
       "<ellipse cx=\"459\" cy=\"-234\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459\" y=\"-230.3\">to</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;15 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>16-&gt;15</title>\n",
       "<path d=\"M492.3488,-288.5708C487.0293,-279.8661 480.4907,-269.1665 474.6167,-259.5546\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"477.4512,-257.4807 469.2501,-250.7729 471.4782,-261.1308 477.4512,-257.4807\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>17</title>\n",
       "<ellipse cx=\"546\" cy=\"-234\" fill=\"none\" rx=\"42.4939\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-230.3\">meaning</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>16-&gt;17</title>\n",
       "<path d=\"M513.4091,-288.5708C518.4948,-280.0553 524.7205,-269.6308 530.3629,-260.183\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"533.4152,-261.8983 535.5377,-251.5182 527.4054,-258.3091 533.4152,-261.8983\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>23</title>\n",
       "<ellipse cx=\"546\" cy=\"-162\" fill=\"none\" rx=\"29.4969\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-158.3\">input</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;23 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>17-&gt;23</title>\n",
       "<path d=\"M546,-215.8314C546,-208.131 546,-198.9743 546,-190.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"549.5001,-190.4132 546,-180.4133 542.5001,-190.4133 549.5001,-190.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>18</title>\n",
       "<ellipse cx=\"464\" cy=\"-90\" fill=\"none\" rx=\"28.6953\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"464\" y=\"-86.3\">from</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>19</title>\n",
       "<ellipse cx=\"546\" cy=\"-90\" fill=\"none\" rx=\"35.9954\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546\" y=\"-86.3\">human</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>20</title>\n",
       "<ellipse cx=\"505\" cy=\"-18\" fill=\"none\" rx=\"27\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"505\" y=\"-14.3\">or</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;20 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>19-&gt;20</title>\n",
       "<path d=\"M536.075,-72.5708C531.19,-63.9922 525.2017,-53.4762 519.7903,-43.9732\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"522.8234,-42.2266 514.8336,-35.2687 516.7405,-45.6905 522.8234,-42.2266\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>21</title>\n",
       "<ellipse cx=\"586\" cy=\"-18\" fill=\"none\" rx=\"35.9954\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586\" y=\"-14.3\">natural</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;21 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>19-&gt;21</title>\n",
       "<path d=\"M555.6829,-72.5708C560.3649,-64.1431 566.0858,-53.8455 571.2914,-44.4755\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"574.4707,-45.9596 576.2676,-35.5182 568.3516,-42.5601 574.4707,-45.9596\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>22</title>\n",
       "<ellipse cx=\"643\" cy=\"-90\" fill=\"none\" rx=\"43.5923\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643\" y=\"-86.3\">language</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;18 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>23-&gt;18</title>\n",
       "<path d=\"M529.0095,-147.0816C517.2775,-136.7802 501.4957,-122.923 488.4197,-111.4417\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"490.5119,-108.621 480.6881,-104.653 485.8932,-113.8811 490.5119,-108.621\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;19 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>23-&gt;19</title>\n",
       "<path d=\"M546,-143.8314C546,-136.131 546,-126.9743 546,-118.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"549.5001,-118.4132 546,-108.4133 542.5001,-118.4133 549.5001,-118.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>23-&gt;22</title>\n",
       "<path d=\"M564.7026,-148.1177C578.452,-137.9119 597.418,-123.8341 613.2397,-112.0901\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"615.7093,-114.6159 621.6529,-105.8453 611.5371,-108.9951 615.7093,-114.6159\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;8 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>27-&gt;8</title>\n",
       "<path d=\"M366,-575.8314C366,-568.131 366,-558.9743 366,-550.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"369.5001,-550.4132 366,-540.4133 362.5001,-550.4133 369.5001,-550.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>30</title>\n",
       "<ellipse cx=\"675\" cy=\"-522\" fill=\"none\" rx=\"49.2915\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"675\" y=\"-518.3\">generation</text>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;30 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>27-&gt;30</title>\n",
       "<path d=\"M394.5799,-582.2072C400.6023,-579.9622 406.9618,-577.7658 413,-576 483.1429,-555.4876 566.047,-539.7894 619.5219,-530.7373\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"620.1979,-534.1729 629.4831,-529.0704 619.0425,-527.2689 620.1979,-534.1729\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>28</title>\n",
       "<ellipse cx=\"675\" cy=\"-450\" fill=\"none\" rx=\"35.9954\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"675\" y=\"-446.3\">natural</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>29</title>\n",
       "<ellipse cx=\"772\" cy=\"-450\" fill=\"none\" rx=\"43.5923\" ry=\"18\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"772\" y=\"-446.3\">language</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;28 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>30-&gt;28</title>\n",
       "<path d=\"M675,-503.8314C675,-496.131 675,-486.9743 675,-478.4166\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"678.5001,-478.4132 675,-468.4133 671.5001,-478.4133 678.5001,-478.4132\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;29 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>30-&gt;29</title>\n",
       "<path d=\"M697.0108,-505.6621C710.4679,-495.6733 727.8498,-482.7713 742.4901,-471.9042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"744.7993,-474.5491 750.7429,-465.7784 740.6271,-468.9283 744.7993,-474.5491\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2tree(root.find('./document/sentences/sentence[3]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58. タプルの抽出\n",
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）に基づき，「主語 述語 目的語」の組をタブ区切り形式で出力せよ．ただし，主語，述語，目的語の定義は以下を参考にせよ．\n",
    "\n",
    "- 述語: nsubj関係とdobj関係の子（dependant）を持つ単語\n",
    "- 主語: 述語からnsubj関係にある子（dependent）\n",
    "- 目的語: 述語からdobj関係にある子（dependent）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('understanding', 'involve', 'generation')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_svo(sentence):\n",
    "    deps = sentence.find(\"./dependencies[@type='collapsed-dependencies']\")\n",
    "    nsubj_governors = [\n",
    "        (d.find('governor').get('idx'), d.find('dependent').text)\n",
    "        for d in deps.findall(\"./dep[@type='nsubj']\")\n",
    "    ]\n",
    "    dobj_governors = [\n",
    "        (d.find('governor').get('idx'), d.find('dependent').text)\n",
    "        for d in deps.findall(\"./dep[@type='dobj']\")\n",
    "    ]\n",
    "    \n",
    "    pred_idxs = set(x[0] for x in nsubj_governors).intersection(x[0] for x in dobj_governors)\n",
    "    if not pred_idxs:\n",
    "        return None\n",
    "    \n",
    "    pred_idx = pred_idxs.pop()\n",
    "    pred = sentence.find(f\"./tokens/token[@id='{pred_idx}']\").find('word').text\n",
    "    \n",
    "    subj = list(filter(lambda x: x[0] == pred_idx, nsubj_governors))[0][1]\n",
    "    obj = list(filter(lambda x: x[0] == pred_idx, dobj_governors))[0][1]\n",
    "    \n",
    "    return subj, pred, obj\n",
    "\n",
    "extract_svo(root.find('./document/sentences/sentence[3]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understanding\tinvolve\tgeneration\n",
      "Turing\tpublished\tarticle\n",
      "experiment\tinvolved\ttranslation\n",
      "ELIZA\tprovided\tinteraction\n",
      "patient\texceeded\tbase\n",
      "which\tstructured\tinformation\n",
      "underpinnings\tdiscouraged\tsort\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "that\tcontains\terrors\n",
      "implementations\tinvolved\tcoding\n",
      "algorithms\ttake\tset\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "models\thave\tadvantage\n",
      "Systems\thave\tadvantages\n",
      "procedures\tmake\tuse\n",
      "that\tmake\tdecisions\n"
     ]
    }
   ],
   "source": [
    "for sentence in root.findall(\"./document/sentences/sentence\"):\n",
    "    svo = extract_svo(sentence)\n",
    "    if svo:\n",
    "        print(*svo, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59. S式の解析\n",
    "Stanford Core NLPの句構造解析の結果（S式）を読み込み，文中のすべての名詞句（NP）を表示せよ．入れ子になっている名詞句もすべて表示すること．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [1.3 sec].\n",
      "\n",
      "Processing file /Users/masato/Desktop/nlp100/nlp.txt ... writing to /Users/masato/Desktop/nlp100/nlp.txt.xml\n",
      "Annotating file /Users/masato/Desktop/nlp100/nlp.txt ... done [14.2 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "POSTaggerAnnotator: 0.2 sec.\n",
      "ParserAnnotator: 13.9 sec.\n",
      "TOTAL: 14.2 sec. for 1452 tokens at 102.2 tokens/sec.\n",
      "Pipeline setup: 3.0 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 17.5 sec.\n"
     ]
    }
   ],
   "source": [
    "!java -Xmx4g -cp \"stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,parse -file nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlp.txt.xml') as f:\n",
    "    root = ETree.fromstring(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'parse' at 0x1a1699cb38>,\n",
       " <Element 'parse' at 0x1a16c4dc28>,\n",
       " <Element 'parse' at 0x1a16c75ef8>,\n",
       " <Element 'parse' at 0x1a16cc8b88>,\n",
       " <Element 'parse' at 0x1a16d08e58>]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses = root.findall(\"./document/sentences/sentence/parse\")\n",
    "parses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ROOT (S (PP (NP (JJ Natural) (NN language) (NN processing)) (IN From) (NP (NNP Wikipedia))) (, ,) (NP (NP (DT the) (JJ free) (NN encyclopedia) (JJ Natural) (NN language) (NN processing)) (PRN (-LRB- -LRB-) (NP (NN NLP)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (NP (DT a) (NN field)) (PP (IN of) (NP (NN computer) (NN science)))) (, ,) (NP (JJ artificial) (NN intelligence)) (, ,) (CC and) (NP (NP (NNS linguistics)) (VP (VBN concerned) (PP (IN with) (NP (NP (DT the) (NNS interactions)) (PP (IN between) (NP (NP (NNS computers)) (CC and) (NP (JJ human) (-LRB- -LRB-) (JJ natural) (-RRB- -RRB-) (NNS languages)))))))))) (. .))) '"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_parse(parse):\n",
    "    tree, _end = parse_parsetext(parse.text)\n",
    "    return tree\n",
    "\n",
    "def parse_parsetext(text, start=0) -> (tuple, int):\n",
    "    #print(f'called: {text[start:]}')\n",
    "    assert text[start] == '('\n",
    "    tag = text[start + 1:text.index(' ', start + 1)]\n",
    "    contents = []\n",
    "    \n",
    "    i = start + len(f'({tag} ')\n",
    "    while i < len(text):\n",
    "        if text[i] == '(':\n",
    "            content, end = extract_pars(text, i)\n",
    "            contents.append(content)\n",
    "            i = end + 1\n",
    "        elif text[i] == ')':\n",
    "            end = i\n",
    "            return ((tag, contents), end)\n",
    "        elif text[i] == ' ':\n",
    "            i += 1\n",
    "        else:\n",
    "            m = re.search(r'[\\(\\) ]', text[i:])\n",
    "            contents.append(text[i:i + m.start()])\n",
    "            #print(f'contents added: {contents[-1]}')\n",
    "            i += m.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ROOT',\n",
       " [('S',\n",
       "   [('PP',\n",
       "     [('NP',\n",
       "       [('JJ', ['Natural']), ('NN', ['language']), ('NN', ['processing'])]),\n",
       "      ('IN', ['From']),\n",
       "      ('NP', [('NNP', ['Wikipedia'])])]),\n",
       "    (',', [',']),\n",
       "    ('NP',\n",
       "     [('NP',\n",
       "       [('DT', ['the']),\n",
       "        ('JJ', ['free']),\n",
       "        ('NN', ['encyclopedia']),\n",
       "        ('JJ', ['Natural']),\n",
       "        ('NN', ['language']),\n",
       "        ('NN', ['processing'])]),\n",
       "      ('PRN',\n",
       "       [('-LRB-', ['-LRB-']),\n",
       "        ('NP', [('NN', ['NLP'])]),\n",
       "        ('-RRB-', ['-RRB-'])])]),\n",
       "    ('VP',\n",
       "     [('VBZ', ['is']),\n",
       "      ('NP',\n",
       "       [('NP',\n",
       "         [('NP', [('DT', ['a']), ('NN', ['field'])]),\n",
       "          ('PP',\n",
       "           [('IN', ['of']),\n",
       "            ('NP', [('NN', ['computer']), ('NN', ['science'])])])]),\n",
       "        (',', [',']),\n",
       "        ('NP', [('JJ', ['artificial']), ('NN', ['intelligence'])]),\n",
       "        (',', [',']),\n",
       "        ('CC', ['and']),\n",
       "        ('NP',\n",
       "         [('NP', [('NNS', ['linguistics'])]),\n",
       "          ('VP',\n",
       "           [('VBN', ['concerned']),\n",
       "            ('PP',\n",
       "             [('IN', ['with']),\n",
       "              ('NP',\n",
       "               [('NP', [('DT', ['the']), ('NNS', ['interactions'])]),\n",
       "                ('PP',\n",
       "                 [('IN', ['between']),\n",
       "                  ('NP',\n",
       "                   [('NP', [('NNS', ['computers'])]),\n",
       "                    ('CC', ['and']),\n",
       "                    ('NP',\n",
       "                     [('JJ', ['human']),\n",
       "                      ('-LRB-', ['-LRB-']),\n",
       "                      ('JJ', ['natural']),\n",
       "                      ('-RRB-', ['-RRB-']),\n",
       "                      ('NNS', ['languages'])])])])])])])])])]),\n",
       "    ('.', ['.'])])])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_parse(parses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rip_tree(tree):\n",
    "    if isinstance(tree, str):\n",
    "        return tree\n",
    "    if isinstance(tree, tuple):\n",
    "        _tag, contents = tree\n",
    "        return ' '.join(map(rip_tree, contents))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing From Wikipedia , the free encyclopedia Natural language processing -LRB- NLP -RRB- is a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages .'"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rip_tree(parse_parse(parses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_np(tree):\n",
    "    if isinstance(tree, tuple):\n",
    "        tag, contents = tree\n",
    "        if tag == 'NP':\n",
    "            print(rip_tree(tree))\n",
    "        for content in contents:\n",
    "            display_np(content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "Wikipedia\n",
      "the free encyclopedia Natural language processing -LRB- NLP -RRB-\n",
      "the free encyclopedia Natural language processing\n",
      "NLP\n",
      "a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "a field of computer science\n",
      "a field\n",
      "computer science\n",
      "artificial intelligence\n",
      "linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "linguistics\n",
      "the interactions between computers and human -LRB- natural -RRB- languages\n",
      "the interactions\n",
      "computers and human -LRB- natural -RRB- languages\n",
      "computers\n",
      "human -LRB- natural -RRB- languages\n"
     ]
    }
   ],
   "source": [
    "display_np(parse_parse(parses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "Wikipedia\n",
      "the free encyclopedia Natural language processing -LRB- NLP -RRB-\n",
      "the free encyclopedia Natural language processing\n",
      "NLP\n",
      "a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "a field of computer science\n",
      "a field\n",
      "computer science\n",
      "artificial intelligence\n",
      "linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "linguistics\n",
      "the interactions between computers and human -LRB- natural -RRB- languages\n",
      "the interactions\n",
      "computers and human -LRB- natural -RRB- languages\n",
      "computers\n",
      "human -LRB- natural -RRB- languages\n",
      "such\n",
      "NLP\n",
      "the area of humani-computer interaction\n",
      "the area\n",
      "humani-computer interaction\n",
      "Many challenges in NLP\n",
      "Many challenges\n",
      "NLP\n",
      "natural language understanding , that is ,\n",
      "natural language understanding\n",
      "computers\n",
      "meaning\n",
      "human or natural language input\n",
      "others\n",
      "natural language generation\n",
      "History The history of NLP\n",
      "History The history\n",
      "NLP\n",
      "the 1950s\n",
      "work\n",
      "earlier periods\n",
      "1950\n",
      "Alan Turing\n",
      "an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence\n",
      "an article\n",
      "Computing Machinery and Intelligence\n",
      "the Turing test\n",
      "a criterion of intelligence\n",
      "a criterion\n",
      "intelligence\n",
      "The Georgetown experiment in 1954\n",
      "The Georgetown experiment\n",
      "1954\n",
      "fully automatic translation of more than sixty Russian sentences\n",
      "fully automatic translation\n",
      "more than sixty Russian sentences\n",
      "English\n",
      "The authors\n",
      "three or five years\n",
      "machine translation\n",
      "a solved problem\n",
      "real progress\n",
      "the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations\n",
      "the ALPAC report\n",
      "1966\n",
      "long research\n",
      "the expectations\n",
      "machine\n",
      "translation\n",
      "Little further research in machine translation\n",
      "Little further research\n",
      "machine translation\n",
      "the late 1980s , when the first statistical machine translation systems were developed\n",
      "the late 1980s\n",
      "the first statistical machine translation systems\n",
      "the first statistical machine\n",
      "translation systems\n",
      "Some notably successful NLP systems developed in the 1960s\n",
      "Some notably successful NLP systems\n",
      "the 1960s\n",
      "SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies\n",
      "SHRDLU\n",
      "a natural language system working in restricted `` blocks worlds '' with restricted vocabularies\n",
      "a natural language system\n",
      "restricted `` blocks worlds ''\n",
      "restricted\n",
      "blocks worlds\n",
      "restricted vocabularies\n",
      "ELIZA , a simulation of a Rogerian psychotherapist ,\n",
      "ELIZA\n",
      "a simulation of a Rogerian psychotherapist\n",
      "a simulation\n",
      "a Rogerian psychotherapist\n",
      "Joseph Weizenbaum between 1964 to 1966\n",
      "Joseph Weizenbaum\n",
      "1964 to 1966\n",
      "almost no information\n",
      "human thought or emotion\n",
      "ELIZA\n",
      "a startlingly human-like interaction\n",
      "the `` patient ''\n",
      "the very small knowledge base\n",
      "ELIZA\n",
      "a generic response , for example , responding to `` My head hurts\n",
      "a generic response\n",
      "example\n",
      "My head\n",
      "you\n",
      "your head\n",
      ".\n",
      "the 1970s\n",
      "many programmers\n",
      "conceptual ontologies ' , which structured real-world information into computer-understandable data\n",
      "conceptual ontologies '\n",
      "conceptual\n",
      "ontologies '\n",
      "real-world information\n",
      "computer-understandable data\n",
      "Examples\n",
      "MARGIE -LRB- Schank , 1975 -RRB- , SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "MARGIE -LRB- Schank , 1975 -RRB-\n",
      "MARGIE\n",
      "Schank\n",
      "1975\n",
      "SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "SAM -LRB- Cullingford , 1978 -RRB-\n",
      "SAM\n",
      "Cullingford\n",
      "1978\n",
      "PAM -LRB- Wilensky , 1978 -RRB-\n",
      "PAM\n",
      "Wilensky\n",
      "1978\n",
      "TaleSpin -LRB- Meehan , 1976 -RRB-\n",
      "TaleSpin\n",
      "Meehan\n",
      "1976\n",
      "QUALM -LRB- Lehnert , 1977 -RRB-\n",
      "QUALM\n",
      "Lehnert , 1977\n",
      "Lehnert\n",
      "1977\n",
      "Politics -LRB- Carbonell , 1979 -RRB-\n",
      "Politics\n",
      "Carbonell\n",
      "1979\n",
      "Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "Plot Units\n",
      "Lehnert 1981\n",
      "this time\n",
      "many chatterbots\n",
      "PARRY , Racter , and Jabberwacky\n",
      "the 1980s\n",
      "most NLP systems\n",
      "complex sets of hand-written rules\n",
      "complex sets\n",
      "hand-written rules\n",
      "the late 1980s\n",
      "there\n",
      "a revolution in NLP\n",
      "a revolution\n",
      "NLP\n",
      "the introduction of machine learning algorithms for language processing\n",
      "the introduction\n",
      "machine learning algorithms for language processing\n",
      "machine learning algorithms\n",
      "language processing\n",
      "This\n",
      "both the steady increase\n",
      "computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "computational power\n",
      "Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "Moore 's Law\n",
      "Moore 's\n",
      "the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "the gradual lessening\n",
      "the dominance of Chomskyan theories\n",
      "the dominance\n",
      "Chomskyan theories\n",
      "linguistics -LRB- e.g. transformational grammar -RRB-\n",
      "linguistics\n",
      "e.g. transformational grammar\n",
      "e.g.\n",
      "transformational grammar\n",
      "theoretical underpinnings\n",
      "the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "the sort\n",
      "corpus linguistics\n",
      "the machine-learning approach\n",
      "language processing\n",
      "Some of the earliest-used machine learning algorithms , such as decision trees ,\n",
      "Some\n",
      "the earliest-used machine learning algorithms , such as decision trees ,\n",
      "the earliest-used machine\n",
      "algorithms , such as decision trees ,\n",
      "algorithms\n",
      "decision trees\n",
      "systems of hard if-then rules similar to existing hand-written rules\n",
      "systems\n",
      "hard if-then rules similar to existing hand-written rules\n",
      "hard if-then rules\n",
      "existing hand-written rules\n",
      "Part of speech\n",
      "Part\n",
      "speech\n",
      "the use of Hidden Markov Models\n",
      "the use\n",
      "Hidden Markov Models\n",
      "NLP\n",
      "research\n",
      "statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data\n",
      "statistical models\n",
      "soft , probabilistic decisions\n",
      "real-valued weights\n",
      "the features making up the input data\n",
      "the features\n",
      "the input data\n",
      "The cache language models upon which many speech recognition systems now rely\n",
      "The cache language models\n",
      "many speech recognition systems\n",
      "examples of such statistical models\n",
      "examples\n",
      "such statistical models\n",
      "Such models\n",
      "unfamiliar input , especially input that contains errors -LRB- as is very common for real-world data -RRB- ,\n",
      "unfamiliar input\n",
      "input that contains errors -LRB- as is very common for real-world data -RRB-\n",
      "input\n",
      "errors -LRB- as is very common for real-world data -RRB-\n",
      "errors\n",
      "real-world data\n",
      "more reliable results\n",
      "a larger system comprising multiple subtasks\n",
      "a larger system\n",
      "multiple subtasks\n",
      "Many of the notable early successes\n",
      "Many\n",
      "the notable early successes\n",
      "the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed\n",
      "the field\n",
      "machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed\n",
      "machine translation\n",
      "IBM Research\n",
      "more complicated statistical models\n",
      "These systems\n",
      "advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "advantage\n",
      "existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "existing multilingual textual corpora\n",
      "the Parliament of Canada and the European Union\n",
      "the Parliament\n",
      "Canada and the European Union\n",
      "Canada\n",
      "the European Union\n",
      "a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "a result\n",
      "laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "laws\n",
      "the translation of all governmental proceedings\n",
      "the translation\n",
      "all governmental proceedings\n",
      "all official languages of the corresponding systems of government\n",
      "all official languages\n",
      "the corresponding systems of government\n",
      "the corresponding systems\n",
      "government\n",
      "most other systems\n",
      "corpora\n",
      "the tasks implemented by these systems , which was -LRB- and often continues to be -RRB-\n",
      "the tasks\n",
      "these systems , which was -LRB- and often continues to be -RRB-\n",
      "these systems\n",
      "a major limitation in the success of these systems\n",
      "a major limitation\n",
      "the success of these systems\n",
      "the success\n",
      "these systems\n",
      "a result\n",
      "a great deal of research\n",
      "a great deal\n",
      "research\n",
      "methods of more effectively learning from limited amounts of data\n",
      "methods\n",
      "more effectively learning from limited amounts of data\n",
      "more\n",
      "limited amounts of data\n",
      "limited amounts\n",
      "data\n",
      "Recent research\n",
      "unsupervised and semi-supervised learning algorithms\n",
      "Such algorithms\n",
      "data that has not been hand-annotated with the desired answers\n",
      "data\n",
      "the desired answers\n",
      "a combination of annotated and non-annotated data\n",
      "a combination\n",
      "annotated and non-annotated data\n",
      "this task\n",
      "supervised learning\n",
      "less accurate results for a given amount of input data\n",
      "less accurate results\n",
      "a given amount of input data\n",
      "a given amount\n",
      "input data\n",
      "there\n",
      "an enormous amount of non-annotated data available -LRB- including , among other things , the entire content of the World Wide Web -RRB- , which can often make up for the inferior results\n",
      "an enormous amount of non-annotated data available\n",
      "an enormous amount\n",
      "non-annotated data available\n",
      "non-annotated data\n",
      "other things\n",
      "the entire content of the World Wide Web\n",
      "the entire content\n",
      "the World Wide Web\n",
      "the inferior results\n",
      "NLP using machine learning Modern NLP algorithms\n",
      "NLP\n",
      "machine learning Modern NLP algorithms\n",
      "machine learning , especially statistical machine learning\n",
      "machine learning\n",
      "statistical machine learning\n",
      "The paradigm of machine learning\n",
      "The paradigm\n",
      "machine learning\n",
      "that of most prior attempts\n",
      "that\n",
      "most prior attempts\n",
      "language processing\n",
      "implementations of language-processing tasks\n",
      "implementations\n",
      "language-processing tasks\n",
      "the direct hand coding of large sets of rules\n",
      "the direct hand coding\n",
      "large sets of rules\n",
      "large sets\n",
      "rules\n",
      "The machine-learning paradigm\n",
      "general learning algorithms - often\n",
      "general learning algorithms\n",
      "statistical inference\n",
      "such rules\n",
      "the analysis of large corpora of typical real-world examples\n",
      "the analysis\n",
      "large corpora of typical real-world examples\n",
      "large corpora\n",
      "typical real-world examples\n",
      "A corpus -LRB- plural , `` corpora '' -RRB-\n",
      "A corpus\n",
      "plural , `` corpora ''\n",
      "plural\n",
      "`` corpora ''\n",
      "a set of documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned\n",
      "a set\n",
      "documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned\n",
      "documents\n",
      "individual sentences\n",
      "the correct values\n",
      "Many different classes of machine learning algorithms\n",
      "Many different classes\n",
      "machine learning algorithms\n",
      "NLP tasks\n",
      "These algorithms\n",
      "as input\n",
      "a large set of `` features '' that are generated from the input data\n",
      "a large set\n",
      "`` features '' that are generated from the input data\n",
      "`` features ''\n",
      "the input data\n",
      "Some of the earliest-used algorithms , such as decision trees ,\n",
      "Some\n",
      "the earliest-used algorithms\n",
      "decision trees\n",
      "systems of hard if-then rules similar to the systems of hand-written rules that were then common\n",
      "systems\n",
      "hard if-then rules similar to the systems of hand-written rules that were then common\n",
      "hard if-then rules\n",
      "the systems of hand-written rules that were then common\n",
      "the systems\n",
      "hand-written rules\n",
      "research\n",
      "statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature\n",
      "statistical models\n",
      "soft , probabilistic decisions\n",
      "real-valued weights\n",
      "each input feature\n",
      "Such models\n",
      "the advantage\n",
      "they\n",
      "the relative certainty of many different possible answers rather than only one\n",
      "the relative certainty\n",
      "many different possible answers rather than only one\n",
      "many different possible answers\n",
      "only one\n",
      "more reliable results\n",
      "such a model\n",
      "a component of a larger system\n",
      "a component\n",
      "a larger system\n",
      "Systems based on machine-learning algorithms\n",
      "Systems\n",
      "machine-learning algorithms\n",
      "many advantages over hand-produced rules\n",
      "many advantages\n",
      "hand-produced rules\n",
      "The learning procedures used during machine learning\n",
      "The learning procedures\n",
      "machine learning\n",
      "the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed\n",
      "the most common cases\n",
      "rules\n",
      "hand\n",
      "it\n",
      "all\n",
      "the effort\n",
      "Automatic learning procedures\n",
      "Automatic\n",
      "procedures\n",
      "use of statistical inference algorithms\n",
      "use\n",
      "statistical inference algorithms\n",
      "models that are robust to unfamiliar input -LRB- e.g. containing words or structures that have not been seen before -RRB- and to erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-\n",
      "models\n",
      "unfamiliar input\n",
      "words or structures that have not been seen before\n",
      "words or structures\n",
      "erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-\n",
      "e.g. with misspelled words or words accidentally omitted\n",
      "e.g.\n",
      "words or words accidentally omitted\n",
      "words or words\n",
      "such input gracefully with hand-written rules -- or more\n",
      "such input\n",
      "hand-written rules\n",
      "systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming\n",
      "systems\n",
      "hand-written rules\n",
      "soft decisions -- extremely difficult , error-prone and time-consuming\n",
      "soft decisions\n",
      "Systems based on automatically learning the rules\n",
      "Systems\n",
      "the rules\n",
      "more input data\n",
      "systems based on hand-written rules\n",
      "systems\n",
      "hand-written rules\n",
      "the complexity of the rules , which is a much more difficult task\n",
      "the complexity\n",
      "the rules , which is a much more difficult task\n",
      "the rules\n",
      "a much more difficult task\n",
      "there\n",
      "a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "a limit\n",
      "the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "the complexity\n",
      "systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "systems\n",
      "hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "hand-crafted rules\n",
      "the systems\n",
      "more data\n",
      "input\n",
      "machine-learning systems\n",
      "a corresponding increase in the number of man-hours\n",
      "a corresponding increase\n",
      "the number of man-hours\n",
      "the number\n",
      "man-hours\n",
      "significant increases in the complexity of the annotation process\n",
      "significant increases\n",
      "the complexity of the annotation process\n",
      "the complexity\n",
      "the annotation process\n",
      "The subfield of NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL\n",
      "The subfield\n",
      "NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL\n",
      "NLP\n",
      "approaches\n",
      "Natural Language Learning -LRB- NLL -RRB-\n",
      "Natural Language Learning\n",
      "NLL\n",
      "its conference CoNLL and peak body\n",
      "SIGNLL\n",
      "ACL\n",
      "their links\n",
      "Computational Linguistics and Language Acquisition\n",
      "Computational Linguistics\n",
      "Language Acquisition\n",
      "the aims of computational language learning research\n",
      "the aims\n",
      "computational language learning research\n",
      "computational language\n",
      "research\n",
      "more\n",
      "human language acquisition , or psycholinguistics\n",
      "human language acquisition\n",
      "psycholinguistics\n",
      "NLL\n",
      "the related field of Computational Psycholinguistics\n",
      "the related field\n",
      "Computational Psycholinguistics\n"
     ]
    }
   ],
   "source": [
    "for parse in parses:\n",
    "    display_np(parse_parse(parse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
